{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/CNAME","path":"CNAME","modified":0,"renderable":0},{"_id":"source/images/ELK-Kibana-URL.png","path":"images/ELK-Kibana-URL.png","modified":0,"renderable":0},{"_id":"source/images/code-pipeline.png","path":"images/code-pipeline.png","modified":0,"renderable":0},{"_id":"source/images/iac-dcos.jpg","path":"images/iac-dcos.jpg","modified":0,"renderable":0},{"_id":"source/images/iac-manager.jpg","path":"images/iac-manager.jpg","modified":0,"renderable":0},{"_id":"source/images/logo.jpg","path":"images/logo.jpg","modified":0,"renderable":0},{"_id":"source/images/iac-wrapper.jpg","path":"images/iac-wrapper.jpg","modified":0,"renderable":0},{"_id":"source/images/logo.png","path":"images/logo.png","modified":0,"renderable":0},{"_id":"source/images/openVPN.png","path":"images/openVPN.png","modified":0,"renderable":0},{"_id":"source/images/ELK-Access-Policy.png","path":"images/ELK-Access-Policy.png","modified":0,"renderable":0},{"_id":"source/images/Kibana-dashboard.png","path":"images/Kibana-dashboard.png","modified":0,"renderable":0},{"_id":"source/images/NGP_Architecture.png","path":"images/NGP_Architecture.png","modified":0,"renderable":0},{"_id":"source/images/marathon-lb-timeouts.png","path":"images/marathon-lb-timeouts.png","modified":0,"renderable":0},{"_id":"source/images/Tyk-API.png","path":"images/Tyk-API.png","modified":0,"renderable":0},{"_id":"source/images/aws-dev-tools/code-pipeline.png","path":"images/aws-dev-tools/code-pipeline.png","modified":0,"renderable":0},{"_id":"source/images/cloudformation/Template_YAML.png","path":"images/cloudformation/Template_YAML.png","modified":0,"renderable":0},{"_id":"source/images/sysdig/Creating-alerts-for-marathon-failure2.png","path":"images/sysdig/Creating-alerts-for-marathon-failure2.png","modified":0,"renderable":0},{"_id":"themes/indigo/source/css/style.less","path":"css/style.less","modified":0,"renderable":1},{"_id":"themes/indigo/source/img/brand.jpg","path":"img/brand.jpg","modified":0,"renderable":1},{"_id":"themes/indigo/source/img/cc.png","path":"img/cc.png","modified":0,"renderable":1},{"_id":"themes/indigo/source/img/img-err.png","path":"img/img-err.png","modified":0,"renderable":1},{"_id":"themes/indigo/source/img/img-loading.png","path":"img/img-loading.png","modified":0,"renderable":1},{"_id":"themes/indigo/source/js/main.js","path":"js/main.js","modified":0,"renderable":1},{"_id":"themes/indigo/source/js/main.min.js","path":"js/main.min.js","modified":0,"renderable":1},{"_id":"themes/indigo/source/js/search.js","path":"js/search.js","modified":0,"renderable":1},{"_id":"themes/indigo/source/js/search.min.js","path":"js/search.min.js","modified":0,"renderable":1},{"_id":"source/images/Tyk-API-Gateway.png","path":"images/Tyk-API-Gateway.png","modified":0,"renderable":0},{"_id":"source/images/cloudformation/CloudFormation_Components.png","path":"images/cloudformation/CloudFormation_Components.png","modified":0,"renderable":0},{"_id":"source/images/cloudformation/Designer.png","path":"images/cloudformation/Designer.png","modified":0,"renderable":0},{"_id":"source/images/cloudformation/Template1.png","path":"images/cloudformation/Template1.png","modified":0,"renderable":0},{"_id":"source/images/cloudformation/Template2.png","path":"images/cloudformation/Template2.png","modified":0,"renderable":0},{"_id":"source/images/cloudformation/Template3.png","path":"images/cloudformation/Template3.png","modified":0,"renderable":0},{"_id":"source/images/sysdig/Creating-an-alert-for-90-CPU-utilization.png","path":"images/sysdig/Creating-an-alert-for-90-CPU-utilization.png","modified":0,"renderable":0},{"_id":"source/images/sysdig/Memory-utilization-monitoring-using-Sysdig.png","path":"images/sysdig/Memory-utilization-monitoring-using-Sysdig.png","modified":0,"renderable":0},{"_id":"themes/indigo/source/js/embed.js","path":"js/embed.js","modified":0,"renderable":1},{"_id":"themes/indigo/source/js/embed.min.js","path":"js/embed.min.js","modified":0,"renderable":1},{"_id":"source/images/sysdig/Creating-alerts-for-marathon-failure.png","path":"images/sysdig/Creating-alerts-for-marathon-failure.png","modified":0,"renderable":0},{"_id":"source/images/aws-dev-tools/codepipeline/code-pipeline-step-1.png","path":"images/aws-dev-tools/codepipeline/code-pipeline-step-1.png","modified":0,"renderable":0},{"_id":"source/images/aws-dev-tools/codepipeline/code-pipeline-step-2.png","path":"images/aws-dev-tools/codepipeline/code-pipeline-step-2.png","modified":0,"renderable":0},{"_id":"source/images/aws-dev-tools/codepipeline/code-pipeline-step-3.png","path":"images/aws-dev-tools/codepipeline/code-pipeline-step-3.png","modified":0,"renderable":0},{"_id":"source/images/aws-dev-tools/codepipeline/code-pipeline-step-5.png","path":"images/aws-dev-tools/codepipeline/code-pipeline-step-5.png","modified":0,"renderable":0},{"_id":"source/images/aws-dev-tools/codepipeline/code-pipeline-step-7.png","path":"images/aws-dev-tools/codepipeline/code-pipeline-step-7.png","modified":0,"renderable":0},{"_id":"source/images/aws-dev-tools/codepipeline/code-pipeline-step-8.png","path":"images/aws-dev-tools/codepipeline/code-pipeline-step-8.png","modified":0,"renderable":0},{"_id":"source/images/aws-dev-tools/codepipeline/code-pipeline-step-6.png","path":"images/aws-dev-tools/codepipeline/code-pipeline-step-6.png","modified":0,"renderable":0},{"_id":"source/images/aws-dev-tools/ecr/ecr-creation-step-1.png","path":"images/aws-dev-tools/ecr/ecr-creation-step-1.png","modified":0,"renderable":0},{"_id":"source/images/aws-dev-tools/ecr/ecr-creation-step-2.png","path":"images/aws-dev-tools/ecr/ecr-creation-step-2.png","modified":0,"renderable":0},{"_id":"source/images/sysdig/Creating-alert-for-disk-utilization2.png","path":"images/sysdig/Creating-alert-for-disk-utilization2.png","modified":0,"renderable":0},{"_id":"source/images/aws-dev-tools/codepipeline/code-pipeline-step-9.png","path":"images/aws-dev-tools/codepipeline/code-pipeline-step-9.png","modified":0,"renderable":0},{"_id":"source/images/sysdig/Creating-alert-for-disk-utilization.png","path":"images/sysdig/Creating-alert-for-disk-utilization.png","modified":0,"renderable":0},{"_id":"source/images/sysdig/Creating-alerts-for-marathon-app-failure.png","path":"images/sysdig/Creating-alerts-for-marathon-app-failure.png","modified":0,"renderable":0},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Bold.eot","path":"css/fonts/roboto/Roboto-Bold.eot","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Bold.woff","path":"css/fonts/roboto/Roboto-Bold.woff","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Bold.woff2","path":"css/fonts/roboto/Roboto-Bold.woff2","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Light.eot","path":"css/fonts/roboto/Roboto-Light.eot","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Light.woff","path":"css/fonts/roboto/Roboto-Light.woff","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Light.woff2","path":"css/fonts/roboto/Roboto-Light.woff2","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Medium.eot","path":"css/fonts/roboto/Roboto-Medium.eot","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Medium.woff","path":"css/fonts/roboto/Roboto-Medium.woff","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Regular.eot","path":"css/fonts/roboto/Roboto-Regular.eot","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Medium.woff2","path":"css/fonts/roboto/Roboto-Medium.woff2","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Regular.woff","path":"css/fonts/roboto/Roboto-Regular.woff","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Regular.woff2","path":"css/fonts/roboto/Roboto-Regular.woff2","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Thin.eot","path":"css/fonts/roboto/Roboto-Thin.eot","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Thin.woff","path":"css/fonts/roboto/Roboto-Thin.woff","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Thin.woff2","path":"css/fonts/roboto/Roboto-Thin.woff2","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/fontawesome/FontAwesome.otf","path":"css/fonts/fontawesome/FontAwesome.otf","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/fontawesome/fontawesome-webfont.eot","path":"css/fonts/fontawesome/fontawesome-webfont.eot","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/fontawesome/fontawesome-webfont.woff","path":"css/fonts/fontawesome/fontawesome-webfont.woff","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/fontawesome/fontawesome-webfont.woff2","path":"css/fonts/fontawesome/fontawesome-webfont.woff2","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Bold.ttf","path":"css/fonts/roboto/Roboto-Bold.ttf","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Light.ttf","path":"css/fonts/roboto/Roboto-Light.ttf","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Medium.ttf","path":"css/fonts/roboto/Roboto-Medium.ttf","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Regular.ttf","path":"css/fonts/roboto/Roboto-Regular.ttf","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Thin.ttf","path":"css/fonts/roboto/Roboto-Thin.ttf","modified":0,"renderable":1},{"_id":"source/images/DCOS.png","path":"images/DCOS.png","modified":0,"renderable":0},{"_id":"themes/indigo/source/css/fonts/fontawesome/fontawesome-webfont.ttf","path":"css/fonts/fontawesome/fontawesome-webfont.ttf","modified":0,"renderable":1},{"_id":"source/images/aws-dev-tools/codepipeline/code-pipeline-step-4.png","path":"images/aws-dev-tools/codepipeline/code-pipeline-step-4.png","modified":0,"renderable":0},{"_id":"themes/indigo/source/css/fonts/fontawesome/fontawesome-webfont.svg","path":"css/fonts/fontawesome/fontawesome-webfont.svg","modified":0,"renderable":1},{"_id":"source/images/sysdig/Disk-utilization-monitoring-using-Sysdig-dashboard-tab.png","path":"images/sysdig/Disk-utilization-monitoring-using-Sysdig-dashboard-tab.png","modified":0,"renderable":0},{"_id":"source/images/elastic-stack/console-create-stack-button.png","path":"images/elastic-stack/console-create-stack-button.png","modified":0,"renderable":0},{"_id":"source/images/elastic-stack/console-create-stack-button1.png","path":"images/elastic-stack/console-create-stack-button1.png","modified":0,"renderable":0},{"_id":"source/images/elastic-stack/elastic-stack.png","path":"images/elastic-stack/elastic-stack.png","modified":0,"renderable":0},{"_id":"source/images/elastic-stack/creation-completed.png","path":"images/elastic-stack/creation-completed.png","modified":0,"renderable":0},{"_id":"source/images/elastic-stack/verify-kibana.png","path":"images/elastic-stack/verify-kibana.png","modified":0,"renderable":0},{"_id":"source/images/elastic-stack/kibana.png","path":"images/elastic-stack/kibana.png","modified":0,"renderable":0},{"_id":"source/images/elastic-stack/select-template.png","path":"images/elastic-stack/select-template.png","modified":0,"renderable":0},{"_id":"source/images/elastic-stack/parameters.png","path":"images/elastic-stack/parameters.png","modified":0,"renderable":0}],"Cache":[{"_id":"source/CNAME","hash":"a9aa187446d7d843ba87d5342135bfa83200b808","modified":1483504408000},{"_id":"themes/indigo/README.md","hash":"e807a57be44e5b826248fe71589ade4a7ec46d8d","modified":1483504408000},{"_id":"themes/indigo/_config.yml","hash":"041b7438caf6e0b308d58ecde301a39d81a3ce89","modified":1483504408000},{"_id":"themes/indigo/package.json","hash":"fda65ce0d59fb93b1f9e72eef5aa574ad4b28979","modified":1483504408000},{"_id":"source/_posts/DCOS-Disaster-Recovery.md","hash":"aa6ab1b3a477c30e2c7414be80e51be47c0c2278","modified":1483504408000},{"_id":"source/_posts/Debugging-DCOS.md","hash":"1cc3b4294925698fa7aeb2ce05936f5636b72bf9","modified":1483504408000},{"_id":"source/_posts/Nginx-Marathon-App-example.md","hash":"d717c1dcf5fed373127df64cfc99e779569d1407","modified":1483504408000},{"_id":"source/categories/index.md","hash":"36ea3e07c4230cbfb9f3b76fed0cc054ca5ae60e","modified":1483504408000},{"_id":"source/images/ELK-Kibana-URL.png","hash":"106eca0d95ddfbcd45f580ef57be7035693e543a","modified":1483504408000},{"_id":"source/images/code-pipeline.png","hash":"6663560186053f15089e4baadd77cf0501e40029","modified":1483504408000},{"_id":"source/images/iac-dcos.jpg","hash":"1c857932ad697bbd26683e9d447fa50e07d1f5e0","modified":1483504408000},{"_id":"source/images/iac-manager.jpg","hash":"e5c2151638512fd6e44b52ff35f878346726cd49","modified":1483504408000},{"_id":"source/images/logo.jpg","hash":"089806a16581309f20ac2c9f3fdb34089981d21c","modified":1483504408000},{"_id":"source/images/iac-wrapper.jpg","hash":"058f128377a53686aeb9d4ead93b362b1d2e3b31","modified":1483504408000},{"_id":"source/images/logo.png","hash":"21409308c44b07be301047757c34e37150ffb9be","modified":1483504408000},{"_id":"source/images/openVPN.png","hash":"56288d0e5163ea25794802d0d3b7988d7bad4895","modified":1483504408000},{"_id":"source/tags/index.md","hash":"7695101fbd9528e22234e1222ff6a678fd735e65","modified":1483504408000},{"_id":"themes/indigo/layout/archive.ejs","hash":"2401f59218ea95a28f026d981ae7eea4c71f34f2","modified":1483504408000},{"_id":"themes/indigo/layout/categories.ejs","hash":"7b8cef49566290faddb7fccbecbc4518fc8f3f82","modified":1483504408000},{"_id":"themes/indigo/layout/category.ejs","hash":"29257bc34e1055969a3c0ec875756174d61853ed","modified":1483504408000},{"_id":"themes/indigo/layout/index.ejs","hash":"7b30eb5d865ffd0070728a148f104b31bd93e697","modified":1483504408000},{"_id":"themes/indigo/layout/layout.ejs","hash":"b78e205eddad90fd4dfb98bbf8a737c0aa7e020d","modified":1483504408000},{"_id":"themes/indigo/layout/page.ejs","hash":"e1e150c9471b357b0fbbc5e635099dcb99dc8086","modified":1483504408000},{"_id":"themes/indigo/layout/post.ejs","hash":"a8ca16b75bbbd1c4545af2dc511e51f3c9a3c360","modified":1483504408000},{"_id":"themes/indigo/layout/tag.ejs","hash":"8af845cf52b6daa2068234388177679493e9a170","modified":1483504408000},{"_id":"themes/indigo/layout/tags.ejs","hash":"a737e6b74867f0dc3b26ea44b245557456835610","modified":1483504408000},{"_id":"source/images/ELK-Access-Policy.png","hash":"0bfff9db3a430a244cb9de2e932c92f246d76c49","modified":1483504408000},{"_id":"source/images/Kibana-dashboard.png","hash":"00852cbde1874f9dc047951b7d42e0e264084128","modified":1483504408000},{"_id":"source/images/NGP_Architecture.png","hash":"859db916cb0afbc416d811d3242152e13a42f714","modified":1483504408000},{"_id":"source/images/marathon-lb-timeouts.png","hash":"c9b35a7660204594ff396aca045f4f4c2c480fee","modified":1483504408000},{"_id":"source/_posts/Troubleshooting/Troubleshoot-CoreOS-in-general-which-you-will-need-in-DCOS.md","hash":"49bce501bdd8607d049b49f57c77298bde4bb16b","modified":1483504408000},{"_id":"source/_posts/Troubleshooting/Troubleshooting-common-scenarios-in-DCOS.md","hash":"2e76f6aff5a4b8b00e53945ed7f8223aec68f977","modified":1483504408000},{"_id":"source/_posts/aws-dev-tools/AwsCodebuild.md","hash":"5e8994032fa85d08c633e62584e83ede1a3d6553","modified":1483504408000},{"_id":"source/_posts/aws-dev-tools/AwsCodepipeline.md","hash":"652ae98e0829716e87b172ebf7b8d9f80565ed82","modified":1483504408000},{"_id":"source/_posts/aws-dev-tools/AwsLamda.md","hash":"869aa285a176dbc0cc2bf3917bc7061f9b5785ce","modified":1483504408000},{"_id":"source/_posts/aws-dev-tools/CI-CD-with-AWS-developer-tools.md","hash":"90262c767053226ed707af4d2c5c1d797516cf99","modified":1483504408000},{"_id":"source/_posts/aws-dev-tools/ECR.md","hash":"3f3282922d004099560bf1b8429241c44b316733","modified":1483504408000},{"_id":"source/_posts/cloudformation/CloudFormation.md","hash":"b6f608b402558f5b1b2952023eb5571a380be01a","modified":1483504580000},{"_id":"source/_posts/sysdig/Creating-alert-for-marathon-and-marathon-app-failure.md","hash":"299fa9e9f9c12c6b912e351f9c939b4559552c48","modified":1483504408000},{"_id":"source/_posts/sysdig/Creating-alert-for-marathon-lb-timeouts.md","hash":"794db1c4576b1ad9ae4b47a41f7440d4ce334d3b","modified":1483504408000},{"_id":"source/_posts/sysdig/Disk-utilization-monitoring-using-Sysdig.md","hash":"95023b32b9149f1d7e00d8df9be2ee00cd155ae3","modified":1483504408000},{"_id":"source/_posts/sysdig/Memory-utilization-monitoring-using-Sysdig.md","hash":"dec236325b4da689cb57d3ade07c5a662bc9cd6d","modified":1483504408000},{"_id":"source/_posts/sysdig/Monitoring-CPU-utilization-using-Sysdig.md","hash":"26bc3e8e6955e561edc79a570111cfb1f21df574","modified":1483504408000},{"_id":"source/_posts/projects/IaC-Manager.md","hash":"23e43396ab558904c6dfd52190882b1f3cb59825","modified":1483504408000},{"_id":"source/_posts/projects/IaC-dcos.md","hash":"f3058c9d98e8bc9ecdf65d7885b3a55cf9674c04","modified":1483504408000},{"_id":"source/_posts/projects/The-Next-Gen-Platform.md","hash":"11f21fa5cfe6ca30c9255eb4827d5acb7ff914a1","modified":1483504408000},{"_id":"source/images/Tyk-API.png","hash":"b20d17fbf63fbc9f98d4491672b5c79e9aba4bb2","modified":1483504408000},{"_id":"source/images/aws-dev-tools/code-pipeline.png","hash":"6663560186053f15089e4baadd77cf0501e40029","modified":1483504408000},{"_id":"source/images/aws-dev-tools/readme.md","hash":"1c48bb59d9f5ca86d9313075bd314296186818df","modified":1483504408000},{"_id":"source/images/cloudformation/Template_YAML.png","hash":"10b92940167ec54c84be2b184fad0aa5cd75b789","modified":1483504408000},{"_id":"source/images/sysdig/Creating-alerts-for-marathon-failure2.png","hash":"c6373a0b337232555ea0d30f839056f6ad68aee2","modified":1483504408000},{"_id":"themes/indigo/layout/_partial/after-footer.ejs","hash":"b69f253ddd4311b8c17adb4862aa5bd4e3c5c3c3","modified":1483504408000},{"_id":"themes/indigo/layout/_partial/archive.ejs","hash":"55cd81ef9183426d6d99fd91550fce0a9cc92aa0","modified":1483504408000},{"_id":"themes/indigo/layout/_partial/cnzz.ejs","hash":"03f75c55cb78686603a430fa42c63805872fb902","modified":1483504408000},{"_id":"themes/indigo/layout/_partial/footer.ejs","hash":"5ac28f60f59564584207b9a74e3e162911a6970e","modified":1483504408000},{"_id":"themes/indigo/layout/_partial/google-analytics.ejs","hash":"f921e7f9223d7c95165e0f835f353b2938e40c45","modified":1483504408000},{"_id":"themes/indigo/layout/_partial/head.ejs","hash":"a699bb1e46094d7413a9161ec4ef5ae23fdd7555","modified":1483504408000},{"_id":"themes/indigo/layout/_partial/header.ejs","hash":"c5bc369d9754b763d81a0a64657cfdef6e2fade6","modified":1483504408000},{"_id":"themes/indigo/layout/_partial/index-item.ejs","hash":"422e4d431f491b64968e668cb3df147329365a53","modified":1483504408000},{"_id":"themes/indigo/layout/_partial/loading.ejs","hash":"bc4cb19b20de55a0332647f4dca9684184383685","modified":1483504408000},{"_id":"themes/indigo/layout/_partial/mathjax.ejs","hash":"18b083b40387e544e0f6acf36260030a5d791e35","modified":1483504408000},{"_id":"themes/indigo/layout/_partial/menu.ejs","hash":"f9c2dff2fabdab0b209f026358c4b4a635a4992b","modified":1483504408000},{"_id":"themes/indigo/layout/_partial/paginator.ejs","hash":"9d739bdbbfa253745c14b48ed0a85ffa966f1c92","modified":1483504408000},{"_id":"themes/indigo/layout/_partial/post.ejs","hash":"f36f1011aa1f7d4603c018a2ed054fc3fea4c1e9","modified":1483504408000},{"_id":"themes/indigo/layout/_partial/script.ejs","hash":"c63e7c6448fc55270d1db15cea454a2fb79fe54f","modified":1483504408000},{"_id":"themes/indigo/layout/_partial/search.ejs","hash":"c2091c621b5480ef1e69d72027028cec8e929892","modified":1483504408000},{"_id":"themes/indigo/layout/_partial/tags-bar.ejs","hash":"833b979ea020a6dfee6532760de740e4dff89c64","modified":1483504408000},{"_id":"themes/indigo/source/css/style.less","hash":"8099b68dc093d9441eda47db598ad8668f7118a2","modified":1483504408000},{"_id":"themes/indigo/source/img/brand.jpg","hash":"0e237f1b433851c156e1f1cdaeb044054b3b9879","modified":1483504408000},{"_id":"themes/indigo/source/img/cc.png","hash":"ebce75a62b40976a72d43f0bd937d859ac24d87c","modified":1483504408000},{"_id":"themes/indigo/source/img/img-err.png","hash":"23a63ea26eb3c1d5e677d9883cf36cc1a1a1228b","modified":1483504408000},{"_id":"themes/indigo/source/img/img-loading.png","hash":"a9cd5cd11866824f31e3d1c5e23badfeb3f73031","modified":1483504408000},{"_id":"themes/indigo/source/js/main.js","hash":"c3fedaaed40dcc527b05cb0b0adc9af970f01cff","modified":1483504408000},{"_id":"themes/indigo/source/js/main.min.js","hash":"cce78fb5d725995f0e2211a873aab1e5a3c6bce6","modified":1483504408000},{"_id":"themes/indigo/source/js/search.js","hash":"394613237629a944beebbe5c68cf02ba24606527","modified":1483504408000},{"_id":"themes/indigo/source/js/search.min.js","hash":"c00b290823c7458e607f13fdb8ac4e95b9777784","modified":1483504408000},{"_id":"source/images/Tyk-API-Gateway.png","hash":"556c8f546f607a6b0c5a4752059b5720e3198c1c","modified":1483504408000},{"_id":"source/images/cloudformation/CloudFormation_Components.png","hash":"35c81f1f0950e20201c23f5a521093383a8725ac","modified":1483504408000},{"_id":"source/images/cloudformation/Designer.png","hash":"789e692c651d36305f2bfe70809f7512d3f4fb78","modified":1483504408000},{"_id":"source/images/cloudformation/Template1.png","hash":"93edcf6a4bfabba8ea00fb3dac21c860e10ad32a","modified":1483504408000},{"_id":"source/images/cloudformation/Template2.png","hash":"5483d137bcc8568cf82d8a6491d0693d8b4cb56b","modified":1483504408000},{"_id":"source/images/cloudformation/Template3.png","hash":"2207635229fb2fc33ee90f5118c8d4c2625b499a","modified":1483504408000},{"_id":"source/images/sysdig/Creating-an-alert-for-90-CPU-utilization.png","hash":"a63b5affbfd0c54a06020150ac35f7e0827a76e4","modified":1483504408000},{"_id":"source/images/sysdig/Memory-utilization-monitoring-using-Sysdig.png","hash":"adc1b51d5b2bf598519ab98e974436b36ccd11ca","modified":1483504408000},{"_id":"themes/indigo/source/js/embed.js","hash":"3c6a5585b46906c65c4d4c1ade6716b01476dd7b","modified":1483504408000},{"_id":"themes/indigo/source/js/embed.min.js","hash":"c2ad9ec865e531f47bb7db5cc032be44d7fe73a2","modified":1483504408000},{"_id":"source/images/aws-dev-tools/codepipeline/readme.md","hash":"a4fde0da7e0377bcb2aeef229a9eb7272e73cd80","modified":1483504408000},{"_id":"source/images/aws-dev-tools/ecr/readme.md","hash":"5b9384a3a23f1b5c89a3908befe4071e7af1d1b2","modified":1483504408000},{"_id":"source/images/sysdig/Creating-alerts-for-marathon-failure.png","hash":"6be2a409c5e44eee1f1ba8d6754aab30e83d4ee3","modified":1483504408000},{"_id":"themes/indigo/layout/_partial/post/category.ejs","hash":"c7476165721a3a5e34d00d8c5c07e1e5474cd800","modified":1483504408000},{"_id":"themes/indigo/layout/_partial/post/comment.ejs","hash":"e26a5629832507fe6354f9650845d41ebdc9801d","modified":1483504408000},{"_id":"themes/indigo/layout/_partial/post/copyright.ejs","hash":"b9715be6f3032267eecc1920e456a8e5e2b393af","modified":1483504408000},{"_id":"themes/indigo/layout/_partial/post/date.ejs","hash":"528490c368d92266b6a8ea3ecab5c0f42877bac3","modified":1483504408000},{"_id":"themes/indigo/layout/_partial/post/duoshuo.ejs","hash":"4219c1f63e72b8bae178bdb0ef3b9606a8eeb3ec","modified":1483504408000},{"_id":"themes/indigo/layout/_partial/post/edit-this-page.ejs","hash":"c46132a95f3cf8c1b6efcf93b7224ed843643e56","modified":1483504408000},{"_id":"themes/indigo/layout/_partial/post/github.ejs","hash":"60cacd0271f7dcf83b239ce3f46dad117b757506","modified":1483504408000},{"_id":"themes/indigo/layout/_partial/post/head-meta.ejs","hash":"b0c680ce5b8aaf461a6731b1ff1287bd140c168a","modified":1483504408000},{"_id":"themes/indigo/layout/_partial/post/nav.ejs","hash":"11e7d504f7c7a3c4c052da13cfa8ea4862c9383e","modified":1483504408000},{"_id":"themes/indigo/layout/_partial/post/reward-btn.ejs","hash":"be16be1f1fbed371ea304bf1a0f41e90ef902939","modified":1483504408000},{"_id":"themes/indigo/layout/_partial/post/reward.ejs","hash":"5740be5c0a282cfe488e5bc0451b091de2c98be2","modified":1483504408000},{"_id":"themes/indigo/layout/_partial/post/share-fab.ejs","hash":"35404fa3f5a0816a254c2f9610c9ac6ac16bb867","modified":1483504408000},{"_id":"themes/indigo/layout/_partial/post/share.ejs","hash":"c7cc9220ee03dc8c2817dd62ec2100b7f230ca24","modified":1483504408000},{"_id":"themes/indigo/layout/_partial/post/tag.ejs","hash":"b3dc38652c4a018a37418136478dcd522fc49f79","modified":1483504408000},{"_id":"themes/indigo/layout/_partial/post/title.ejs","hash":"062d56cb88ae2be3a6616b911d4ebeffcbfe3cff","modified":1483504408000},{"_id":"themes/indigo/layout/_partial/post/toc.ejs","hash":"b6123e895c16ace651f1832281ff655776d4068c","modified":1483504408000},{"_id":"themes/indigo/source/css/_duoshuo/common.less","hash":"93193dafee2844021f27a6c23b28264a0e288cfd","modified":1483504408000},{"_id":"themes/indigo/source/css/_duoshuo/custom.less","hash":"10c3e846afb891edf847cdc150bb842371458172","modified":1483504408000},{"_id":"themes/indigo/source/css/_duoshuo/dialog.less","hash":"d11fdc9df93da6f40b792bf7f487085136a35d58","modified":1483504408000},{"_id":"themes/indigo/source/css/_duoshuo/embed.less","hash":"a09aeb68646e6309d737dddea237a2d160608bbf","modified":1483504408000},{"_id":"themes/indigo/source/css/_duoshuo/global.less","hash":"b95ac4f80d83595186e158a05f9e5551fb199171","modified":1483504408000},{"_id":"themes/indigo/source/css/_duoshuo/login.less","hash":"6a7962f817199802f91d32d4e9bb87098683d84c","modified":1483504408000},{"_id":"themes/indigo/source/css/_duoshuo/mixins.less","hash":"caf782f681fc97ecdab34bc34e16e3353bcd1eb6","modified":1483504408000},{"_id":"themes/indigo/source/css/_duoshuo/notify.less","hash":"de48d76de6b99d7aa3f176cb1345b5bd1a6e3ec0","modified":1483504408000},{"_id":"themes/indigo/source/css/_duoshuo/recent-comments.less","hash":"1e2a57b7dc9ca3ef46d9966b49d0a8e614920c0a","modified":1483504408000},{"_id":"themes/indigo/source/css/_duoshuo/recent-visitors.less","hash":"9494e2183ce7a7a3f5742e3ba42b3514312a5006","modified":1483504408000},{"_id":"themes/indigo/source/css/_duoshuo/share.less","hash":"4218e03b97d12b006dc01c78f02f76a1e0daafb7","modified":1483504408000},{"_id":"themes/indigo/source/css/_duoshuo/thread.less","hash":"628edaf9f13877de67b9634a8cab177a8096be7f","modified":1483504408000},{"_id":"themes/indigo/source/css/_duoshuo/variables.less","hash":"5b4e813e3141d5509ee80fa319ae4cf3adfdd7da","modified":1483504408000},{"_id":"themes/indigo/source/css/_partial/archives.less","hash":"f6dc5356b94d48b99f255df5c8a47a3f9fa9a5c5","modified":1483504408000},{"_id":"themes/indigo/source/css/_partial/article.less","hash":"51a2459bc29b401ca75be991bc80eb8b367e0d45","modified":1483504408000},{"_id":"themes/indigo/source/css/_partial/edit-this-page.less","hash":"4b197181a0dc3b0fce092f6b405e94c069bb713d","modified":1483504408000},{"_id":"themes/indigo/source/css/_partial/github-buttons.less","hash":"4028e0ccedcc7e205f8252963e5f865f354c4313","modified":1483504408000},{"_id":"themes/indigo/source/css/_partial/gotop.less","hash":"b7db31b9bc563c10b9e3cf3e6d9cfddfeb3e805a","modified":1483504408000},{"_id":"themes/indigo/source/css/_partial/header.less","hash":"c9a5b4589a8f2b8845cf7726da0bd7c4b37c605e","modified":1483504408000},{"_id":"themes/indigo/source/css/_partial/highlight.less","hash":"58492b7cdb45fe09b026b2f34e8ae69c2ddb8228","modified":1483504408000},{"_id":"themes/indigo/source/css/_partial/layout.less","hash":"1ca5f796f311d24d8b8eafbe5112cd043eb48fce","modified":1483504408000},{"_id":"themes/indigo/source/css/_partial/loading.less","hash":"c32656b8d51fca9b3bfa95f1aa44b51ade203e18","modified":1483504408000},{"_id":"themes/indigo/source/css/_partial/page.less","hash":"426808b91b17471f1ff8210a0e0d7ef2925795fc","modified":1483504408000},{"_id":"themes/indigo/source/css/_partial/postlist.less","hash":"750f4bbc68c68de3e880588859ca0129edfa7dff","modified":1483504408000},{"_id":"themes/indigo/source/css/_partial/reward.less","hash":"238236c2dba0c4678271352073bbb433743357f2","modified":1483504408000},{"_id":"themes/indigo/source/css/_partial/roboto.less","hash":"2e0469ed8161d5672d903ca1a8027cd65fe007f1","modified":1483504408000},{"_id":"themes/indigo/source/css/_partial/search.less","hash":"d73a12ca56cd710a13cb61074958c82a5cb95d63","modified":1483504408000},{"_id":"themes/indigo/source/css/_partial/share.less","hash":"c65661962f6cc79aa301115593099d5557e53d10","modified":1483504408000},{"_id":"themes/indigo/source/css/_partial/tags.less","hash":"959f4373fda6e45f6a4041a995ed3ea8a05a5170","modified":1483504408000},{"_id":"themes/indigo/source/css/_partial/variable.less","hash":"6aa81b6e4c3e55c0d64bef19891726db47df8e71","modified":1483504408000},{"_id":"themes/indigo/source/css/_partial/waves.less","hash":"77bfd0b373b0469eb0176167fb076ccda4edf2a7","modified":1483504408000},{"_id":"source/images/aws-dev-tools/codepipeline/code-pipeline-step-1.png","hash":"644982c6d28035736422af12f48dc82e70eeb717","modified":1483504408000},{"_id":"source/images/aws-dev-tools/codepipeline/code-pipeline-step-2.png","hash":"285f6ce24d20b2644ba7e3bc64ed5c8a8e990b5d","modified":1483504408000},{"_id":"source/images/aws-dev-tools/codepipeline/code-pipeline-step-3.png","hash":"22c7556d6e4866652c681884d3fb252387f9c472","modified":1483504408000},{"_id":"source/images/aws-dev-tools/codepipeline/code-pipeline-step-5.png","hash":"5bc65f0058ca90c6f1f604c730d71932e211b91f","modified":1483504408000},{"_id":"source/images/aws-dev-tools/codepipeline/code-pipeline-step-7.png","hash":"103ae6f749bc65d285293382123e348f3c256337","modified":1483504408000},{"_id":"source/images/aws-dev-tools/codepipeline/code-pipeline-step-8.png","hash":"31d4f2ad65aad6fd01285902f3356f9f8751df94","modified":1483504408000},{"_id":"source/images/aws-dev-tools/codepipeline/code-pipeline-step-6.png","hash":"1115f5cfe27c2982bd480147605a2e38f035b68c","modified":1483504408000},{"_id":"source/images/aws-dev-tools/ecr/ecr-creation-step-1.png","hash":"5c451f551ef8ae12dd49b067ccd3bfa5f4270193","modified":1483504408000},{"_id":"source/images/aws-dev-tools/ecr/ecr-creation-step-2.png","hash":"1f5ef3739b64cc7f5d8b28642827693c4f647470","modified":1483504408000},{"_id":"source/images/sysdig/Creating-alert-for-disk-utilization2.png","hash":"bbd4f97b5fa4c0dfdd964b1978be47496923d2df","modified":1483504408000},{"_id":"themes/indigo/source/css/_partial/fontawesome.less","hash":"9d9b1946357a653adebc29859ad0de70adcc27dd","modified":1483504408000},{"_id":"source/images/aws-dev-tools/codepipeline/code-pipeline-step-9.png","hash":"762361582b143df57fe2655d3dfa56baf97760af","modified":1483504408000},{"_id":"source/images/sysdig/Creating-alert-for-disk-utilization.png","hash":"41d3a0a4ed0a9a2427eadbb5dbd9710522ccaaf6","modified":1483504408000},{"_id":"source/images/sysdig/Creating-alerts-for-marathon-app-failure.png","hash":"0a9e6fd2b4aecb219fec56335d0bbbdc185707ed","modified":1483504408000},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Bold.eot","hash":"a76cd602f5188b9fbd4ba7443dcb9c064e3dbf10","modified":1483504408000},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Bold.woff","hash":"ee99cd87a59a9a5d4092c83232bb3eec67547425","modified":1483504408000},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Bold.woff2","hash":"933b866d09c2b087707a98dab64b3888865eeb96","modified":1483504408000},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Light.eot","hash":"42fe156996197e5eb0c0264c5d1bb3b4681f4595","modified":1483504408000},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Light.woff","hash":"6300f659be9e834ab263efe2fb3c581d48b1e7b2","modified":1483504408000},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Light.woff2","hash":"bbdc28b887400fcb340b504ec2904993af42a5d7","modified":1483504408000},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Medium.eot","hash":"1517f4b6e1c5d0e5198f937557253aac8fab0416","modified":1483504408000},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Medium.woff","hash":"d45f84922131364989ad6578c7a06b6b4fc22c34","modified":1483504408000},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Regular.eot","hash":"77ae3e980ec03863ebe2587a8ef9ddfd06941db0","modified":1483504408000},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Medium.woff2","hash":"6cc1b73571af9e827c4e7e91418f476703cd4c4b","modified":1483504408000},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Regular.woff","hash":"74734dde8d94e7268170f9b994dedfbdcb5b3a15","modified":1483504408000},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Regular.woff2","hash":"ed1558b0541f5e01ce48c7db1588371b990eec19","modified":1483504408000},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Thin.eot","hash":"0790a51a848dbe7292c98f9d0459218bf1a8ffdd","modified":1483504408000},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Thin.woff","hash":"fbc3e71d456c96667d8082ab910e3946ef89240b","modified":1483504408000},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Thin.woff2","hash":"2449e3dac5ddb7c3da8bb07450493b62d052758c","modified":1483504408000},{"_id":"themes/indigo/source/css/fonts/fontawesome/FontAwesome.otf","hash":"1b22f17fdc38070de50e6d1ab3a32da71aa2d819","modified":1483504408000},{"_id":"themes/indigo/source/css/fonts/fontawesome/fontawesome-webfont.eot","hash":"965ce8f688fedbeed504efd498bc9c1622d12362","modified":1483504408000},{"_id":"themes/indigo/source/css/fonts/fontawesome/fontawesome-webfont.woff","hash":"6d7e6a5fc802b13694d8820fc0138037c0977d2e","modified":1483504408000},{"_id":"themes/indigo/source/css/fonts/fontawesome/fontawesome-webfont.woff2","hash":"97e438cc545714309882fbceadbf344fcaddcec5","modified":1483504408000},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Bold.ttf","hash":"47327df0f35e7cd7c8645874897a7449697544ae","modified":1483504408000},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Light.ttf","hash":"e321c183e2b75ee19813892b7bac8d7c411cb88a","modified":1483504408000},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Medium.ttf","hash":"6060ca726b9760b76f7c347dce9d2fa1fe42ec92","modified":1483504408000},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Regular.ttf","hash":"824b5480c977a8166e177e5357d13164ccc45f47","modified":1483504408000},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Thin.ttf","hash":"173ed64528b4d010a76d8d38deb1d7e7eed58eda","modified":1483504408000},{"_id":"source/images/DCOS.png","hash":"865b52cf9d1d5bfdec7d40a92e32bc576cd438e7","modified":1483504408000},{"_id":"themes/indigo/source/css/fonts/fontawesome/fontawesome-webfont.ttf","hash":"61d8d967807ef12598d81582fa95b9f600c3ee01","modified":1483504408000},{"_id":"source/images/aws-dev-tools/codepipeline/code-pipeline-step-4.png","hash":"27839987f1c0f4270c914bd89f658e12b55e26a1","modified":1483504408000},{"_id":"themes/indigo/source/css/fonts/fontawesome/fontawesome-webfont.svg","hash":"c0522272bbaef2acb3d341912754d6ea2d0ecfc0","modified":1483504408000},{"_id":"source/images/sysdig/Disk-utilization-monitoring-using-Sysdig-dashboard-tab.png","hash":"004919847867e65609dd692d834eddf51caf0d0a","modified":1483504408000},{"_id":"source/_posts/elastic-stack/Steps-to-create-elastic-stack.md","hash":"1c9595a3324876906e6b1a8a2c85c3349158d704","modified":1483526633158},{"_id":"source/_posts/elastic-stack/Steps-to-verify-elastic-stack-creation.md","hash":"c8ad7fe83a15e036f3025827641feb6836f75531","modified":1483506477069},{"_id":"source/images/elastic-stack/console-create-stack-button.png","hash":"2c0d143ab5620aa97c8e056f2bb9f9ad2e3a072f","modified":1483506457765},{"_id":"source/images/elastic-stack/console-create-stack-button1.png","hash":"8ca0573cd9f7fb7f4d608efc4dd2ee06cf684904","modified":1483506457785},{"_id":"source/images/elastic-stack/elastic-stack.png","hash":"b90bfd70e195011ac861b6629cc2ac5451e10327","modified":1483506457789},{"_id":"source/images/elastic-stack/creation-completed.png","hash":"6c20ea0fca6f02b5752976b026c2fb99b264208e","modified":1483506457789},{"_id":"source/images/elastic-stack/verify-kibana.png","hash":"af234f51134a24c39d40997846650727f179ed69","modified":1483506457797},{"_id":"source/images/elastic-stack/kibana.png","hash":"d96df46e8d5094a304355958f0f1dafb1444fc21","modified":1483506457789},{"_id":"source/images/elastic-stack/select-template.png","hash":"c03836badacf8b5fdcf7d63062f38d590edd3b85","modified":1483506457793},{"_id":"source/images/elastic-stack/parameters.png","hash":"e50a15ecc5881832c1db2596fe0131d51d96ac96","modified":1483506457793}],"Category":[{"name":"Troubleshooting","_id":"cixigfrjo000cf33pmqhtjqkm"},{"name":"sysdig","_id":"cixigfrjy000wf33p33bon66e"},{"name":"Projects","_id":"cixigfrk30017f33p4u18t3uj"},{"name":"elstic-stack","_id":"cixion04u0002wvlnuhfokrt7"}],"Data":[],"Page":[{"title":"categories","layout":"categories","comments":0,"date":"2016-11-09T12:24:44.000Z","_content":"","source":"categories/index.md","raw":"---\ntitle: categories\nlayout: categories\ncomments: false\ndate: 2016-11-09 17:54:44\n---\n","updated":"2017-01-04T04:33:28.000Z","path":"categories/index.html","_id":"cixigfriy0009f33p5bh7bkls","content":"","excerpt":"","more":""},{"title":"tags","layout":"tags","comments":0,"date":"2016-11-09T14:26:03.000Z","_content":"","source":"tags/index.md","raw":"---\ntitle: tags\nlayout: tags\ncomments: false\ndate: 2016-11-09 19:56:03\n---\n","updated":"2017-01-04T04:33:28.000Z","path":"tags/index.html","_id":"cixigfrj2000af33p7rjqff4h","content":"","excerpt":"","more":""},{"_content":"#######Use this directory for adding images for AWS Developertools\n","source":"images/aws-dev-tools/readme.md","raw":"#######Use this directory for adding images for AWS Developertools\n","date":"2017-01-04T04:33:28.000Z","updated":"2017-01-04T04:33:28.000Z","path":"images/aws-dev-tools/readme.html","title":"","comments":1,"layout":"page","_id":"cixigfrk6001hf33pwnw1g1cj","content":"<p>#######Use this directory for adding images for AWS Developertools</p>\n","excerpt":"","more":"<p>#######Use this directory for adding images for AWS Developertools</p>\n"},{"_content":"#### Add images regarding codepipeline here\n","source":"images/aws-dev-tools/codepipeline/readme.md","raw":"#### Add images regarding codepipeline here\n","date":"2017-01-04T04:33:28.000Z","updated":"2017-01-04T04:33:28.000Z","path":"images/aws-dev-tools/codepipeline/readme.html","title":"","comments":1,"layout":"page","_id":"cixigfrkl001if33pzil03plc","content":"<h4 id=\"Add-images-regarding-codepipeline-here\"><a href=\"#Add-images-regarding-codepipeline-here\" class=\"headerlink\" title=\"Add images regarding codepipeline here\"></a>Add images regarding codepipeline here</h4>","excerpt":"","more":"<h4 id=\"Add-images-regarding-codepipeline-here\"><a href=\"#Add-images-regarding-codepipeline-here\" class=\"headerlink\" title=\"Add images regarding codepipeline here\"></a>Add images regarding codepipeline here</h4>"},{"_content":"### Adding images regarding `ECR` here.\n","source":"images/aws-dev-tools/ecr/readme.md","raw":"### Adding images regarding `ECR` here.\n","date":"2017-01-04T04:33:28.000Z","updated":"2017-01-04T04:33:28.000Z","path":"images/aws-dev-tools/ecr/readme.html","title":"","comments":1,"layout":"page","_id":"cixigfrkm001jf33pw6bf78e5","content":"<h3 id=\"Adding-images-regarding-ECR-here\"><a href=\"#Adding-images-regarding-ECR-here\" class=\"headerlink\" title=\"Adding images regarding ECR here.\"></a>Adding images regarding <code>ECR</code> here.</h3>","excerpt":"","more":"<h3 id=\"Adding-images-regarding-ECR-here\"><a href=\"#Adding-images-regarding-ECR-here\" class=\"headerlink\" title=\"Adding images regarding ECR here.\"></a>Adding images regarding <code>ECR</code> here.</h3>"}],"Post":[{"title":"DCOS Disaster Recovery","date":"2016-11-03T11:37:05.000Z","_content":"\n### Marathon App Recovery\n\n#### Taking Marathon Snapshots\n\n[Marathon snapshot](https://github.com/microservices-today/IaC-marathon-snapshots) IaC is used to take snapshots of marathon applications. These snapshots are stored in a S3 bucket (Bucket name is specified while running NGP). This is performed by running a Lambda function which is periodically triggered by a CloudWatch metric. This app takes snapshots of marathon applications every hour. The IaC, also creates an AWS API gateway to trigger the Lambda function in order to restore the marathon snapshot.\n","source":"_posts/DCOS-Disaster-Recovery.md","raw":"---\ntitle: DCOS Disaster Recovery\ndate: 2016-11-03 17:07:05\ntags: DCOS Disaster Recovery\n---\n\n### Marathon App Recovery\n\n#### Taking Marathon Snapshots\n\n[Marathon snapshot](https://github.com/microservices-today/IaC-marathon-snapshots) IaC is used to take snapshots of marathon applications. These snapshots are stored in a S3 bucket (Bucket name is specified while running NGP). This is performed by running a Lambda function which is periodically triggered by a CloudWatch metric. This app takes snapshots of marathon applications every hour. The IaC, also creates an AWS API gateway to trigger the Lambda function in order to restore the marathon snapshot.\n","slug":"DCOS-Disaster-Recovery","published":1,"updated":"2017-01-04T04:33:28.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cixigfrip0000f33pv3u4r1yj","content":"<h3 id=\"Marathon-App-Recovery\"><a href=\"#Marathon-App-Recovery\" class=\"headerlink\" title=\"Marathon App Recovery\"></a>Marathon App Recovery</h3><h4 id=\"Taking-Marathon-Snapshots\"><a href=\"#Taking-Marathon-Snapshots\" class=\"headerlink\" title=\"Taking Marathon Snapshots\"></a>Taking Marathon Snapshots</h4><p><a href=\"https://github.com/microservices-today/IaC-marathon-snapshots\" target=\"_blank\" rel=\"external\">Marathon snapshot</a> IaC is used to take snapshots of marathon applications. These snapshots are stored in a S3 bucket (Bucket name is specified while running NGP). This is performed by running a Lambda function which is periodically triggered by a CloudWatch metric. This app takes snapshots of marathon applications every hour. The IaC, also creates an AWS API gateway to trigger the Lambda function in order to restore the marathon snapshot.</p>\n","excerpt":"","more":"<h3 id=\"Marathon-App-Recovery\"><a href=\"#Marathon-App-Recovery\" class=\"headerlink\" title=\"Marathon App Recovery\"></a>Marathon App Recovery</h3><h4 id=\"Taking-Marathon-Snapshots\"><a href=\"#Taking-Marathon-Snapshots\" class=\"headerlink\" title=\"Taking Marathon Snapshots\"></a>Taking Marathon Snapshots</h4><p><a href=\"https://github.com/microservices-today/IaC-marathon-snapshots\">Marathon snapshot</a> IaC is used to take snapshots of marathon applications. These snapshots are stored in a S3 bucket (Bucket name is specified while running NGP). This is performed by running a Lambda function which is periodically triggered by a CloudWatch metric. This app takes snapshots of marathon applications every hour. The IaC, also creates an AWS API gateway to trigger the Lambda function in order to restore the marathon snapshot.</p>\n"},{"title":"Debugging DCOS","date":"2016-10-31T03:39:33.000Z","_content":"### Steps - To be discussed and updated\n\nFor troubleshooting, once we ssh into the machine create a folder in `/home/core/debugging` and make sure that the backups of the configurations to be kept there.\n\nBefore closing the ssh session `history >> /home/core/debugging/history` to keep a track of the steps you have performed to troubleshoot.\n\nOnce you back into the manager:\n1. For easy troubleshooting install JQ from steps below.\n```\nwget http://stedolan.github.io/jq/download/linux64/jq \nchmod +x ./jq \ncp jq /usr/bin\n```\n\n2. To compress the debugging folder of each slaves.\n```\nfor i in $(curl -sS 10.0.3.89:5050/slaves | jq '.slaves[] | .hostname' | tr -d '\"'); do ssh \"core@$i\" \"sudo tar -zcvf debugging-$i.tar.gz debugging\"; done\n\nmkdir debugging\n\nfor i in $(curl -sS 10.0.3.89:5050/slaves | jq '.slaves[] | .hostname' | tr -d '\"'); do scp \"core@$i:/home/core/debugging-$i.tar.gz\" \"debugging/\"; done\n\ntar -zvcf debugging.tar.gz debugging\n```\n\nEither we can scp the compressed file to our local machine or push it to an s3 bucket.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/Debugging-DCOS.md","raw":"---\ntitle: Debugging DCOS\ndate: 2016-10-31 09:09:33\ntags: Debugging DCOS\n---\n### Steps - To be discussed and updated\n\nFor troubleshooting, once we ssh into the machine create a folder in `/home/core/debugging` and make sure that the backups of the configurations to be kept there.\n\nBefore closing the ssh session `history >> /home/core/debugging/history` to keep a track of the steps you have performed to troubleshoot.\n\nOnce you back into the manager:\n1. For easy troubleshooting install JQ from steps below.\n```\nwget http://stedolan.github.io/jq/download/linux64/jq \nchmod +x ./jq \ncp jq /usr/bin\n```\n\n2. To compress the debugging folder of each slaves.\n```\nfor i in $(curl -sS 10.0.3.89:5050/slaves | jq '.slaves[] | .hostname' | tr -d '\"'); do ssh \"core@$i\" \"sudo tar -zcvf debugging-$i.tar.gz debugging\"; done\n\nmkdir debugging\n\nfor i in $(curl -sS 10.0.3.89:5050/slaves | jq '.slaves[] | .hostname' | tr -d '\"'); do scp \"core@$i:/home/core/debugging-$i.tar.gz\" \"debugging/\"; done\n\ntar -zvcf debugging.tar.gz debugging\n```\n\nEither we can scp the compressed file to our local machine or push it to an s3 bucket.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","slug":"Debugging-DCOS","published":1,"updated":"2017-01-04T04:33:28.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cixigfriv0003f33po264wzc3","content":"<h3 id=\"Steps-To-be-discussed-and-updated\"><a href=\"#Steps-To-be-discussed-and-updated\" class=\"headerlink\" title=\"Steps - To be discussed and updated\"></a>Steps - To be discussed and updated</h3><p>For troubleshooting, once we ssh into the machine create a folder in <code>/home/core/debugging</code> and make sure that the backups of the configurations to be kept there.</p>\n<p>Before closing the ssh session <code>history &gt;&gt; /home/core/debugging/history</code> to keep a track of the steps you have performed to troubleshoot.</p>\n<p>Once you back into the manager:</p>\n<ol>\n<li><p>For easy troubleshooting install JQ from steps below.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">wget http://stedolan.github.io/jq/download/linux64/jq </div><div class=\"line\">chmod +x ./jq </div><div class=\"line\">cp jq /usr/bin</div></pre></td></tr></table></figure>\n</li>\n<li><p>To compress the debugging folder of each slaves.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">for i in $(curl -sS 10.0.3.89:5050/slaves | jq &apos;.slaves[] | .hostname&apos; | tr -d &apos;&quot;&apos;); do ssh &quot;core@$i&quot; &quot;sudo tar -zcvf debugging-$i.tar.gz debugging&quot;; done</div><div class=\"line\"></div><div class=\"line\">mkdir debugging</div><div class=\"line\"></div><div class=\"line\">for i in $(curl -sS 10.0.3.89:5050/slaves | jq &apos;.slaves[] | .hostname&apos; | tr -d &apos;&quot;&apos;); do scp &quot;core@$i:/home/core/debugging-$i.tar.gz&quot; &quot;debugging/&quot;; done</div><div class=\"line\"></div><div class=\"line\">tar -zvcf debugging.tar.gz debugging</div></pre></td></tr></table></figure>\n</li>\n</ol>\n<p>Either we can scp the compressed file to our local machine or push it to an s3 bucket.</p>\n","excerpt":"","more":"<h3 id=\"Steps-To-be-discussed-and-updated\"><a href=\"#Steps-To-be-discussed-and-updated\" class=\"headerlink\" title=\"Steps - To be discussed and updated\"></a>Steps - To be discussed and updated</h3><p>For troubleshooting, once we ssh into the machine create a folder in <code>/home/core/debugging</code> and make sure that the backups of the configurations to be kept there.</p>\n<p>Before closing the ssh session <code>history &gt;&gt; /home/core/debugging/history</code> to keep a track of the steps you have performed to troubleshoot.</p>\n<p>Once you back into the manager:</p>\n<ol>\n<li><p>For easy troubleshooting install JQ from steps below.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">wget http://stedolan.github.io/jq/download/linux64/jq </div><div class=\"line\">chmod +x ./jq </div><div class=\"line\">cp jq /usr/bin</div></pre></td></tr></table></figure>\n</li>\n<li><p>To compress the debugging folder of each slaves.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">for i in $(curl -sS 10.0.3.89:5050/slaves | jq &apos;.slaves[] | .hostname&apos; | tr -d &apos;&quot;&apos;); do ssh &quot;core@$i&quot; &quot;sudo tar -zcvf debugging-$i.tar.gz debugging&quot;; done</div><div class=\"line\"></div><div class=\"line\">mkdir debugging</div><div class=\"line\"></div><div class=\"line\">for i in $(curl -sS 10.0.3.89:5050/slaves | jq &apos;.slaves[] | .hostname&apos; | tr -d &apos;&quot;&apos;); do scp &quot;core@$i:/home/core/debugging-$i.tar.gz&quot; &quot;debugging/&quot;; done</div><div class=\"line\"></div><div class=\"line\">tar -zvcf debugging.tar.gz debugging</div></pre></td></tr></table></figure>\n</li>\n</ol>\n<p>Either we can scp the compressed file to our local machine or push it to an s3 bucket.</p>\n"},{"title":"Nginx Marathon App example","date":"2016-10-28T09:15:38.000Z","_content":"Here is an example how to run Nginx Marathon App in DCOS with [VIP](https://docs.mesosphere.com/1.8/usage/service-discovery/load-balancing-vips/virtual-ip-addresses/): \n\n```\n{\n  \"id\": \"nginx\",\n  \"cmd\": null,\n  \"cpus\": 1,\n  \"mem\": 128,\n  \"disk\": 0,\n  \"instances\": 1,\n  \"container\": {\n    \"docker\": {\n      \"image\": \"nginx\",\n      \"network\": \"BRIDGE\",\n      \"portMappings\": [\n        {\n          \"containerPort\": 80,\n          \"protocol\": \"tcp\",\n          \"name\": null,\n          \"labels\": {\n            \"VIP_0\": \"1.1.1.4:8000\"\n          }\n        }\n      ]\n    },\n    \"type\": \"DOCKER\",\n    \"volumes\": []\n  },\n  \"env\": {},\n  \"labels\": {\n    \"HAPROXY_GROUP\": \"external\"\n  },\n  \"healthChecks\": []\n}\n```\n","source":"_posts/Nginx-Marathon-App-example.md","raw":"---\ntitle: Nginx Marathon App example\ndate: 2016-10-28 14:45:38\ntags: Nginx Marathon App example\n---\nHere is an example how to run Nginx Marathon App in DCOS with [VIP](https://docs.mesosphere.com/1.8/usage/service-discovery/load-balancing-vips/virtual-ip-addresses/): \n\n```\n{\n  \"id\": \"nginx\",\n  \"cmd\": null,\n  \"cpus\": 1,\n  \"mem\": 128,\n  \"disk\": 0,\n  \"instances\": 1,\n  \"container\": {\n    \"docker\": {\n      \"image\": \"nginx\",\n      \"network\": \"BRIDGE\",\n      \"portMappings\": [\n        {\n          \"containerPort\": 80,\n          \"protocol\": \"tcp\",\n          \"name\": null,\n          \"labels\": {\n            \"VIP_0\": \"1.1.1.4:8000\"\n          }\n        }\n      ]\n    },\n    \"type\": \"DOCKER\",\n    \"volumes\": []\n  },\n  \"env\": {},\n  \"labels\": {\n    \"HAPROXY_GROUP\": \"external\"\n  },\n  \"healthChecks\": []\n}\n```\n","slug":"Nginx-Marathon-App-example","published":1,"updated":"2017-01-04T04:33:28.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cixigfriw0006f33p0plx9dup","content":"<p>Here is an example how to run Nginx Marathon App in DCOS with <a href=\"https://docs.mesosphere.com/1.8/usage/service-discovery/load-balancing-vips/virtual-ip-addresses/\" target=\"_blank\" rel=\"external\">VIP</a>: </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div></pre></td><td class=\"code\"><pre><div class=\"line\">&#123;</div><div class=\"line\">  &quot;id&quot;: &quot;nginx&quot;,</div><div class=\"line\">  &quot;cmd&quot;: null,</div><div class=\"line\">  &quot;cpus&quot;: 1,</div><div class=\"line\">  &quot;mem&quot;: 128,</div><div class=\"line\">  &quot;disk&quot;: 0,</div><div class=\"line\">  &quot;instances&quot;: 1,</div><div class=\"line\">  &quot;container&quot;: &#123;</div><div class=\"line\">    &quot;docker&quot;: &#123;</div><div class=\"line\">      &quot;image&quot;: &quot;nginx&quot;,</div><div class=\"line\">      &quot;network&quot;: &quot;BRIDGE&quot;,</div><div class=\"line\">      &quot;portMappings&quot;: [</div><div class=\"line\">        &#123;</div><div class=\"line\">          &quot;containerPort&quot;: 80,</div><div class=\"line\">          &quot;protocol&quot;: &quot;tcp&quot;,</div><div class=\"line\">          &quot;name&quot;: null,</div><div class=\"line\">          &quot;labels&quot;: &#123;</div><div class=\"line\">            &quot;VIP_0&quot;: &quot;1.1.1.4:8000&quot;</div><div class=\"line\">          &#125;</div><div class=\"line\">        &#125;</div><div class=\"line\">      ]</div><div class=\"line\">    &#125;,</div><div class=\"line\">    &quot;type&quot;: &quot;DOCKER&quot;,</div><div class=\"line\">    &quot;volumes&quot;: []</div><div class=\"line\">  &#125;,</div><div class=\"line\">  &quot;env&quot;: &#123;&#125;,</div><div class=\"line\">  &quot;labels&quot;: &#123;</div><div class=\"line\">    &quot;HAPROXY_GROUP&quot;: &quot;external&quot;</div><div class=\"line\">  &#125;,</div><div class=\"line\">  &quot;healthChecks&quot;: []</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n","excerpt":"","more":"<p>Here is an example how to run Nginx Marathon App in DCOS with <a href=\"https://docs.mesosphere.com/1.8/usage/service-discovery/load-balancing-vips/virtual-ip-addresses/\">VIP</a>: </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div></pre></td><td class=\"code\"><pre><div class=\"line\">&#123;</div><div class=\"line\">  &quot;id&quot;: &quot;nginx&quot;,</div><div class=\"line\">  &quot;cmd&quot;: null,</div><div class=\"line\">  &quot;cpus&quot;: 1,</div><div class=\"line\">  &quot;mem&quot;: 128,</div><div class=\"line\">  &quot;disk&quot;: 0,</div><div class=\"line\">  &quot;instances&quot;: 1,</div><div class=\"line\">  &quot;container&quot;: &#123;</div><div class=\"line\">    &quot;docker&quot;: &#123;</div><div class=\"line\">      &quot;image&quot;: &quot;nginx&quot;,</div><div class=\"line\">      &quot;network&quot;: &quot;BRIDGE&quot;,</div><div class=\"line\">      &quot;portMappings&quot;: [</div><div class=\"line\">        &#123;</div><div class=\"line\">          &quot;containerPort&quot;: 80,</div><div class=\"line\">          &quot;protocol&quot;: &quot;tcp&quot;,</div><div class=\"line\">          &quot;name&quot;: null,</div><div class=\"line\">          &quot;labels&quot;: &#123;</div><div class=\"line\">            &quot;VIP_0&quot;: &quot;1.1.1.4:8000&quot;</div><div class=\"line\">          &#125;</div><div class=\"line\">        &#125;</div><div class=\"line\">      ]</div><div class=\"line\">    &#125;,</div><div class=\"line\">    &quot;type&quot;: &quot;DOCKER&quot;,</div><div class=\"line\">    &quot;volumes&quot;: []</div><div class=\"line\">  &#125;,</div><div class=\"line\">  &quot;env&quot;: &#123;&#125;,</div><div class=\"line\">  &quot;labels&quot;: &#123;</div><div class=\"line\">    &quot;HAPROXY_GROUP&quot;: &quot;external&quot;</div><div class=\"line\">  &#125;,</div><div class=\"line\">  &quot;healthChecks&quot;: []</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n"},{"title":"Troubleshoot CoreOS in general which you will need in DCOS","date":"2016-10-30T03:37:29.000Z","_content":"These are supposed to be the steps followed to troubleshoot CoreOS in general.\n\n`ssh` into the machine and check for initial login warnings.\n\n`systemctl status`, this will list out the status of different services.\n\n`systemctl list-units`, this will list the services with their status\n\n`systemctl status name.service`, to find out the status of individual services.\n\n`journalctl -u name.service`, to list out the logs of service.\n\nYou can use various journalctl parameter combination to fetch the logs of different time.\n\n\n### Systemctl Cheatsheet\n\n```\nsudo systemctl start application.service\nsudo systemctl stop application.service\nsudo systemctl restart application.service\nsudo systemctl reload application.service\nsudo systemctl reload-or-restart application.service\nsudo systemctl enable application.service\nsudo systemctl disable application.service\nsudo systemctl status application.service\nsudo systemctl try-restart application.service\n```\n\n[Journalctl Cheatsheet](https://www.digitalocean.com/community/tutorials/how-to-use-journalctl-to-view-and-manipulate-systemd-logs)\n","source":"_posts/Troubleshooting/Troubleshoot-CoreOS-in-general-which-you-will-need-in-DCOS.md","raw":"---\ntitle: Troubleshoot CoreOS in general which you will need in DCOS\ndate: 2016-10-30 09:07:29\ntags: Troubleshoot CoreOS in DCOS\ncategories: Troubleshooting\n---\nThese are supposed to be the steps followed to troubleshoot CoreOS in general.\n\n`ssh` into the machine and check for initial login warnings.\n\n`systemctl status`, this will list out the status of different services.\n\n`systemctl list-units`, this will list the services with their status\n\n`systemctl status name.service`, to find out the status of individual services.\n\n`journalctl -u name.service`, to list out the logs of service.\n\nYou can use various journalctl parameter combination to fetch the logs of different time.\n\n\n### Systemctl Cheatsheet\n\n```\nsudo systemctl start application.service\nsudo systemctl stop application.service\nsudo systemctl restart application.service\nsudo systemctl reload application.service\nsudo systemctl reload-or-restart application.service\nsudo systemctl enable application.service\nsudo systemctl disable application.service\nsudo systemctl status application.service\nsudo systemctl try-restart application.service\n```\n\n[Journalctl Cheatsheet](https://www.digitalocean.com/community/tutorials/how-to-use-journalctl-to-view-and-manipulate-systemd-logs)\n","slug":"Troubleshooting/Troubleshoot-CoreOS-in-general-which-you-will-need-in-DCOS","published":1,"updated":"2017-01-04T04:33:28.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cixigfrjn000bf33p6ps0t6py","content":"<p>These are supposed to be the steps followed to troubleshoot CoreOS in general.</p>\n<p><code>ssh</code> into the machine and check for initial login warnings.</p>\n<p><code>systemctl status</code>, this will list out the status of different services.</p>\n<p><code>systemctl list-units</code>, this will list the services with their status</p>\n<p><code>systemctl status name.service</code>, to find out the status of individual services.</p>\n<p><code>journalctl -u name.service</code>, to list out the logs of service.</p>\n<p>You can use various journalctl parameter combination to fetch the logs of different time.</p>\n<h3 id=\"Systemctl-Cheatsheet\"><a href=\"#Systemctl-Cheatsheet\" class=\"headerlink\" title=\"Systemctl Cheatsheet\"></a>Systemctl Cheatsheet</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo systemctl start application.service</div><div class=\"line\">sudo systemctl stop application.service</div><div class=\"line\">sudo systemctl restart application.service</div><div class=\"line\">sudo systemctl reload application.service</div><div class=\"line\">sudo systemctl reload-or-restart application.service</div><div class=\"line\">sudo systemctl enable application.service</div><div class=\"line\">sudo systemctl disable application.service</div><div class=\"line\">sudo systemctl status application.service</div><div class=\"line\">sudo systemctl try-restart application.service</div></pre></td></tr></table></figure>\n<p><a href=\"https://www.digitalocean.com/community/tutorials/how-to-use-journalctl-to-view-and-manipulate-systemd-logs\" target=\"_blank\" rel=\"external\">Journalctl Cheatsheet</a></p>\n","excerpt":"","more":"<p>These are supposed to be the steps followed to troubleshoot CoreOS in general.</p>\n<p><code>ssh</code> into the machine and check for initial login warnings.</p>\n<p><code>systemctl status</code>, this will list out the status of different services.</p>\n<p><code>systemctl list-units</code>, this will list the services with their status</p>\n<p><code>systemctl status name.service</code>, to find out the status of individual services.</p>\n<p><code>journalctl -u name.service</code>, to list out the logs of service.</p>\n<p>You can use various journalctl parameter combination to fetch the logs of different time.</p>\n<h3 id=\"Systemctl-Cheatsheet\"><a href=\"#Systemctl-Cheatsheet\" class=\"headerlink\" title=\"Systemctl Cheatsheet\"></a>Systemctl Cheatsheet</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo systemctl start application.service</div><div class=\"line\">sudo systemctl stop application.service</div><div class=\"line\">sudo systemctl restart application.service</div><div class=\"line\">sudo systemctl reload application.service</div><div class=\"line\">sudo systemctl reload-or-restart application.service</div><div class=\"line\">sudo systemctl enable application.service</div><div class=\"line\">sudo systemctl disable application.service</div><div class=\"line\">sudo systemctl status application.service</div><div class=\"line\">sudo systemctl try-restart application.service</div></pre></td></tr></table></figure>\n<p><a href=\"https://www.digitalocean.com/community/tutorials/how-to-use-journalctl-to-view-and-manipulate-systemd-logs\">Journalctl Cheatsheet</a></p>\n"},{"title":"Troubleshooting common scenarios in DCOS","date":"2016-10-29T10:20:49.000Z","_content":"\nThis doc contains information on how to troubleshoot common scenarios.\n\n### Disk space issue\nThe instance running dcos might get filled up and dcos can fail. \nThis can lead to unhealthy agents which may not respond to the Mesos. \nFollow the steps below to troubleshoot the scenario.\n\nIf able to identify the source of high disk space, \ntry to do the cleanup and bring back the disk space. \nIf there is a failure/bad configuration with docker, \nthe `/var/lib/docker/overlay` folder can get used up. \n1. If able to identify the docker we can stop the container and it is not advised to delete the instance.\n2. Disk space used by jenkins containers. \nWe have had scenarios where the jenkins backup getting accumulated and using up the space. \nStopping the backup plugin and deleting the backup from the container can resolve the issue.\n3. If the above scenarios and scenario does not help, \nwe can stop the instance from the console and wait for the auto scaling configuration to bring up new agents.\n\n### IPTables blocking marathon-lb ports\nThis is where the `iptables` of the instances are setup to block the ports of marathon-lb and resulting timeouts.\nYou can use the below scripts to backup and flush the `iptables`.\n\n```\nfor i in $(curl -sS leader-ip:5050/slaves | jq '.slaves[] | .hostname' | tr -d '\"'); do ssh \"core@$i\" \"mkdir -p debugging && sudo iptables-save >> debugging/iptables-backup && sudo iptables -F\"; done\n```\n\n### Marathon service down\nThis scenario occurs when the marathon service running in one of the masters fails and does not restart on its own.\n\n```\njournalctl  -u dcos-marathon.service\nsystemctl try-restart dcos-marathon.service\n```\n\n\n\n\n","source":"_posts/Troubleshooting/Troubleshooting-common-scenarios-in-DCOS.md","raw":"---\ntitle: Troubleshooting common scenarios in DCOS\ndate: 2016-10-29 15:50:49\ntags: Troubleshooting common scenarios in DCOS\ncategories: Troubleshooting\n---\n\nThis doc contains information on how to troubleshoot common scenarios.\n\n### Disk space issue\nThe instance running dcos might get filled up and dcos can fail. \nThis can lead to unhealthy agents which may not respond to the Mesos. \nFollow the steps below to troubleshoot the scenario.\n\nIf able to identify the source of high disk space, \ntry to do the cleanup and bring back the disk space. \nIf there is a failure/bad configuration with docker, \nthe `/var/lib/docker/overlay` folder can get used up. \n1. If able to identify the docker we can stop the container and it is not advised to delete the instance.\n2. Disk space used by jenkins containers. \nWe have had scenarios where the jenkins backup getting accumulated and using up the space. \nStopping the backup plugin and deleting the backup from the container can resolve the issue.\n3. If the above scenarios and scenario does not help, \nwe can stop the instance from the console and wait for the auto scaling configuration to bring up new agents.\n\n### IPTables blocking marathon-lb ports\nThis is where the `iptables` of the instances are setup to block the ports of marathon-lb and resulting timeouts.\nYou can use the below scripts to backup and flush the `iptables`.\n\n```\nfor i in $(curl -sS leader-ip:5050/slaves | jq '.slaves[] | .hostname' | tr -d '\"'); do ssh \"core@$i\" \"mkdir -p debugging && sudo iptables-save >> debugging/iptables-backup && sudo iptables -F\"; done\n```\n\n### Marathon service down\nThis scenario occurs when the marathon service running in one of the masters fails and does not restart on its own.\n\n```\njournalctl  -u dcos-marathon.service\nsystemctl try-restart dcos-marathon.service\n```\n\n\n\n\n","slug":"Troubleshooting/Troubleshooting-common-scenarios-in-DCOS","published":1,"updated":"2017-01-04T04:33:28.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cixigfrjp000gf33phjji6s8d","content":"<p>This doc contains information on how to troubleshoot common scenarios.</p>\n<h3 id=\"Disk-space-issue\"><a href=\"#Disk-space-issue\" class=\"headerlink\" title=\"Disk space issue\"></a>Disk space issue</h3><p>The instance running dcos might get filled up and dcos can fail.<br>This can lead to unhealthy agents which may not respond to the Mesos.<br>Follow the steps below to troubleshoot the scenario.</p>\n<p>If able to identify the source of high disk space,<br>try to do the cleanup and bring back the disk space.<br>If there is a failure/bad configuration with docker,<br>the <code>/var/lib/docker/overlay</code> folder can get used up. </p>\n<ol>\n<li>If able to identify the docker we can stop the container and it is not advised to delete the instance.</li>\n<li>Disk space used by jenkins containers.<br>We have had scenarios where the jenkins backup getting accumulated and using up the space.<br>Stopping the backup plugin and deleting the backup from the container can resolve the issue.</li>\n<li>If the above scenarios and scenario does not help,<br>we can stop the instance from the console and wait for the auto scaling configuration to bring up new agents.</li>\n</ol>\n<h3 id=\"IPTables-blocking-marathon-lb-ports\"><a href=\"#IPTables-blocking-marathon-lb-ports\" class=\"headerlink\" title=\"IPTables blocking marathon-lb ports\"></a>IPTables blocking marathon-lb ports</h3><p>This is where the <code>iptables</code> of the instances are setup to block the ports of marathon-lb and resulting timeouts.<br>You can use the below scripts to backup and flush the <code>iptables</code>.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">for i in $(curl -sS leader-ip:5050/slaves | jq &apos;.slaves[] | .hostname&apos; | tr -d &apos;&quot;&apos;); do ssh &quot;core@$i&quot; &quot;mkdir -p debugging &amp;&amp; sudo iptables-save &gt;&gt; debugging/iptables-backup &amp;&amp; sudo iptables -F&quot;; done</div></pre></td></tr></table></figure>\n<h3 id=\"Marathon-service-down\"><a href=\"#Marathon-service-down\" class=\"headerlink\" title=\"Marathon service down\"></a>Marathon service down</h3><p>This scenario occurs when the marathon service running in one of the masters fails and does not restart on its own.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">journalctl  -u dcos-marathon.service</div><div class=\"line\">systemctl try-restart dcos-marathon.service</div></pre></td></tr></table></figure>\n","excerpt":"","more":"<p>This doc contains information on how to troubleshoot common scenarios.</p>\n<h3 id=\"Disk-space-issue\"><a href=\"#Disk-space-issue\" class=\"headerlink\" title=\"Disk space issue\"></a>Disk space issue</h3><p>The instance running dcos might get filled up and dcos can fail.<br>This can lead to unhealthy agents which may not respond to the Mesos.<br>Follow the steps below to troubleshoot the scenario.</p>\n<p>If able to identify the source of high disk space,<br>try to do the cleanup and bring back the disk space.<br>If there is a failure/bad configuration with docker,<br>the <code>/var/lib/docker/overlay</code> folder can get used up. </p>\n<ol>\n<li>If able to identify the docker we can stop the container and it is not advised to delete the instance.</li>\n<li>Disk space used by jenkins containers.<br>We have had scenarios where the jenkins backup getting accumulated and using up the space.<br>Stopping the backup plugin and deleting the backup from the container can resolve the issue.</li>\n<li>If the above scenarios and scenario does not help,<br>we can stop the instance from the console and wait for the auto scaling configuration to bring up new agents.</li>\n</ol>\n<h3 id=\"IPTables-blocking-marathon-lb-ports\"><a href=\"#IPTables-blocking-marathon-lb-ports\" class=\"headerlink\" title=\"IPTables blocking marathon-lb ports\"></a>IPTables blocking marathon-lb ports</h3><p>This is where the <code>iptables</code> of the instances are setup to block the ports of marathon-lb and resulting timeouts.<br>You can use the below scripts to backup and flush the <code>iptables</code>.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">for i in $(curl -sS leader-ip:5050/slaves | jq &apos;.slaves[] | .hostname&apos; | tr -d &apos;&quot;&apos;); do ssh &quot;core@$i&quot; &quot;mkdir -p debugging &amp;&amp; sudo iptables-save &gt;&gt; debugging/iptables-backup &amp;&amp; sudo iptables -F&quot;; done</div></pre></td></tr></table></figure>\n<h3 id=\"Marathon-service-down\"><a href=\"#Marathon-service-down\" class=\"headerlink\" title=\"Marathon service down\"></a>Marathon service down</h3><p>This scenario occurs when the marathon service running in one of the masters fails and does not restart on its own.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">journalctl  -u dcos-marathon.service</div><div class=\"line\">systemctl try-restart dcos-marathon.service</div></pre></td></tr></table></figure>\n"},{"title":"AWS CodeBuild","date":"2016-12-21T09:15:38.000Z","_content":"#### The following steps can be used to prepare the Github to be added to the codebuild.\n\n1. The codebuild looks for `buildspec.yml` in root of the repository. It contains the actions that are to be performed by the   Codebuild. We can add `buildspec.yml` to the github repository.\n  ```\n  version: 0.1\n\n  phases:\n    build:\n      commands:\n        - git ls-remote https://${GITHUB_TOKEN}@github.com/microservices-today/*****.git HEAD | awk '{ print $1;}' > master.commit\n        - docker build -t $ECR_REPO:$(cat ./master.commit) .\n        - sed -i \"s@DOCKER_URI@${ECR_REPO}:$(cat ./master.commit)@g\" task-definition.json\n        - sed -i \"s@ECS_CLUSTER_NAME@${ECS_CLUSTER_NAME}@g\" service-definition.json\n        - sed -i \"s@TARGET_GROUP_ARN@${TARGET_GROUP_ARN}@g\" service-definition.json\n        - sed -i \"s@ECS_SERVICE_ROLE@${ECS_SERVICE_ROLE}@g\" service-definition.json\n    post_build:\n      commands:\n        - $(aws ecr get-login --region $AWS_REGION)\n        - docker push $ECR_REPO:$(cat ./master.commit)\n  artifacts:\n    files:\n      - task-definition.json\n      - service-definition.json\n      - master.commit\n  ```\n  Replace the `https://github.com/***********.git` from the buildspec.yml with current github URL.\n\n2. Add the service-definition.json and task-definition.json for ECR.\n  #### `task-definition.json`\n  ```\n  {\n      \"family\": \"sample-app-name\",\n      \"containerDefinitions\": [\n          {\n              \"environment\": [],\n              \"name\": \"sample-app-name\",\n              \"image\": \"DOCKER_URI\",\n              \"cpu\": 10,\n              \"memory\": 500,\n              \"portMappings\": [\n                  {\n                      \"containerPort\": 80,\n                      \"hostPort\": 80\n                  }\n              ]\n          }\n      ]\n  }\n  ```\n  #### `service-definition.json`\n  ```\n  {\n    \"serviceName\": \"sample-app-name\",\n    \"taskDefinition\": \"sample-app-name\",\n    \"cluster\": \"ECS_CLUSTER_NAME\",\n    \"desiredCount\":2,\n    \"loadBalancers\": [\n       {\n      \"containerName\": \"sample-app-name\", \n      \"containerPort\": 80, \n      \"targetGroupArn\": \"TARGET_GROUP_ARN\"\n     }\n    ],\n    \"role\": \"ECS_SERVICE_ROLE\"\n  }\n  ```\n  replace the `sample-app-name` with appropriate name in both `service-definition.json` and `task-definition.json`.\n","source":"_posts/aws-dev-tools/AwsCodebuild.md","raw":"---\ntitle: AWS CodeBuild\ndate: 2016-12-21 14:45:38\ntags: AWS Developer tools\n---\n#### The following steps can be used to prepare the Github to be added to the codebuild.\n\n1. The codebuild looks for `buildspec.yml` in root of the repository. It contains the actions that are to be performed by the   Codebuild. We can add `buildspec.yml` to the github repository.\n  ```\n  version: 0.1\n\n  phases:\n    build:\n      commands:\n        - git ls-remote https://${GITHUB_TOKEN}@github.com/microservices-today/*****.git HEAD | awk '{ print $1;}' > master.commit\n        - docker build -t $ECR_REPO:$(cat ./master.commit) .\n        - sed -i \"s@DOCKER_URI@${ECR_REPO}:$(cat ./master.commit)@g\" task-definition.json\n        - sed -i \"s@ECS_CLUSTER_NAME@${ECS_CLUSTER_NAME}@g\" service-definition.json\n        - sed -i \"s@TARGET_GROUP_ARN@${TARGET_GROUP_ARN}@g\" service-definition.json\n        - sed -i \"s@ECS_SERVICE_ROLE@${ECS_SERVICE_ROLE}@g\" service-definition.json\n    post_build:\n      commands:\n        - $(aws ecr get-login --region $AWS_REGION)\n        - docker push $ECR_REPO:$(cat ./master.commit)\n  artifacts:\n    files:\n      - task-definition.json\n      - service-definition.json\n      - master.commit\n  ```\n  Replace the `https://github.com/***********.git` from the buildspec.yml with current github URL.\n\n2. Add the service-definition.json and task-definition.json for ECR.\n  #### `task-definition.json`\n  ```\n  {\n      \"family\": \"sample-app-name\",\n      \"containerDefinitions\": [\n          {\n              \"environment\": [],\n              \"name\": \"sample-app-name\",\n              \"image\": \"DOCKER_URI\",\n              \"cpu\": 10,\n              \"memory\": 500,\n              \"portMappings\": [\n                  {\n                      \"containerPort\": 80,\n                      \"hostPort\": 80\n                  }\n              ]\n          }\n      ]\n  }\n  ```\n  #### `service-definition.json`\n  ```\n  {\n    \"serviceName\": \"sample-app-name\",\n    \"taskDefinition\": \"sample-app-name\",\n    \"cluster\": \"ECS_CLUSTER_NAME\",\n    \"desiredCount\":2,\n    \"loadBalancers\": [\n       {\n      \"containerName\": \"sample-app-name\", \n      \"containerPort\": 80, \n      \"targetGroupArn\": \"TARGET_GROUP_ARN\"\n     }\n    ],\n    \"role\": \"ECS_SERVICE_ROLE\"\n  }\n  ```\n  replace the `sample-app-name` with appropriate name in both `service-definition.json` and `task-definition.json`.\n","slug":"aws-dev-tools/AwsCodebuild","published":1,"updated":"2017-01-04T04:33:28.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cixigfrjq000kf33pf6h8yxmt","content":"<h4 id=\"The-following-steps-can-be-used-to-prepare-the-Github-to-be-added-to-the-codebuild\"><a href=\"#The-following-steps-can-be-used-to-prepare-the-Github-to-be-added-to-the-codebuild\" class=\"headerlink\" title=\"The following steps can be used to prepare the Github to be added to the codebuild.\"></a>The following steps can be used to prepare the Github to be added to the codebuild.</h4><ol>\n<li><p>The codebuild looks for <code>buildspec.yml</code> in root of the repository. It contains the actions that are to be performed by the   Codebuild. We can add <code>buildspec.yml</code> to the github repository.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div></pre></td><td class=\"code\"><pre><div class=\"line\">version: 0.1</div><div class=\"line\"></div><div class=\"line\">phases:</div><div class=\"line\">  build:</div><div class=\"line\">    commands:</div><div class=\"line\">      - git ls-remote https://$&#123;GITHUB_TOKEN&#125;@github.com/microservices-today/*****.git HEAD | awk &apos;&#123; print $1;&#125;&apos; &gt; master.commit</div><div class=\"line\">      - docker build -t $ECR_REPO:$(cat ./master.commit) .</div><div class=\"line\">      - sed -i &quot;s@DOCKER_URI@$&#123;ECR_REPO&#125;:$(cat ./master.commit)@g&quot; task-definition.json</div><div class=\"line\">      - sed -i &quot;s@ECS_CLUSTER_NAME@$&#123;ECS_CLUSTER_NAME&#125;@g&quot; service-definition.json</div><div class=\"line\">      - sed -i &quot;s@TARGET_GROUP_ARN@$&#123;TARGET_GROUP_ARN&#125;@g&quot; service-definition.json</div><div class=\"line\">      - sed -i &quot;s@ECS_SERVICE_ROLE@$&#123;ECS_SERVICE_ROLE&#125;@g&quot; service-definition.json</div><div class=\"line\">  post_build:</div><div class=\"line\">    commands:</div><div class=\"line\">      - $(aws ecr get-login --region $AWS_REGION)</div><div class=\"line\">      - docker push $ECR_REPO:$(cat ./master.commit)</div><div class=\"line\">artifacts:</div><div class=\"line\">  files:</div><div class=\"line\">    - task-definition.json</div><div class=\"line\">    - service-definition.json</div><div class=\"line\">    - master.commit</div></pre></td></tr></table></figure>\n<p>Replace the <code>https://github.com/***********.git</code> from the buildspec.yml with current github URL.</p>\n</li>\n<li><p>Add the service-definition.json and task-definition.json for ECR.</p>\n<h4 id=\"task-definition-json\"><a href=\"#task-definition-json\" class=\"headerlink\" title=\"task-definition.json\"></a><code>task-definition.json</code></h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div></pre></td><td class=\"code\"><pre><div class=\"line\">&#123;</div><div class=\"line\">    &quot;family&quot;: &quot;sample-app-name&quot;,</div><div class=\"line\">    &quot;containerDefinitions&quot;: [</div><div class=\"line\">        &#123;</div><div class=\"line\">            &quot;environment&quot;: [],</div><div class=\"line\">            &quot;name&quot;: &quot;sample-app-name&quot;,</div><div class=\"line\">            &quot;image&quot;: &quot;DOCKER_URI&quot;,</div><div class=\"line\">            &quot;cpu&quot;: 10,</div><div class=\"line\">            &quot;memory&quot;: 500,</div><div class=\"line\">            &quot;portMappings&quot;: [</div><div class=\"line\">                &#123;</div><div class=\"line\">                    &quot;containerPort&quot;: 80,</div><div class=\"line\">                    &quot;hostPort&quot;: 80</div><div class=\"line\">                &#125;</div><div class=\"line\">            ]</div><div class=\"line\">        &#125;</div><div class=\"line\">    ]</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<h4 id=\"service-definition-json\"><a href=\"#service-definition-json\" class=\"headerlink\" title=\"service-definition.json\"></a><code>service-definition.json</code></h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div></pre></td><td class=\"code\"><pre><div class=\"line\">&#123;</div><div class=\"line\">  &quot;serviceName&quot;: &quot;sample-app-name&quot;,</div><div class=\"line\">  &quot;taskDefinition&quot;: &quot;sample-app-name&quot;,</div><div class=\"line\">  &quot;cluster&quot;: &quot;ECS_CLUSTER_NAME&quot;,</div><div class=\"line\">  &quot;desiredCount&quot;:2,</div><div class=\"line\">  &quot;loadBalancers&quot;: [</div><div class=\"line\">     &#123;</div><div class=\"line\">    &quot;containerName&quot;: &quot;sample-app-name&quot;, </div><div class=\"line\">    &quot;containerPort&quot;: 80, </div><div class=\"line\">    &quot;targetGroupArn&quot;: &quot;TARGET_GROUP_ARN&quot;</div><div class=\"line\">   &#125;</div><div class=\"line\">  ],</div><div class=\"line\">  &quot;role&quot;: &quot;ECS_SERVICE_ROLE&quot;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>replace the <code>sample-app-name</code> with appropriate name in both <code>service-definition.json</code> and <code>task-definition.json</code>.</p>\n</li>\n</ol>\n","excerpt":"","more":"<h4 id=\"The-following-steps-can-be-used-to-prepare-the-Github-to-be-added-to-the-codebuild\"><a href=\"#The-following-steps-can-be-used-to-prepare-the-Github-to-be-added-to-the-codebuild\" class=\"headerlink\" title=\"The following steps can be used to prepare the Github to be added to the codebuild.\"></a>The following steps can be used to prepare the Github to be added to the codebuild.</h4><ol>\n<li><p>The codebuild looks for <code>buildspec.yml</code> in root of the repository. It contains the actions that are to be performed by the   Codebuild. We can add <code>buildspec.yml</code> to the github repository.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div></pre></td><td class=\"code\"><pre><div class=\"line\">version: 0.1</div><div class=\"line\"></div><div class=\"line\">phases:</div><div class=\"line\">  build:</div><div class=\"line\">    commands:</div><div class=\"line\">      - git ls-remote https://$&#123;GITHUB_TOKEN&#125;@github.com/microservices-today/*****.git HEAD | awk &apos;&#123; print $1;&#125;&apos; &gt; master.commit</div><div class=\"line\">      - docker build -t $ECR_REPO:$(cat ./master.commit) .</div><div class=\"line\">      - sed -i &quot;s@DOCKER_URI@$&#123;ECR_REPO&#125;:$(cat ./master.commit)@g&quot; task-definition.json</div><div class=\"line\">      - sed -i &quot;s@ECS_CLUSTER_NAME@$&#123;ECS_CLUSTER_NAME&#125;@g&quot; service-definition.json</div><div class=\"line\">      - sed -i &quot;s@TARGET_GROUP_ARN@$&#123;TARGET_GROUP_ARN&#125;@g&quot; service-definition.json</div><div class=\"line\">      - sed -i &quot;s@ECS_SERVICE_ROLE@$&#123;ECS_SERVICE_ROLE&#125;@g&quot; service-definition.json</div><div class=\"line\">  post_build:</div><div class=\"line\">    commands:</div><div class=\"line\">      - $(aws ecr get-login --region $AWS_REGION)</div><div class=\"line\">      - docker push $ECR_REPO:$(cat ./master.commit)</div><div class=\"line\">artifacts:</div><div class=\"line\">  files:</div><div class=\"line\">    - task-definition.json</div><div class=\"line\">    - service-definition.json</div><div class=\"line\">    - master.commit</div></pre></td></tr></table></figure>\n<p>Replace the <code>https://github.com/***********.git</code> from the buildspec.yml with current github URL.</p>\n</li>\n<li><p>Add the service-definition.json and task-definition.json for ECR.</p>\n<h4 id=\"task-definition-json\"><a href=\"#task-definition-json\" class=\"headerlink\" title=\"task-definition.json\"></a><code>task-definition.json</code></h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div></pre></td><td class=\"code\"><pre><div class=\"line\">&#123;</div><div class=\"line\">    &quot;family&quot;: &quot;sample-app-name&quot;,</div><div class=\"line\">    &quot;containerDefinitions&quot;: [</div><div class=\"line\">        &#123;</div><div class=\"line\">            &quot;environment&quot;: [],</div><div class=\"line\">            &quot;name&quot;: &quot;sample-app-name&quot;,</div><div class=\"line\">            &quot;image&quot;: &quot;DOCKER_URI&quot;,</div><div class=\"line\">            &quot;cpu&quot;: 10,</div><div class=\"line\">            &quot;memory&quot;: 500,</div><div class=\"line\">            &quot;portMappings&quot;: [</div><div class=\"line\">                &#123;</div><div class=\"line\">                    &quot;containerPort&quot;: 80,</div><div class=\"line\">                    &quot;hostPort&quot;: 80</div><div class=\"line\">                &#125;</div><div class=\"line\">            ]</div><div class=\"line\">        &#125;</div><div class=\"line\">    ]</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<h4 id=\"service-definition-json\"><a href=\"#service-definition-json\" class=\"headerlink\" title=\"service-definition.json\"></a><code>service-definition.json</code></h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div></pre></td><td class=\"code\"><pre><div class=\"line\">&#123;</div><div class=\"line\">  &quot;serviceName&quot;: &quot;sample-app-name&quot;,</div><div class=\"line\">  &quot;taskDefinition&quot;: &quot;sample-app-name&quot;,</div><div class=\"line\">  &quot;cluster&quot;: &quot;ECS_CLUSTER_NAME&quot;,</div><div class=\"line\">  &quot;desiredCount&quot;:2,</div><div class=\"line\">  &quot;loadBalancers&quot;: [</div><div class=\"line\">     &#123;</div><div class=\"line\">    &quot;containerName&quot;: &quot;sample-app-name&quot;, </div><div class=\"line\">    &quot;containerPort&quot;: 80, </div><div class=\"line\">    &quot;targetGroupArn&quot;: &quot;TARGET_GROUP_ARN&quot;</div><div class=\"line\">   &#125;</div><div class=\"line\">  ],</div><div class=\"line\">  &quot;role&quot;: &quot;ECS_SERVICE_ROLE&quot;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>replace the <code>sample-app-name</code> with appropriate name in both <code>service-definition.json</code> and <code>task-definition.json</code>.</p>\n</li>\n</ol>\n"},{"title":"AWS Codepipeline","date":"2016-12-21T09:15:38.000Z","_content":"##### These steps can be followed to create Codepipeline.\n\n1. Go to https://console.aws.amazon.com/codepipeline/home?#/create/Name\n2. ![image](../../images/aws-dev-tools/codepipeline/code-pipeline-step-1.png)\n3. ![image](../../images/aws-dev-tools/codepipeline/code-pipeline-step-2.png)\n4. ![image](../../images/aws-dev-tools/codepipeline/code-pipeline-step-3.png)\n5. ![image](../../images/aws-dev-tools/codepipeline/code-pipeline-step-4.png)\n6. ![image](../../images/aws-dev-tools/codepipeline/code-pipeline-step-5.png)\n7. ![image](../../images/aws-dev-tools/codepipeline/code-pipeline-step-6.png)\n8. ![image](../../images/aws-dev-tools/codepipeline/code-pipeline-step-7.png)\n9. ![image](../../images/aws-dev-tools/codepipeline/code-pipeline-step-8.png)\n10. ![image](../../images/aws-dev-tools/codepipeline/code-pipeline-step-9.png)\n","source":"_posts/aws-dev-tools/AwsCodepipeline.md","raw":"---\ntitle: AWS Codepipeline\ndate: 2016-12-21 14:45:38\ntags: AWS Developer tools\n---\n##### These steps can be followed to create Codepipeline.\n\n1. Go to https://console.aws.amazon.com/codepipeline/home?#/create/Name\n2. ![image](../../images/aws-dev-tools/codepipeline/code-pipeline-step-1.png)\n3. ![image](../../images/aws-dev-tools/codepipeline/code-pipeline-step-2.png)\n4. ![image](../../images/aws-dev-tools/codepipeline/code-pipeline-step-3.png)\n5. ![image](../../images/aws-dev-tools/codepipeline/code-pipeline-step-4.png)\n6. ![image](../../images/aws-dev-tools/codepipeline/code-pipeline-step-5.png)\n7. ![image](../../images/aws-dev-tools/codepipeline/code-pipeline-step-6.png)\n8. ![image](../../images/aws-dev-tools/codepipeline/code-pipeline-step-7.png)\n9. ![image](../../images/aws-dev-tools/codepipeline/code-pipeline-step-8.png)\n10. ![image](../../images/aws-dev-tools/codepipeline/code-pipeline-step-9.png)\n","slug":"aws-dev-tools/AwsCodepipeline","published":1,"updated":"2017-01-04T10:59:16.506Z","_id":"cixigfrjs000nf33prz59ljhi","comments":1,"layout":"post","photos":[],"link":"","content":"<h5 id=\"These-steps-can-be-followed-to-create-Codepipeline\"><a href=\"#These-steps-can-be-followed-to-create-Codepipeline\" class=\"headerlink\" title=\"These steps can be followed to create Codepipeline.\"></a>These steps can be followed to create Codepipeline.</h5><ol>\n<li>Go to <a href=\"https://console.aws.amazon.com/codepipeline/home?#/create/Name\" target=\"_blank\" rel=\"external\">https://console.aws.amazon.com/codepipeline/home?#/create/Name</a></li>\n<li><img src=\"../../images/aws-dev-tools/codepipeline/code-pipeline-step-1.png\" alt=\"image\"></li>\n<li><img src=\"../../images/aws-dev-tools/codepipeline/code-pipeline-step-2.png\" alt=\"image\"></li>\n<li><img src=\"../../images/aws-dev-tools/codepipeline/code-pipeline-step-3.png\" alt=\"image\"></li>\n<li><img src=\"../../images/aws-dev-tools/codepipeline/code-pipeline-step-4.png\" alt=\"image\"></li>\n<li><img src=\"../../images/aws-dev-tools/codepipeline/code-pipeline-step-5.png\" alt=\"image\"></li>\n<li><img src=\"../../images/aws-dev-tools/codepipeline/code-pipeline-step-6.png\" alt=\"image\"></li>\n<li><img src=\"../../images/aws-dev-tools/codepipeline/code-pipeline-step-7.png\" alt=\"image\"></li>\n<li><img src=\"../../images/aws-dev-tools/codepipeline/code-pipeline-step-8.png\" alt=\"image\"></li>\n<li><img src=\"../../images/aws-dev-tools/codepipeline/code-pipeline-step-9.png\" alt=\"image\"></li>\n</ol>\n","excerpt":"","more":"<h5 id=\"These-steps-can-be-followed-to-create-Codepipeline\"><a href=\"#These-steps-can-be-followed-to-create-Codepipeline\" class=\"headerlink\" title=\"These steps can be followed to create Codepipeline.\"></a>These steps can be followed to create Codepipeline.</h5><ol>\n<li>Go to <a href=\"https://console.aws.amazon.com/codepipeline/home?#/create/Name\">https://console.aws.amazon.com/codepipeline/home?#/create/Name</a></li>\n<li><img src=\"../../images/aws-dev-tools/codepipeline/code-pipeline-step-1.png\" alt=\"image\"></li>\n<li><img src=\"../../images/aws-dev-tools/codepipeline/code-pipeline-step-2.png\" alt=\"image\"></li>\n<li><img src=\"../../images/aws-dev-tools/codepipeline/code-pipeline-step-3.png\" alt=\"image\"></li>\n<li><img src=\"../../images/aws-dev-tools/codepipeline/code-pipeline-step-4.png\" alt=\"image\"></li>\n<li><img src=\"../../images/aws-dev-tools/codepipeline/code-pipeline-step-5.png\" alt=\"image\"></li>\n<li><img src=\"../../images/aws-dev-tools/codepipeline/code-pipeline-step-6.png\" alt=\"image\"></li>\n<li><img src=\"../../images/aws-dev-tools/codepipeline/code-pipeline-step-7.png\" alt=\"image\"></li>\n<li><img src=\"../../images/aws-dev-tools/codepipeline/code-pipeline-step-8.png\" alt=\"image\"></li>\n<li><img src=\"../../images/aws-dev-tools/codepipeline/code-pipeline-step-9.png\" alt=\"image\"></li>\n</ol>\n"},{"title":"AWS Lamda for Task definition updation","date":"2016-12-21T09:15:38.000Z","_content":"#### Follow these steps to create two lamda functions.\n\n1. Update Task Definition \n\nThe sample code below can be used to update the service definition.\n```\n'use strict';\nexports.handler = (event, context, callback) => {\n    //Configuring AWS \n    var AWS = require('aws-sdk');\n    \n    var fs = require('fs');\n    var codepipeline = new AWS.CodePipeline();\n    //Child process\n    const exec = require('child_process').exec;\n    //expecting params from input artifacts\n    var params = {\n        Bucket: event['CodePipeline.job'].data.inputArtifacts[0].location.s3Location.bucketName,\n        Key: event['CodePipeline.job'].data.inputArtifacts[0].location.s3Location.objectKey\n    };\n    //Getting pipeline ID\n    var jobId = event[\"CodePipeline.job\"].id;\n    AWS.config.update({region: 'ap-southeast-1'});\n    var ecs = new AWS.ECS();\n    var s3 = new AWS.S3({\n        maxRetries: 10,\n        signatureVersion: \"v4\"\n    });\n    const unzipCommand = \"rm -rf /tmp/artifacts && mkdir -p /tmp/artifacts && unzip /tmp/artifact.zip -d /tmp/artifacts\"\n    // Notify AWS CodePipeline of a successful job\n    var putJobSuccess = function(message) {\n        console.log(\"Success\" + message);\n        var params = {\n            jobId: jobId\n        };\n        console.log(params)\n        AWS.config.update({region: 'us-east-1'});\n        codepipeline.putJobSuccessResult(params, function(err, data) {\n            if(err) {\n                console.log(\"Unable to update pipeline\" + err);\n                context.fail(err);      \n            } else {\n                context.succeed(message);      \n            }\n        });\n    };\n    \n    // Notify AWS CodePipeline of a failed job\n    var putJobFailure = function(message) {\n        console.log(\"Failure\" + message);\n        AWS.config.update({region: 'us-east-1'});\n        var params = {\n            jobId: jobId,\n            failureDetails: {\n                message: JSON.stringify(message),\n                type: 'JobFailed',\n                externalExecutionId: context.invokeid\n            }\n        };\n        AWS.config.update({region: 'us-east-1'});\n        codepipeline.putJobFailureResult(params, function(err, data) {\n            context.fail(message);      \n        });\n    };\n    //We can start with pulling the artifacts\n    s3.getObject(params, function(err, data) {\n    if (err) putJobFailure(err);\n    else {\n        //writing the artifacts to the /tmp/ , we have access to only this directory\n        fs.writeFile(\"/tmp/artifact.zip\", data.Body, function(err) {\n            if (err) putJobFailure(err);\n            else {\n                const child = exec(unzipCommand, (error) => {\n                    var taskDefinition = require('/tmp/artifacts/task-definition.json');\n                    var serviceDefinition = require('/tmp/artifacts/service-definition.json');\n                    ecs.registerTaskDefinition(taskDefinition, function(err, data) {\n                        if (err) putJobFailure(err);\n                        else putJobSuccess(\"Successfully created task defnition\");\n                    });\n                });\n                //print the output of child process\n                child.stdout.on('data', console.log);\n                child.stderr.on('data', console.error);\n                callback(null, 'Process complete!');\n            }\n        });\n        }\n\n    });\n};\n\n```\nThis lamda function will create a new task definition or a new revision of the existing task definition.\n\n2. Update Service Definition\n\n```\n'use strict';\nexports.handler = (event, context, callback) => {\n    //Configuring AWS \n    var AWS = require('aws-sdk');\n    \n    var fs = require('fs');\n    \n    var codepipeline = new AWS.CodePipeline();\n    //Child process\n    const exec = require('child_process').exec;\n    //expecting params from input artifacts\n    var params = {\n        Bucket: event['CodePipeline.job'].data.inputArtifacts[0].location.s3Location.bucketName,\n        Key: event['CodePipeline.job'].data.inputArtifacts[0].location.s3Location.objectKey\n    };\n    //Getting pipeline ID\n    var jobId = event[\"CodePipeline.job\"].id;\n    var codePipelineParams = {\n        jobId: jobId\n    };\n    AWS.config.update({region: 'ap-southeast-1'});\n    var ecs = new AWS.ECS();\n    var s3 = new AWS.S3({\n        maxRetries: 10,\n        signatureVersion: \"v4\"\n    });\n    const unzipCommand = \"rm -rf /tmp/artifacts && mkdir -p /tmp/artifacts && unzip /tmp/artifact.zip -d /tmp/artifacts\"\n    // Notify AWS CodePipeline of a successful job\n    var putJobSuccess = function(message) {\n        console.log(\"Success\" + message);\n        AWS.config.update({region: 'us-east-1'});\n        var params = {\n            jobId: jobId\n        };\n        codepipeline.putJobSuccessResult(params, function(err, data) {\n            if(err) {\n                context.fail(err);      \n            } else {\n                context.succeed(message);      \n            }\n        });\n    };\n    \n    // Notify AWS CodePipeline of a failed job\n    var putJobFailure = function(message) {\n        console.log(\"Failure\" + message);\n        var params = {\n            jobId: jobId,\n            failureDetails: {\n                message: JSON.stringify(message),\n                type: 'JobFailed',\n                externalExecutionId: context.invokeid\n            }\n        };\n        AWS.config.update({region: 'us-east-1'});\n        codepipeline.putJobFailureResult(params, function(err, data) {\n            context.fail(message);      \n        });\n    };\n    //We can start with pulling the artifacts\n    s3.getObject(params, function(err, data) {\n    if (err) putJobFailure(err);\n    else {\n        //writing the artifacts to the /tmp/ , we have access to only this directory\n        fs.writeFile(\"/tmp/artifact.zip\", data.Body, function(err) {\n            if (err) putJobFailure(err);\n            else {\n                const child = exec(unzipCommand, (error) => {\n                    var taskDefinition = require('/tmp/artifacts/task-definition.json');\n                    var serviceDefinition = require('/tmp/artifacts/service-definition.json');\n                    console.log(serviceDefinition);\n                    var params = {\n                        desiredCount: 2, \n                        service: serviceDefinition.serviceName,\n                        cluster: serviceDefinition.cluster,\n                    };\n                    ecs.updateService(params, function(err, data) {\n                        if (err) {\n                            console.log(err);\n                            console.log(params);\n                            ecs.createService(serviceDefinition, function(err, data) {\n                                if (err) putJobFailure(err);\n                                else putJobSuccess(\"Successfully launched the service\");\n                            });\n                            \n                        } else putJobSuccess(\"Successfully launched the service\");\n                    });\n                    callback(null, 'Process complete!');\n                });\n                child.stdout.on('data', console.log);\n                child.stderr.on('data', console.error);\n            }\n        });\n        }\n\n    });\n};\n\n\n```\n","source":"_posts/aws-dev-tools/AwsLamda.md","raw":"---\ntitle: AWS Lamda for Task definition updation\ndate: 2016-12-21 14:45:38\ntags: AWS Developer tools\n---\n#### Follow these steps to create two lamda functions.\n\n1. Update Task Definition \n\nThe sample code below can be used to update the service definition.\n```\n'use strict';\nexports.handler = (event, context, callback) => {\n    //Configuring AWS \n    var AWS = require('aws-sdk');\n    \n    var fs = require('fs');\n    var codepipeline = new AWS.CodePipeline();\n    //Child process\n    const exec = require('child_process').exec;\n    //expecting params from input artifacts\n    var params = {\n        Bucket: event['CodePipeline.job'].data.inputArtifacts[0].location.s3Location.bucketName,\n        Key: event['CodePipeline.job'].data.inputArtifacts[0].location.s3Location.objectKey\n    };\n    //Getting pipeline ID\n    var jobId = event[\"CodePipeline.job\"].id;\n    AWS.config.update({region: 'ap-southeast-1'});\n    var ecs = new AWS.ECS();\n    var s3 = new AWS.S3({\n        maxRetries: 10,\n        signatureVersion: \"v4\"\n    });\n    const unzipCommand = \"rm -rf /tmp/artifacts && mkdir -p /tmp/artifacts && unzip /tmp/artifact.zip -d /tmp/artifacts\"\n    // Notify AWS CodePipeline of a successful job\n    var putJobSuccess = function(message) {\n        console.log(\"Success\" + message);\n        var params = {\n            jobId: jobId\n        };\n        console.log(params)\n        AWS.config.update({region: 'us-east-1'});\n        codepipeline.putJobSuccessResult(params, function(err, data) {\n            if(err) {\n                console.log(\"Unable to update pipeline\" + err);\n                context.fail(err);      \n            } else {\n                context.succeed(message);      \n            }\n        });\n    };\n    \n    // Notify AWS CodePipeline of a failed job\n    var putJobFailure = function(message) {\n        console.log(\"Failure\" + message);\n        AWS.config.update({region: 'us-east-1'});\n        var params = {\n            jobId: jobId,\n            failureDetails: {\n                message: JSON.stringify(message),\n                type: 'JobFailed',\n                externalExecutionId: context.invokeid\n            }\n        };\n        AWS.config.update({region: 'us-east-1'});\n        codepipeline.putJobFailureResult(params, function(err, data) {\n            context.fail(message);      \n        });\n    };\n    //We can start with pulling the artifacts\n    s3.getObject(params, function(err, data) {\n    if (err) putJobFailure(err);\n    else {\n        //writing the artifacts to the /tmp/ , we have access to only this directory\n        fs.writeFile(\"/tmp/artifact.zip\", data.Body, function(err) {\n            if (err) putJobFailure(err);\n            else {\n                const child = exec(unzipCommand, (error) => {\n                    var taskDefinition = require('/tmp/artifacts/task-definition.json');\n                    var serviceDefinition = require('/tmp/artifacts/service-definition.json');\n                    ecs.registerTaskDefinition(taskDefinition, function(err, data) {\n                        if (err) putJobFailure(err);\n                        else putJobSuccess(\"Successfully created task defnition\");\n                    });\n                });\n                //print the output of child process\n                child.stdout.on('data', console.log);\n                child.stderr.on('data', console.error);\n                callback(null, 'Process complete!');\n            }\n        });\n        }\n\n    });\n};\n\n```\nThis lamda function will create a new task definition or a new revision of the existing task definition.\n\n2. Update Service Definition\n\n```\n'use strict';\nexports.handler = (event, context, callback) => {\n    //Configuring AWS \n    var AWS = require('aws-sdk');\n    \n    var fs = require('fs');\n    \n    var codepipeline = new AWS.CodePipeline();\n    //Child process\n    const exec = require('child_process').exec;\n    //expecting params from input artifacts\n    var params = {\n        Bucket: event['CodePipeline.job'].data.inputArtifacts[0].location.s3Location.bucketName,\n        Key: event['CodePipeline.job'].data.inputArtifacts[0].location.s3Location.objectKey\n    };\n    //Getting pipeline ID\n    var jobId = event[\"CodePipeline.job\"].id;\n    var codePipelineParams = {\n        jobId: jobId\n    };\n    AWS.config.update({region: 'ap-southeast-1'});\n    var ecs = new AWS.ECS();\n    var s3 = new AWS.S3({\n        maxRetries: 10,\n        signatureVersion: \"v4\"\n    });\n    const unzipCommand = \"rm -rf /tmp/artifacts && mkdir -p /tmp/artifacts && unzip /tmp/artifact.zip -d /tmp/artifacts\"\n    // Notify AWS CodePipeline of a successful job\n    var putJobSuccess = function(message) {\n        console.log(\"Success\" + message);\n        AWS.config.update({region: 'us-east-1'});\n        var params = {\n            jobId: jobId\n        };\n        codepipeline.putJobSuccessResult(params, function(err, data) {\n            if(err) {\n                context.fail(err);      \n            } else {\n                context.succeed(message);      \n            }\n        });\n    };\n    \n    // Notify AWS CodePipeline of a failed job\n    var putJobFailure = function(message) {\n        console.log(\"Failure\" + message);\n        var params = {\n            jobId: jobId,\n            failureDetails: {\n                message: JSON.stringify(message),\n                type: 'JobFailed',\n                externalExecutionId: context.invokeid\n            }\n        };\n        AWS.config.update({region: 'us-east-1'});\n        codepipeline.putJobFailureResult(params, function(err, data) {\n            context.fail(message);      \n        });\n    };\n    //We can start with pulling the artifacts\n    s3.getObject(params, function(err, data) {\n    if (err) putJobFailure(err);\n    else {\n        //writing the artifacts to the /tmp/ , we have access to only this directory\n        fs.writeFile(\"/tmp/artifact.zip\", data.Body, function(err) {\n            if (err) putJobFailure(err);\n            else {\n                const child = exec(unzipCommand, (error) => {\n                    var taskDefinition = require('/tmp/artifacts/task-definition.json');\n                    var serviceDefinition = require('/tmp/artifacts/service-definition.json');\n                    console.log(serviceDefinition);\n                    var params = {\n                        desiredCount: 2, \n                        service: serviceDefinition.serviceName,\n                        cluster: serviceDefinition.cluster,\n                    };\n                    ecs.updateService(params, function(err, data) {\n                        if (err) {\n                            console.log(err);\n                            console.log(params);\n                            ecs.createService(serviceDefinition, function(err, data) {\n                                if (err) putJobFailure(err);\n                                else putJobSuccess(\"Successfully launched the service\");\n                            });\n                            \n                        } else putJobSuccess(\"Successfully launched the service\");\n                    });\n                    callback(null, 'Process complete!');\n                });\n                child.stdout.on('data', console.log);\n                child.stderr.on('data', console.error);\n            }\n        });\n        }\n\n    });\n};\n\n\n```\n","slug":"aws-dev-tools/AwsLamda","published":1,"updated":"2017-01-04T04:33:28.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cixigfrjt000of33pb0qjeh70","content":"<h4 id=\"Follow-these-steps-to-create-two-lamda-functions\"><a href=\"#Follow-these-steps-to-create-two-lamda-functions\" class=\"headerlink\" title=\"Follow these steps to create two lamda functions.\"></a>Follow these steps to create two lamda functions.</h4><ol>\n<li>Update Task Definition </li>\n</ol>\n<p>The sample code below can be used to update the service definition.<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div></pre></td><td class=\"code\"><pre><div class=\"line\">&apos;use strict&apos;;</div><div class=\"line\">exports.handler = (event, context, callback) =&gt; &#123;</div><div class=\"line\">    //Configuring AWS </div><div class=\"line\">    var AWS = require(&apos;aws-sdk&apos;);</div><div class=\"line\">    </div><div class=\"line\">    var fs = require(&apos;fs&apos;);</div><div class=\"line\">    var codepipeline = new AWS.CodePipeline();</div><div class=\"line\">    //Child process</div><div class=\"line\">    const exec = require(&apos;child_process&apos;).exec;</div><div class=\"line\">    //expecting params from input artifacts</div><div class=\"line\">    var params = &#123;</div><div class=\"line\">        Bucket: event[&apos;CodePipeline.job&apos;].data.inputArtifacts[0].location.s3Location.bucketName,</div><div class=\"line\">        Key: event[&apos;CodePipeline.job&apos;].data.inputArtifacts[0].location.s3Location.objectKey</div><div class=\"line\">    &#125;;</div><div class=\"line\">    //Getting pipeline ID</div><div class=\"line\">    var jobId = event[&quot;CodePipeline.job&quot;].id;</div><div class=\"line\">    AWS.config.update(&#123;region: &apos;ap-southeast-1&apos;&#125;);</div><div class=\"line\">    var ecs = new AWS.ECS();</div><div class=\"line\">    var s3 = new AWS.S3(&#123;</div><div class=\"line\">        maxRetries: 10,</div><div class=\"line\">        signatureVersion: &quot;v4&quot;</div><div class=\"line\">    &#125;);</div><div class=\"line\">    const unzipCommand = &quot;rm -rf /tmp/artifacts &amp;&amp; mkdir -p /tmp/artifacts &amp;&amp; unzip /tmp/artifact.zip -d /tmp/artifacts&quot;</div><div class=\"line\">    // Notify AWS CodePipeline of a successful job</div><div class=\"line\">    var putJobSuccess = function(message) &#123;</div><div class=\"line\">        console.log(&quot;Success&quot; + message);</div><div class=\"line\">        var params = &#123;</div><div class=\"line\">            jobId: jobId</div><div class=\"line\">        &#125;;</div><div class=\"line\">        console.log(params)</div><div class=\"line\">        AWS.config.update(&#123;region: &apos;us-east-1&apos;&#125;);</div><div class=\"line\">        codepipeline.putJobSuccessResult(params, function(err, data) &#123;</div><div class=\"line\">            if(err) &#123;</div><div class=\"line\">                console.log(&quot;Unable to update pipeline&quot; + err);</div><div class=\"line\">                context.fail(err);      </div><div class=\"line\">            &#125; else &#123;</div><div class=\"line\">                context.succeed(message);      </div><div class=\"line\">            &#125;</div><div class=\"line\">        &#125;);</div><div class=\"line\">    &#125;;</div><div class=\"line\">    </div><div class=\"line\">    // Notify AWS CodePipeline of a failed job</div><div class=\"line\">    var putJobFailure = function(message) &#123;</div><div class=\"line\">        console.log(&quot;Failure&quot; + message);</div><div class=\"line\">        AWS.config.update(&#123;region: &apos;us-east-1&apos;&#125;);</div><div class=\"line\">        var params = &#123;</div><div class=\"line\">            jobId: jobId,</div><div class=\"line\">            failureDetails: &#123;</div><div class=\"line\">                message: JSON.stringify(message),</div><div class=\"line\">                type: &apos;JobFailed&apos;,</div><div class=\"line\">                externalExecutionId: context.invokeid</div><div class=\"line\">            &#125;</div><div class=\"line\">        &#125;;</div><div class=\"line\">        AWS.config.update(&#123;region: &apos;us-east-1&apos;&#125;);</div><div class=\"line\">        codepipeline.putJobFailureResult(params, function(err, data) &#123;</div><div class=\"line\">            context.fail(message);      </div><div class=\"line\">        &#125;);</div><div class=\"line\">    &#125;;</div><div class=\"line\">    //We can start with pulling the artifacts</div><div class=\"line\">    s3.getObject(params, function(err, data) &#123;</div><div class=\"line\">    if (err) putJobFailure(err);</div><div class=\"line\">    else &#123;</div><div class=\"line\">        //writing the artifacts to the /tmp/ , we have access to only this directory</div><div class=\"line\">        fs.writeFile(&quot;/tmp/artifact.zip&quot;, data.Body, function(err) &#123;</div><div class=\"line\">            if (err) putJobFailure(err);</div><div class=\"line\">            else &#123;</div><div class=\"line\">                const child = exec(unzipCommand, (error) =&gt; &#123;</div><div class=\"line\">                    var taskDefinition = require(&apos;/tmp/artifacts/task-definition.json&apos;);</div><div class=\"line\">                    var serviceDefinition = require(&apos;/tmp/artifacts/service-definition.json&apos;);</div><div class=\"line\">                    ecs.registerTaskDefinition(taskDefinition, function(err, data) &#123;</div><div class=\"line\">                        if (err) putJobFailure(err);</div><div class=\"line\">                        else putJobSuccess(&quot;Successfully created task defnition&quot;);</div><div class=\"line\">                    &#125;);</div><div class=\"line\">                &#125;);</div><div class=\"line\">                //print the output of child process</div><div class=\"line\">                child.stdout.on(&apos;data&apos;, console.log);</div><div class=\"line\">                child.stderr.on(&apos;data&apos;, console.error);</div><div class=\"line\">                callback(null, &apos;Process complete!&apos;);</div><div class=\"line\">            &#125;</div><div class=\"line\">        &#125;);</div><div class=\"line\">        &#125;</div><div class=\"line\"></div><div class=\"line\">    &#125;);</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure></p>\n<p>This lamda function will create a new task definition or a new revision of the existing task definition.</p>\n<ol>\n<li>Update Service Definition</li>\n</ol>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div><div class=\"line\">96</div><div class=\"line\">97</div></pre></td><td class=\"code\"><pre><div class=\"line\">&apos;use strict&apos;;</div><div class=\"line\">exports.handler = (event, context, callback) =&gt; &#123;</div><div class=\"line\">    //Configuring AWS </div><div class=\"line\">    var AWS = require(&apos;aws-sdk&apos;);</div><div class=\"line\">    </div><div class=\"line\">    var fs = require(&apos;fs&apos;);</div><div class=\"line\">    </div><div class=\"line\">    var codepipeline = new AWS.CodePipeline();</div><div class=\"line\">    //Child process</div><div class=\"line\">    const exec = require(&apos;child_process&apos;).exec;</div><div class=\"line\">    //expecting params from input artifacts</div><div class=\"line\">    var params = &#123;</div><div class=\"line\">        Bucket: event[&apos;CodePipeline.job&apos;].data.inputArtifacts[0].location.s3Location.bucketName,</div><div class=\"line\">        Key: event[&apos;CodePipeline.job&apos;].data.inputArtifacts[0].location.s3Location.objectKey</div><div class=\"line\">    &#125;;</div><div class=\"line\">    //Getting pipeline ID</div><div class=\"line\">    var jobId = event[&quot;CodePipeline.job&quot;].id;</div><div class=\"line\">    var codePipelineParams = &#123;</div><div class=\"line\">        jobId: jobId</div><div class=\"line\">    &#125;;</div><div class=\"line\">    AWS.config.update(&#123;region: &apos;ap-southeast-1&apos;&#125;);</div><div class=\"line\">    var ecs = new AWS.ECS();</div><div class=\"line\">    var s3 = new AWS.S3(&#123;</div><div class=\"line\">        maxRetries: 10,</div><div class=\"line\">        signatureVersion: &quot;v4&quot;</div><div class=\"line\">    &#125;);</div><div class=\"line\">    const unzipCommand = &quot;rm -rf /tmp/artifacts &amp;&amp; mkdir -p /tmp/artifacts &amp;&amp; unzip /tmp/artifact.zip -d /tmp/artifacts&quot;</div><div class=\"line\">    // Notify AWS CodePipeline of a successful job</div><div class=\"line\">    var putJobSuccess = function(message) &#123;</div><div class=\"line\">        console.log(&quot;Success&quot; + message);</div><div class=\"line\">        AWS.config.update(&#123;region: &apos;us-east-1&apos;&#125;);</div><div class=\"line\">        var params = &#123;</div><div class=\"line\">            jobId: jobId</div><div class=\"line\">        &#125;;</div><div class=\"line\">        codepipeline.putJobSuccessResult(params, function(err, data) &#123;</div><div class=\"line\">            if(err) &#123;</div><div class=\"line\">                context.fail(err);      </div><div class=\"line\">            &#125; else &#123;</div><div class=\"line\">                context.succeed(message);      </div><div class=\"line\">            &#125;</div><div class=\"line\">        &#125;);</div><div class=\"line\">    &#125;;</div><div class=\"line\">    </div><div class=\"line\">    // Notify AWS CodePipeline of a failed job</div><div class=\"line\">    var putJobFailure = function(message) &#123;</div><div class=\"line\">        console.log(&quot;Failure&quot; + message);</div><div class=\"line\">        var params = &#123;</div><div class=\"line\">            jobId: jobId,</div><div class=\"line\">            failureDetails: &#123;</div><div class=\"line\">                message: JSON.stringify(message),</div><div class=\"line\">                type: &apos;JobFailed&apos;,</div><div class=\"line\">                externalExecutionId: context.invokeid</div><div class=\"line\">            &#125;</div><div class=\"line\">        &#125;;</div><div class=\"line\">        AWS.config.update(&#123;region: &apos;us-east-1&apos;&#125;);</div><div class=\"line\">        codepipeline.putJobFailureResult(params, function(err, data) &#123;</div><div class=\"line\">            context.fail(message);      </div><div class=\"line\">        &#125;);</div><div class=\"line\">    &#125;;</div><div class=\"line\">    //We can start with pulling the artifacts</div><div class=\"line\">    s3.getObject(params, function(err, data) &#123;</div><div class=\"line\">    if (err) putJobFailure(err);</div><div class=\"line\">    else &#123;</div><div class=\"line\">        //writing the artifacts to the /tmp/ , we have access to only this directory</div><div class=\"line\">        fs.writeFile(&quot;/tmp/artifact.zip&quot;, data.Body, function(err) &#123;</div><div class=\"line\">            if (err) putJobFailure(err);</div><div class=\"line\">            else &#123;</div><div class=\"line\">                const child = exec(unzipCommand, (error) =&gt; &#123;</div><div class=\"line\">                    var taskDefinition = require(&apos;/tmp/artifacts/task-definition.json&apos;);</div><div class=\"line\">                    var serviceDefinition = require(&apos;/tmp/artifacts/service-definition.json&apos;);</div><div class=\"line\">                    console.log(serviceDefinition);</div><div class=\"line\">                    var params = &#123;</div><div class=\"line\">                        desiredCount: 2, </div><div class=\"line\">                        service: serviceDefinition.serviceName,</div><div class=\"line\">                        cluster: serviceDefinition.cluster,</div><div class=\"line\">                    &#125;;</div><div class=\"line\">                    ecs.updateService(params, function(err, data) &#123;</div><div class=\"line\">                        if (err) &#123;</div><div class=\"line\">                            console.log(err);</div><div class=\"line\">                            console.log(params);</div><div class=\"line\">                            ecs.createService(serviceDefinition, function(err, data) &#123;</div><div class=\"line\">                                if (err) putJobFailure(err);</div><div class=\"line\">                                else putJobSuccess(&quot;Successfully launched the service&quot;);</div><div class=\"line\">                            &#125;);</div><div class=\"line\">                            </div><div class=\"line\">                        &#125; else putJobSuccess(&quot;Successfully launched the service&quot;);</div><div class=\"line\">                    &#125;);</div><div class=\"line\">                    callback(null, &apos;Process complete!&apos;);</div><div class=\"line\">                &#125;);</div><div class=\"line\">                child.stdout.on(&apos;data&apos;, console.log);</div><div class=\"line\">                child.stderr.on(&apos;data&apos;, console.error);</div><div class=\"line\">            &#125;</div><div class=\"line\">        &#125;);</div><div class=\"line\">        &#125;</div><div class=\"line\"></div><div class=\"line\">    &#125;);</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure>\n","excerpt":"","more":"<h4 id=\"Follow-these-steps-to-create-two-lamda-functions\"><a href=\"#Follow-these-steps-to-create-two-lamda-functions\" class=\"headerlink\" title=\"Follow these steps to create two lamda functions.\"></a>Follow these steps to create two lamda functions.</h4><ol>\n<li>Update Task Definition </li>\n</ol>\n<p>The sample code below can be used to update the service definition.<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div></pre></td><td class=\"code\"><pre><div class=\"line\">&apos;use strict&apos;;</div><div class=\"line\">exports.handler = (event, context, callback) =&gt; &#123;</div><div class=\"line\">    //Configuring AWS </div><div class=\"line\">    var AWS = require(&apos;aws-sdk&apos;);</div><div class=\"line\">    </div><div class=\"line\">    var fs = require(&apos;fs&apos;);</div><div class=\"line\">    var codepipeline = new AWS.CodePipeline();</div><div class=\"line\">    //Child process</div><div class=\"line\">    const exec = require(&apos;child_process&apos;).exec;</div><div class=\"line\">    //expecting params from input artifacts</div><div class=\"line\">    var params = &#123;</div><div class=\"line\">        Bucket: event[&apos;CodePipeline.job&apos;].data.inputArtifacts[0].location.s3Location.bucketName,</div><div class=\"line\">        Key: event[&apos;CodePipeline.job&apos;].data.inputArtifacts[0].location.s3Location.objectKey</div><div class=\"line\">    &#125;;</div><div class=\"line\">    //Getting pipeline ID</div><div class=\"line\">    var jobId = event[&quot;CodePipeline.job&quot;].id;</div><div class=\"line\">    AWS.config.update(&#123;region: &apos;ap-southeast-1&apos;&#125;);</div><div class=\"line\">    var ecs = new AWS.ECS();</div><div class=\"line\">    var s3 = new AWS.S3(&#123;</div><div class=\"line\">        maxRetries: 10,</div><div class=\"line\">        signatureVersion: &quot;v4&quot;</div><div class=\"line\">    &#125;);</div><div class=\"line\">    const unzipCommand = &quot;rm -rf /tmp/artifacts &amp;&amp; mkdir -p /tmp/artifacts &amp;&amp; unzip /tmp/artifact.zip -d /tmp/artifacts&quot;</div><div class=\"line\">    // Notify AWS CodePipeline of a successful job</div><div class=\"line\">    var putJobSuccess = function(message) &#123;</div><div class=\"line\">        console.log(&quot;Success&quot; + message);</div><div class=\"line\">        var params = &#123;</div><div class=\"line\">            jobId: jobId</div><div class=\"line\">        &#125;;</div><div class=\"line\">        console.log(params)</div><div class=\"line\">        AWS.config.update(&#123;region: &apos;us-east-1&apos;&#125;);</div><div class=\"line\">        codepipeline.putJobSuccessResult(params, function(err, data) &#123;</div><div class=\"line\">            if(err) &#123;</div><div class=\"line\">                console.log(&quot;Unable to update pipeline&quot; + err);</div><div class=\"line\">                context.fail(err);      </div><div class=\"line\">            &#125; else &#123;</div><div class=\"line\">                context.succeed(message);      </div><div class=\"line\">            &#125;</div><div class=\"line\">        &#125;);</div><div class=\"line\">    &#125;;</div><div class=\"line\">    </div><div class=\"line\">    // Notify AWS CodePipeline of a failed job</div><div class=\"line\">    var putJobFailure = function(message) &#123;</div><div class=\"line\">        console.log(&quot;Failure&quot; + message);</div><div class=\"line\">        AWS.config.update(&#123;region: &apos;us-east-1&apos;&#125;);</div><div class=\"line\">        var params = &#123;</div><div class=\"line\">            jobId: jobId,</div><div class=\"line\">            failureDetails: &#123;</div><div class=\"line\">                message: JSON.stringify(message),</div><div class=\"line\">                type: &apos;JobFailed&apos;,</div><div class=\"line\">                externalExecutionId: context.invokeid</div><div class=\"line\">            &#125;</div><div class=\"line\">        &#125;;</div><div class=\"line\">        AWS.config.update(&#123;region: &apos;us-east-1&apos;&#125;);</div><div class=\"line\">        codepipeline.putJobFailureResult(params, function(err, data) &#123;</div><div class=\"line\">            context.fail(message);      </div><div class=\"line\">        &#125;);</div><div class=\"line\">    &#125;;</div><div class=\"line\">    //We can start with pulling the artifacts</div><div class=\"line\">    s3.getObject(params, function(err, data) &#123;</div><div class=\"line\">    if (err) putJobFailure(err);</div><div class=\"line\">    else &#123;</div><div class=\"line\">        //writing the artifacts to the /tmp/ , we have access to only this directory</div><div class=\"line\">        fs.writeFile(&quot;/tmp/artifact.zip&quot;, data.Body, function(err) &#123;</div><div class=\"line\">            if (err) putJobFailure(err);</div><div class=\"line\">            else &#123;</div><div class=\"line\">                const child = exec(unzipCommand, (error) =&gt; &#123;</div><div class=\"line\">                    var taskDefinition = require(&apos;/tmp/artifacts/task-definition.json&apos;);</div><div class=\"line\">                    var serviceDefinition = require(&apos;/tmp/artifacts/service-definition.json&apos;);</div><div class=\"line\">                    ecs.registerTaskDefinition(taskDefinition, function(err, data) &#123;</div><div class=\"line\">                        if (err) putJobFailure(err);</div><div class=\"line\">                        else putJobSuccess(&quot;Successfully created task defnition&quot;);</div><div class=\"line\">                    &#125;);</div><div class=\"line\">                &#125;);</div><div class=\"line\">                //print the output of child process</div><div class=\"line\">                child.stdout.on(&apos;data&apos;, console.log);</div><div class=\"line\">                child.stderr.on(&apos;data&apos;, console.error);</div><div class=\"line\">                callback(null, &apos;Process complete!&apos;);</div><div class=\"line\">            &#125;</div><div class=\"line\">        &#125;);</div><div class=\"line\">        &#125;</div><div class=\"line\"></div><div class=\"line\">    &#125;);</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure></p>\n<p>This lamda function will create a new task definition or a new revision of the existing task definition.</p>\n<ol>\n<li>Update Service Definition</li>\n</ol>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div><div class=\"line\">96</div><div class=\"line\">97</div></pre></td><td class=\"code\"><pre><div class=\"line\">&apos;use strict&apos;;</div><div class=\"line\">exports.handler = (event, context, callback) =&gt; &#123;</div><div class=\"line\">    //Configuring AWS </div><div class=\"line\">    var AWS = require(&apos;aws-sdk&apos;);</div><div class=\"line\">    </div><div class=\"line\">    var fs = require(&apos;fs&apos;);</div><div class=\"line\">    </div><div class=\"line\">    var codepipeline = new AWS.CodePipeline();</div><div class=\"line\">    //Child process</div><div class=\"line\">    const exec = require(&apos;child_process&apos;).exec;</div><div class=\"line\">    //expecting params from input artifacts</div><div class=\"line\">    var params = &#123;</div><div class=\"line\">        Bucket: event[&apos;CodePipeline.job&apos;].data.inputArtifacts[0].location.s3Location.bucketName,</div><div class=\"line\">        Key: event[&apos;CodePipeline.job&apos;].data.inputArtifacts[0].location.s3Location.objectKey</div><div class=\"line\">    &#125;;</div><div class=\"line\">    //Getting pipeline ID</div><div class=\"line\">    var jobId = event[&quot;CodePipeline.job&quot;].id;</div><div class=\"line\">    var codePipelineParams = &#123;</div><div class=\"line\">        jobId: jobId</div><div class=\"line\">    &#125;;</div><div class=\"line\">    AWS.config.update(&#123;region: &apos;ap-southeast-1&apos;&#125;);</div><div class=\"line\">    var ecs = new AWS.ECS();</div><div class=\"line\">    var s3 = new AWS.S3(&#123;</div><div class=\"line\">        maxRetries: 10,</div><div class=\"line\">        signatureVersion: &quot;v4&quot;</div><div class=\"line\">    &#125;);</div><div class=\"line\">    const unzipCommand = &quot;rm -rf /tmp/artifacts &amp;&amp; mkdir -p /tmp/artifacts &amp;&amp; unzip /tmp/artifact.zip -d /tmp/artifacts&quot;</div><div class=\"line\">    // Notify AWS CodePipeline of a successful job</div><div class=\"line\">    var putJobSuccess = function(message) &#123;</div><div class=\"line\">        console.log(&quot;Success&quot; + message);</div><div class=\"line\">        AWS.config.update(&#123;region: &apos;us-east-1&apos;&#125;);</div><div class=\"line\">        var params = &#123;</div><div class=\"line\">            jobId: jobId</div><div class=\"line\">        &#125;;</div><div class=\"line\">        codepipeline.putJobSuccessResult(params, function(err, data) &#123;</div><div class=\"line\">            if(err) &#123;</div><div class=\"line\">                context.fail(err);      </div><div class=\"line\">            &#125; else &#123;</div><div class=\"line\">                context.succeed(message);      </div><div class=\"line\">            &#125;</div><div class=\"line\">        &#125;);</div><div class=\"line\">    &#125;;</div><div class=\"line\">    </div><div class=\"line\">    // Notify AWS CodePipeline of a failed job</div><div class=\"line\">    var putJobFailure = function(message) &#123;</div><div class=\"line\">        console.log(&quot;Failure&quot; + message);</div><div class=\"line\">        var params = &#123;</div><div class=\"line\">            jobId: jobId,</div><div class=\"line\">            failureDetails: &#123;</div><div class=\"line\">                message: JSON.stringify(message),</div><div class=\"line\">                type: &apos;JobFailed&apos;,</div><div class=\"line\">                externalExecutionId: context.invokeid</div><div class=\"line\">            &#125;</div><div class=\"line\">        &#125;;</div><div class=\"line\">        AWS.config.update(&#123;region: &apos;us-east-1&apos;&#125;);</div><div class=\"line\">        codepipeline.putJobFailureResult(params, function(err, data) &#123;</div><div class=\"line\">            context.fail(message);      </div><div class=\"line\">        &#125;);</div><div class=\"line\">    &#125;;</div><div class=\"line\">    //We can start with pulling the artifacts</div><div class=\"line\">    s3.getObject(params, function(err, data) &#123;</div><div class=\"line\">    if (err) putJobFailure(err);</div><div class=\"line\">    else &#123;</div><div class=\"line\">        //writing the artifacts to the /tmp/ , we have access to only this directory</div><div class=\"line\">        fs.writeFile(&quot;/tmp/artifact.zip&quot;, data.Body, function(err) &#123;</div><div class=\"line\">            if (err) putJobFailure(err);</div><div class=\"line\">            else &#123;</div><div class=\"line\">                const child = exec(unzipCommand, (error) =&gt; &#123;</div><div class=\"line\">                    var taskDefinition = require(&apos;/tmp/artifacts/task-definition.json&apos;);</div><div class=\"line\">                    var serviceDefinition = require(&apos;/tmp/artifacts/service-definition.json&apos;);</div><div class=\"line\">                    console.log(serviceDefinition);</div><div class=\"line\">                    var params = &#123;</div><div class=\"line\">                        desiredCount: 2, </div><div class=\"line\">                        service: serviceDefinition.serviceName,</div><div class=\"line\">                        cluster: serviceDefinition.cluster,</div><div class=\"line\">                    &#125;;</div><div class=\"line\">                    ecs.updateService(params, function(err, data) &#123;</div><div class=\"line\">                        if (err) &#123;</div><div class=\"line\">                            console.log(err);</div><div class=\"line\">                            console.log(params);</div><div class=\"line\">                            ecs.createService(serviceDefinition, function(err, data) &#123;</div><div class=\"line\">                                if (err) putJobFailure(err);</div><div class=\"line\">                                else putJobSuccess(&quot;Successfully launched the service&quot;);</div><div class=\"line\">                            &#125;);</div><div class=\"line\">                            </div><div class=\"line\">                        &#125; else putJobSuccess(&quot;Successfully launched the service&quot;);</div><div class=\"line\">                    &#125;);</div><div class=\"line\">                    callback(null, &apos;Process complete!&apos;);</div><div class=\"line\">                &#125;);</div><div class=\"line\">                child.stdout.on(&apos;data&apos;, console.log);</div><div class=\"line\">                child.stderr.on(&apos;data&apos;, console.error);</div><div class=\"line\">            &#125;</div><div class=\"line\">        &#125;);</div><div class=\"line\">        &#125;</div><div class=\"line\"></div><div class=\"line\">    &#125;);</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure>\n"},{"title":"CI/CD pipeline for ECS with AWS Developer tools","date":"2016-12-21T09:15:38.000Z","_content":"### CI/CD pipeline for ECS with AWS Developer tools\nWe can use the AWS developer tools to Automate the app deployment to ECS clustor. This can help us to achieve a serveless architecture compared to the usual Jenkins automations.\n\n### The Components that we use.\n\n1. AWS ECS Cluster \n2. AWS CodeBuild\n3. AWS Lambda\n4. AWS CodePipeline.\n5. AWS ECR\n\n### AWS ECS Cluster\nWe can use the cloudformation template https://github.com/microservices-today/IaC-ecs to create an ECS cluster.\n### AWS ECR\nThe docker images to be deployed to ECS Cluster are stored in the ECR repository. We need to create a repository for \neach of the custom application that we are hosting on ECS. You can follow these [steps](../ECR) to create a new ECR Repository.\n### AWS CodeBuild\nWe build the docker image and push to the ECR with the latest tag using AWS Codebuild. You can follow [these](../AwsCodebuild) steps to create CodeBuild\n\n### AWS Lambda\n\nThe AWS Lambda can be used as a part of our pipeline for updating task and service definition. You can follow [these](../Awslamda)\n\n### AWS CodePipeline\nThe components are added to the CodePipeline in to complete the CI/CD pipeline. You can follow [these](../AwsCodepipeline) steps to create Codepipeline.\n","source":"_posts/aws-dev-tools/CI-CD-with-AWS-developer-tools.md","raw":"---\ntitle: CI/CD pipeline for ECS with AWS Developer tools\ndate: 2016-12-21 14:45:38\ntags: AWS Developer tools\n---\n### CI/CD pipeline for ECS with AWS Developer tools\nWe can use the AWS developer tools to Automate the app deployment to ECS clustor. This can help us to achieve a serveless architecture compared to the usual Jenkins automations.\n\n### The Components that we use.\n\n1. AWS ECS Cluster \n2. AWS CodeBuild\n3. AWS Lambda\n4. AWS CodePipeline.\n5. AWS ECR\n\n### AWS ECS Cluster\nWe can use the cloudformation template https://github.com/microservices-today/IaC-ecs to create an ECS cluster.\n### AWS ECR\nThe docker images to be deployed to ECS Cluster are stored in the ECR repository. We need to create a repository for \neach of the custom application that we are hosting on ECS. You can follow these [steps](../ECR) to create a new ECR Repository.\n### AWS CodeBuild\nWe build the docker image and push to the ECR with the latest tag using AWS Codebuild. You can follow [these](../AwsCodebuild) steps to create CodeBuild\n\n### AWS Lambda\n\nThe AWS Lambda can be used as a part of our pipeline for updating task and service definition. You can follow [these](../Awslamda)\n\n### AWS CodePipeline\nThe components are added to the CodePipeline in to complete the CI/CD pipeline. You can follow [these](../AwsCodepipeline) steps to create Codepipeline.\n","slug":"aws-dev-tools/CI-CD-with-AWS-developer-tools","published":1,"updated":"2017-01-04T04:33:28.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cixigfrju000qf33pwfl9cv0c","content":"<h3 id=\"CI-CD-pipeline-for-ECS-with-AWS-Developer-tools\"><a href=\"#CI-CD-pipeline-for-ECS-with-AWS-Developer-tools\" class=\"headerlink\" title=\"CI/CD pipeline for ECS with AWS Developer tools\"></a>CI/CD pipeline for ECS with AWS Developer tools</h3><p>We can use the AWS developer tools to Automate the app deployment to ECS clustor. This can help us to achieve a serveless architecture compared to the usual Jenkins automations.</p>\n<h3 id=\"The-Components-that-we-use\"><a href=\"#The-Components-that-we-use\" class=\"headerlink\" title=\"The Components that we use.\"></a>The Components that we use.</h3><ol>\n<li>AWS ECS Cluster </li>\n<li>AWS CodeBuild</li>\n<li>AWS Lambda</li>\n<li>AWS CodePipeline.</li>\n<li>AWS ECR</li>\n</ol>\n<h3 id=\"AWS-ECS-Cluster\"><a href=\"#AWS-ECS-Cluster\" class=\"headerlink\" title=\"AWS ECS Cluster\"></a>AWS ECS Cluster</h3><p>We can use the cloudformation template <a href=\"https://github.com/microservices-today/IaC-ecs\" target=\"_blank\" rel=\"external\">https://github.com/microservices-today/IaC-ecs</a> to create an ECS cluster.</p>\n<h3 id=\"AWS-ECR\"><a href=\"#AWS-ECR\" class=\"headerlink\" title=\"AWS ECR\"></a>AWS ECR</h3><p>The docker images to be deployed to ECS Cluster are stored in the ECR repository. We need to create a repository for<br>each of the custom application that we are hosting on ECS. You can follow these <a href=\"../ECR\">steps</a> to create a new ECR Repository.</p>\n<h3 id=\"AWS-CodeBuild\"><a href=\"#AWS-CodeBuild\" class=\"headerlink\" title=\"AWS CodeBuild\"></a>AWS CodeBuild</h3><p>We build the docker image and push to the ECR with the latest tag using AWS Codebuild. You can follow <a href=\"../AwsCodebuild\">these</a> steps to create CodeBuild</p>\n<h3 id=\"AWS-Lambda\"><a href=\"#AWS-Lambda\" class=\"headerlink\" title=\"AWS Lambda\"></a>AWS Lambda</h3><p>The AWS Lambda can be used as a part of our pipeline for updating task and service definition. You can follow <a href=\"../Awslamda\">these</a></p>\n<h3 id=\"AWS-CodePipeline\"><a href=\"#AWS-CodePipeline\" class=\"headerlink\" title=\"AWS CodePipeline\"></a>AWS CodePipeline</h3><p>The components are added to the CodePipeline in to complete the CI/CD pipeline. You can follow <a href=\"../AwsCodepipeline\">these</a> steps to create Codepipeline.</p>\n","excerpt":"","more":"<h3 id=\"CI-CD-pipeline-for-ECS-with-AWS-Developer-tools\"><a href=\"#CI-CD-pipeline-for-ECS-with-AWS-Developer-tools\" class=\"headerlink\" title=\"CI/CD pipeline for ECS with AWS Developer tools\"></a>CI/CD pipeline for ECS with AWS Developer tools</h3><p>We can use the AWS developer tools to Automate the app deployment to ECS clustor. This can help us to achieve a serveless architecture compared to the usual Jenkins automations.</p>\n<h3 id=\"The-Components-that-we-use\"><a href=\"#The-Components-that-we-use\" class=\"headerlink\" title=\"The Components that we use.\"></a>The Components that we use.</h3><ol>\n<li>AWS ECS Cluster </li>\n<li>AWS CodeBuild</li>\n<li>AWS Lambda</li>\n<li>AWS CodePipeline.</li>\n<li>AWS ECR</li>\n</ol>\n<h3 id=\"AWS-ECS-Cluster\"><a href=\"#AWS-ECS-Cluster\" class=\"headerlink\" title=\"AWS ECS Cluster\"></a>AWS ECS Cluster</h3><p>We can use the cloudformation template <a href=\"https://github.com/microservices-today/IaC-ecs\">https://github.com/microservices-today/IaC-ecs</a> to create an ECS cluster.</p>\n<h3 id=\"AWS-ECR\"><a href=\"#AWS-ECR\" class=\"headerlink\" title=\"AWS ECR\"></a>AWS ECR</h3><p>The docker images to be deployed to ECS Cluster are stored in the ECR repository. We need to create a repository for<br>each of the custom application that we are hosting on ECS. You can follow these <a href=\"../ECR\">steps</a> to create a new ECR Repository.</p>\n<h3 id=\"AWS-CodeBuild\"><a href=\"#AWS-CodeBuild\" class=\"headerlink\" title=\"AWS CodeBuild\"></a>AWS CodeBuild</h3><p>We build the docker image and push to the ECR with the latest tag using AWS Codebuild. You can follow <a href=\"../AwsCodebuild\">these</a> steps to create CodeBuild</p>\n<h3 id=\"AWS-Lambda\"><a href=\"#AWS-Lambda\" class=\"headerlink\" title=\"AWS Lambda\"></a>AWS Lambda</h3><p>The AWS Lambda can be used as a part of our pipeline for updating task and service definition. You can follow <a href=\"../Awslamda\">these</a></p>\n<h3 id=\"AWS-CodePipeline\"><a href=\"#AWS-CodePipeline\" class=\"headerlink\" title=\"AWS CodePipeline\"></a>AWS CodePipeline</h3><p>The components are added to the CodePipeline in to complete the CI/CD pipeline. You can follow <a href=\"../AwsCodepipeline\">these</a> steps to create Codepipeline.</p>\n"},{"title":"ECR Repository Creation","date":"2016-12-21T09:15:38.000Z","_content":"### Steps to create an ECR Repository.\n1. Goto to https://console.aws.amazon.com/ecs/home#/repositories/create/new\n![image](../../images/aws-dev-tools/ecr/ecr-creation-step-1.png)\n2. Copy the ECR Repository URI for later use and Finish the step.\n![image](../../images/aws-dev-tools/ecr/ecr-creation-step-2.png)\n","source":"_posts/aws-dev-tools/ECR.md","raw":"---\ntitle: ECR Repository Creation\ndate: 2016-12-21 14:45:38\ntags: AWS Developer tools\n---\n### Steps to create an ECR Repository.\n1. Goto to https://console.aws.amazon.com/ecs/home#/repositories/create/new\n![image](../../images/aws-dev-tools/ecr/ecr-creation-step-1.png)\n2. Copy the ECR Repository URI for later use and Finish the step.\n![image](../../images/aws-dev-tools/ecr/ecr-creation-step-2.png)\n","slug":"aws-dev-tools/ECR","published":1,"updated":"2017-01-04T10:54:27.926Z","_id":"cixigfrjv000sf33pusfnvix9","comments":1,"layout":"post","photos":[],"link":"","content":"<h3 id=\"Steps-to-create-an-ECR-Repository\"><a href=\"#Steps-to-create-an-ECR-Repository\" class=\"headerlink\" title=\"Steps to create an ECR Repository.\"></a>Steps to create an ECR Repository.</h3><ol>\n<li>Goto to <a href=\"https://console.aws.amazon.com/ecs/home#/repositories/create/new\" target=\"_blank\" rel=\"external\">https://console.aws.amazon.com/ecs/home#/repositories/create/new</a><br><img src=\"../../images/aws-dev-tools/ecr/ecr-creation-step-1.png\" alt=\"image\"></li>\n<li>Copy the ECR Repository URI for later use and Finish the step.<br><img src=\"../../images/aws-dev-tools/ecr/ecr-creation-step-2.png\" alt=\"image\"></li>\n</ol>\n","excerpt":"","more":"<h3 id=\"Steps-to-create-an-ECR-Repository\"><a href=\"#Steps-to-create-an-ECR-Repository\" class=\"headerlink\" title=\"Steps to create an ECR Repository.\"></a>Steps to create an ECR Repository.</h3><ol>\n<li>Goto to <a href=\"https://console.aws.amazon.com/ecs/home#/repositories/create/new\">https://console.aws.amazon.com/ecs/home#/repositories/create/new</a><br><img src=\"../../images/aws-dev-tools/ecr/ecr-creation-step-1.png\" alt=\"image\"></li>\n<li>Copy the ECR Repository URI for later use and Finish the step.<br><img src=\"../../images/aws-dev-tools/ecr/ecr-creation-step-2.png\" alt=\"image\"></li>\n</ol>\n"},{"title":"CloudFormation","date":"2017-01-03T09:15:56.000Z","git":"https://github.com/microservices-today/website-source","_content":"### Overview\nThis post explains AWS CloudFormation concepts. \nAWS CloudFormation provides an easy way to create and manage a collection of AWS resources. This allows us to version control our AWS infrastructure. You only pay for the resources you create.\n\n![CloudFormation Components](../../images/cloudformation/CloudFormation_Components.png)\n\n### CloudFormation Template\n\nWe use CloudFormation Templates to create service or application architectures and have CloudFormation use those templates for quick and reliable provisioning of the services or applications.\nThese are formatted text files in JSON or YAML. These templates describe the resources that you want to provision in your AWS CloudFormation stacks. \n\n![Parameters](../../images/cloudformation/Template1.png)\n![Resources](../../images/cloudformation/Template2.png)\n![Outputs](../../images/cloudformation/Template3.png)\n![Template YAML](../../images/cloudformation/Template_YAML.png)\n\n### AWS CloudFromation Designer\n\nAWS CloudFormation Designer is a graphic tool for creating, viewing, and modifying AWS CloudFormation templates.\n\nThe following figure illustrates the Designer panes and its main components.\n![Designer Panes](../../images/cloudformation/Designer.png)\n\n a. Canvas Pane: Displays template resources as diagram.\n b. Resource types pane: Lists all of the template resources that you can add to your template.\n c. JSON Editor: Here you specify the details of your template, such as resource properties or template parameters\n d. Errors Pane: Errors pane displays validation errors.\n e. Full screen and Split screen buttons: Buttons to select different views of Designer.\n f. Fit to window button: A button that resizes the canvas pane to fit your template's diagram.\n g. Toolbar: Provides quick access to commands for common actions, such as opening and saving templates.\n\n\n### CloudFormation Framework\n\nFramework, creates, updates, deletes stack \nThe AWS CloudFormation framework creates, updates and deletes CloudFormation Stacks. It provisions and configures resources by making calls to AWS resources that are described in your template. If stack creation fails, AWS CloudFormation rolls back your changes by deleting the resources that it created.\n\n##### Getting Started\n\na. Pick a template \n\tYou will need a template that specifies the resources that you want in your stack. You can create them either using Designer, or you can upload your template file created locally to S3 Bucket.\nb. Make sure your template is valid and have all the required dependent resources required for your stack.\nc. Create Stack\n\t- Sign in to the AWS Management Console and open the AWS CloudFormation console at https://console.aws.amazon.com/cloudformation/.\n\t- If this is a new AWS CloudFormation account, click Create New Stack. Otherwise, click Create Stack.\n\t- In the Template section, you can either design your template or choose a template (local file or S3 URL).\n\t- In the Specify Details section, enter the stack name. The stack name cannot contain spaces.\n\t- In the Parameters Section, specify all the required parameters.\n\t- Click Next\n\t- If required, you can add some tags to identify your stack.\n\t- Review the information for the stack. When you're satisfied with the settings, click Create.\nd. Monitor the progress of the stack creation.\n\tTo view the events for the stack, select your stack and in the Stack Details pane, click the Events tab.\ne. Use your stack resources.\n\tWhen the stack has a status of CREATE_COMPLETE, AWS CloudFormation has finished creating the stack, and you can start using its resources.\nf. Clean Up\n\tTo delete the stack and its resources, from the AWS CloudFormation console, select the stack and click Delete.\n\tIn the same way you monitored the creation of the stack, you can monitor its deletion by using the Event tab.\n\n\n\n","source":"_posts/cloudformation/CloudFormation.md","raw":"---\ntitle: CloudFormation\ndate: 2017-01-03 14:45:56\ngit: https://github.com/microservices-today/website-source\n---\n### Overview\nThis post explains AWS CloudFormation concepts. \nAWS CloudFormation provides an easy way to create and manage a collection of AWS resources. This allows us to version control our AWS infrastructure. You only pay for the resources you create.\n\n![CloudFormation Components](../../images/cloudformation/CloudFormation_Components.png)\n\n### CloudFormation Template\n\nWe use CloudFormation Templates to create service or application architectures and have CloudFormation use those templates for quick and reliable provisioning of the services or applications.\nThese are formatted text files in JSON or YAML. These templates describe the resources that you want to provision in your AWS CloudFormation stacks. \n\n![Parameters](../../images/cloudformation/Template1.png)\n![Resources](../../images/cloudformation/Template2.png)\n![Outputs](../../images/cloudformation/Template3.png)\n![Template YAML](../../images/cloudformation/Template_YAML.png)\n\n### AWS CloudFromation Designer\n\nAWS CloudFormation Designer is a graphic tool for creating, viewing, and modifying AWS CloudFormation templates.\n\nThe following figure illustrates the Designer panes and its main components.\n![Designer Panes](../../images/cloudformation/Designer.png)\n\n a. Canvas Pane: Displays template resources as diagram.\n b. Resource types pane: Lists all of the template resources that you can add to your template.\n c. JSON Editor: Here you specify the details of your template, such as resource properties or template parameters\n d. Errors Pane: Errors pane displays validation errors.\n e. Full screen and Split screen buttons: Buttons to select different views of Designer.\n f. Fit to window button: A button that resizes the canvas pane to fit your template's diagram.\n g. Toolbar: Provides quick access to commands for common actions, such as opening and saving templates.\n\n\n### CloudFormation Framework\n\nFramework, creates, updates, deletes stack \nThe AWS CloudFormation framework creates, updates and deletes CloudFormation Stacks. It provisions and configures resources by making calls to AWS resources that are described in your template. If stack creation fails, AWS CloudFormation rolls back your changes by deleting the resources that it created.\n\n##### Getting Started\n\na. Pick a template \n\tYou will need a template that specifies the resources that you want in your stack. You can create them either using Designer, or you can upload your template file created locally to S3 Bucket.\nb. Make sure your template is valid and have all the required dependent resources required for your stack.\nc. Create Stack\n\t- Sign in to the AWS Management Console and open the AWS CloudFormation console at https://console.aws.amazon.com/cloudformation/.\n\t- If this is a new AWS CloudFormation account, click Create New Stack. Otherwise, click Create Stack.\n\t- In the Template section, you can either design your template or choose a template (local file or S3 URL).\n\t- In the Specify Details section, enter the stack name. The stack name cannot contain spaces.\n\t- In the Parameters Section, specify all the required parameters.\n\t- Click Next\n\t- If required, you can add some tags to identify your stack.\n\t- Review the information for the stack. When you're satisfied with the settings, click Create.\nd. Monitor the progress of the stack creation.\n\tTo view the events for the stack, select your stack and in the Stack Details pane, click the Events tab.\ne. Use your stack resources.\n\tWhen the stack has a status of CREATE_COMPLETE, AWS CloudFormation has finished creating the stack, and you can start using its resources.\nf. Clean Up\n\tTo delete the stack and its resources, from the AWS CloudFormation console, select the stack and click Delete.\n\tIn the same way you monitored the creation of the stack, you can monitor its deletion by using the Event tab.\n\n\n\n","slug":"cloudformation/CloudFormation","published":1,"updated":"2017-01-04T10:53:44.342Z","_id":"cixigfrjw000uf33pypokwp25","comments":1,"layout":"post","photos":[],"link":"","content":"<h3 id=\"Overview\"><a href=\"#Overview\" class=\"headerlink\" title=\"Overview\"></a>Overview</h3><p>This post explains AWS CloudFormation concepts.<br>AWS CloudFormation provides an easy way to create and manage a collection of AWS resources. This allows us to version control our AWS infrastructure. You only pay for the resources you create.</p>\n<p><img src=\"../../images/cloudformation/CloudFormation_Components.png\" alt=\"CloudFormation Components\"></p>\n<h3 id=\"CloudFormation-Template\"><a href=\"#CloudFormation-Template\" class=\"headerlink\" title=\"CloudFormation Template\"></a>CloudFormation Template</h3><p>We use CloudFormation Templates to create service or application architectures and have CloudFormation use those templates for quick and reliable provisioning of the services or applications.<br>These are formatted text files in JSON or YAML. These templates describe the resources that you want to provision in your AWS CloudFormation stacks. </p>\n<p><img src=\"../../images/cloudformation/Template1.png\" alt=\"Parameters\"><br><img src=\"../../images/cloudformation/Template2.png\" alt=\"Resources\"><br><img src=\"../../images/cloudformation/Template3.png\" alt=\"Outputs\"><br><img src=\"../../images/cloudformation/Template_YAML.png\" alt=\"Template YAML\"></p>\n<h3 id=\"AWS-CloudFromation-Designer\"><a href=\"#AWS-CloudFromation-Designer\" class=\"headerlink\" title=\"AWS CloudFromation Designer\"></a>AWS CloudFromation Designer</h3><p>AWS CloudFormation Designer is a graphic tool for creating, viewing, and modifying AWS CloudFormation templates.</p>\n<p>The following figure illustrates the Designer panes and its main components.<br><img src=\"../../images/cloudformation/Designer.png\" alt=\"Designer Panes\"></p>\n<p> a. Canvas Pane: Displays template resources as diagram.<br> b. Resource types pane: Lists all of the template resources that you can add to your template.<br> c. JSON Editor: Here you specify the details of your template, such as resource properties or template parameters<br> d. Errors Pane: Errors pane displays validation errors.<br> e. Full screen and Split screen buttons: Buttons to select different views of Designer.<br> f. Fit to window button: A button that resizes the canvas pane to fit your template’s diagram.<br> g. Toolbar: Provides quick access to commands for common actions, such as opening and saving templates.</p>\n<h3 id=\"CloudFormation-Framework\"><a href=\"#CloudFormation-Framework\" class=\"headerlink\" title=\"CloudFormation Framework\"></a>CloudFormation Framework</h3><p>Framework, creates, updates, deletes stack<br>The AWS CloudFormation framework creates, updates and deletes CloudFormation Stacks. It provisions and configures resources by making calls to AWS resources that are described in your template. If stack creation fails, AWS CloudFormation rolls back your changes by deleting the resources that it created.</p>\n<h5 id=\"Getting-Started\"><a href=\"#Getting-Started\" class=\"headerlink\" title=\"Getting Started\"></a>Getting Started</h5><p>a. Pick a template<br>    You will need a template that specifies the resources that you want in your stack. You can create them either using Designer, or you can upload your template file created locally to S3 Bucket.<br>b. Make sure your template is valid and have all the required dependent resources required for your stack.<br>c. Create Stack</p>\n<pre><code>- Sign in to the AWS Management Console and open the AWS CloudFormation console at https://console.aws.amazon.com/cloudformation/.\n- If this is a new AWS CloudFormation account, click Create New Stack. Otherwise, click Create Stack.\n- In the Template section, you can either design your template or choose a template (local file or S3 URL).\n- In the Specify Details section, enter the stack name. The stack name cannot contain spaces.\n- In the Parameters Section, specify all the required parameters.\n- Click Next\n- If required, you can add some tags to identify your stack.\n- Review the information for the stack. When you&apos;re satisfied with the settings, click Create.\n</code></pre><p>d. Monitor the progress of the stack creation.<br>    To view the events for the stack, select your stack and in the Stack Details pane, click the Events tab.<br>e. Use your stack resources.<br>    When the stack has a status of CREATE_COMPLETE, AWS CloudFormation has finished creating the stack, and you can start using its resources.<br>f. Clean Up<br>    To delete the stack and its resources, from the AWS CloudFormation console, select the stack and click Delete.<br>    In the same way you monitored the creation of the stack, you can monitor its deletion by using the Event tab.</p>\n","excerpt":"","more":"<h3 id=\"Overview\"><a href=\"#Overview\" class=\"headerlink\" title=\"Overview\"></a>Overview</h3><p>This post explains AWS CloudFormation concepts.<br>AWS CloudFormation provides an easy way to create and manage a collection of AWS resources. This allows us to version control our AWS infrastructure. You only pay for the resources you create.</p>\n<p><img src=\"../../images/cloudformation/CloudFormation_Components.png\" alt=\"CloudFormation Components\"></p>\n<h3 id=\"CloudFormation-Template\"><a href=\"#CloudFormation-Template\" class=\"headerlink\" title=\"CloudFormation Template\"></a>CloudFormation Template</h3><p>We use CloudFormation Templates to create service or application architectures and have CloudFormation use those templates for quick and reliable provisioning of the services or applications.<br>These are formatted text files in JSON or YAML. These templates describe the resources that you want to provision in your AWS CloudFormation stacks. </p>\n<p><img src=\"../../images/cloudformation/Template1.png\" alt=\"Parameters\"><br><img src=\"../../images/cloudformation/Template2.png\" alt=\"Resources\"><br><img src=\"../../images/cloudformation/Template3.png\" alt=\"Outputs\"><br><img src=\"../../images/cloudformation/Template_YAML.png\" alt=\"Template YAML\"></p>\n<h3 id=\"AWS-CloudFromation-Designer\"><a href=\"#AWS-CloudFromation-Designer\" class=\"headerlink\" title=\"AWS CloudFromation Designer\"></a>AWS CloudFromation Designer</h3><p>AWS CloudFormation Designer is a graphic tool for creating, viewing, and modifying AWS CloudFormation templates.</p>\n<p>The following figure illustrates the Designer panes and its main components.<br><img src=\"../../images/cloudformation/Designer.png\" alt=\"Designer Panes\"></p>\n<p> a. Canvas Pane: Displays template resources as diagram.<br> b. Resource types pane: Lists all of the template resources that you can add to your template.<br> c. JSON Editor: Here you specify the details of your template, such as resource properties or template parameters<br> d. Errors Pane: Errors pane displays validation errors.<br> e. Full screen and Split screen buttons: Buttons to select different views of Designer.<br> f. Fit to window button: A button that resizes the canvas pane to fit your template’s diagram.<br> g. Toolbar: Provides quick access to commands for common actions, such as opening and saving templates.</p>\n<h3 id=\"CloudFormation-Framework\"><a href=\"#CloudFormation-Framework\" class=\"headerlink\" title=\"CloudFormation Framework\"></a>CloudFormation Framework</h3><p>Framework, creates, updates, deletes stack<br>The AWS CloudFormation framework creates, updates and deletes CloudFormation Stacks. It provisions and configures resources by making calls to AWS resources that are described in your template. If stack creation fails, AWS CloudFormation rolls back your changes by deleting the resources that it created.</p>\n<h5 id=\"Getting-Started\"><a href=\"#Getting-Started\" class=\"headerlink\" title=\"Getting Started\"></a>Getting Started</h5><p>a. Pick a template<br>    You will need a template that specifies the resources that you want in your stack. You can create them either using Designer, or you can upload your template file created locally to S3 Bucket.<br>b. Make sure your template is valid and have all the required dependent resources required for your stack.<br>c. Create Stack</p>\n<pre><code>- Sign in to the AWS Management Console and open the AWS CloudFormation console at https://console.aws.amazon.com/cloudformation/.\n- If this is a new AWS CloudFormation account, click Create New Stack. Otherwise, click Create Stack.\n- In the Template section, you can either design your template or choose a template (local file or S3 URL).\n- In the Specify Details section, enter the stack name. The stack name cannot contain spaces.\n- In the Parameters Section, specify all the required parameters.\n- Click Next\n- If required, you can add some tags to identify your stack.\n- Review the information for the stack. When you&apos;re satisfied with the settings, click Create.\n</code></pre><p>d. Monitor the progress of the stack creation.<br>    To view the events for the stack, select your stack and in the Stack Details pane, click the Events tab.<br>e. Use your stack resources.<br>    When the stack has a status of CREATE_COMPLETE, AWS CloudFormation has finished creating the stack, and you can start using its resources.<br>f. Clean Up<br>    To delete the stack and its resources, from the AWS CloudFormation console, select the stack and click Delete.<br>    In the same way you monitored the creation of the stack, you can monitor its deletion by using the Event tab.</p>\n"},{"title":"Creating alerts for marathon and marathon app failure","date":"2016-11-15T09:53:00.000Z","_content":"\nCreating alerts for marathon and marathon app failure\n\n### Creating alerts for marathon failure\n\n1. Under Explore tab select Server -> Overview.\n2. Choose Group by `mesos.framework.name`.\n3. Click on the bell button next to marathon framework ( marathon [<ip>:8080] ) from the list. A new alert popup will appear.\n4. Under `Set the condition` choose type as `manual`\n5. For `Alert when` option Choose `Entity is down`.\n6. Leave `Where` option unchecked.\n7. Choose the minimum monitoring value as `1 min`.\n8. Specify the Name, Description and Severity of the alert.\n9. Enable the notification channel.\n10. Enable automatic sysdig capture if necessary.\n11. Click Create button.\n\n\n![Creating alerts for marathon failure](../../images/sysdig/Creating-alerts-for-marathon-failure.png)\n\nWhile grouping with `mesos.framework.name` on sysdig, it lists marathon from work running on one of the masters ( marathon [<ip>:8080] ). But the ip showing in the list might change when marathon is restarted. In that case we need to create alert for new listing name also. For solving this issue, we need to create alert for each of the master nodes. \nIn order to do that:\n- Go to Alerts page and select the alert we have created from above steps. Click copy for creating a similar alert. \n- Modify the master ip from the scope manually. \n- Specify the ip of another master and create a new alert. \n- Similarly create alert for each of the master nodes.\n\n![Set the scope of nodes to watch](../../images/sysdig/Creating-alerts-for-marathon-failure2.png)\n\n\n### Creating alerts for marathon app failure\n1. Under Explore tab select Server -> Overview.\n2. Choose Group by `agent.tag.dcosName`.\n3. Click on the bell button next to your dcos name \n\n    a. A new alert popup will appear.\n\n4. Under `Set the condition` choose type as `manual`\n5. For `Alert when` option Choose `Entity is down`.\n6. For `Segmented by` option choose second radio button and select `Any of` from dropdown. Select the filter metrics `marathon.app.name` from the dropdown.\n7. Leave `Where` option unchecked.\n8. Choose the minimum monitoring value as `1 min`.\n9. Specify the Name, Description and Severity of the alert.\n10. Enable the notification channel.\n11. Enable automatic sysdig capture if necessary.\n12. Click Create button.\n\n![Creating alerts for marathon app failure](../../images/sysdig/Creating-alerts-for-marathon-app-failure.png)\n\n\n","source":"_posts/sysdig/Creating-alert-for-marathon-and-marathon-app-failure.md","raw":"---\ntitle: Creating alerts for marathon and marathon app failure\ndate: 2016-11-15 15:23:00\ntags:\ncategories: sysdig\n---\n\nCreating alerts for marathon and marathon app failure\n\n### Creating alerts for marathon failure\n\n1. Under Explore tab select Server -> Overview.\n2. Choose Group by `mesos.framework.name`.\n3. Click on the bell button next to marathon framework ( marathon [<ip>:8080] ) from the list. A new alert popup will appear.\n4. Under `Set the condition` choose type as `manual`\n5. For `Alert when` option Choose `Entity is down`.\n6. Leave `Where` option unchecked.\n7. Choose the minimum monitoring value as `1 min`.\n8. Specify the Name, Description and Severity of the alert.\n9. Enable the notification channel.\n10. Enable automatic sysdig capture if necessary.\n11. Click Create button.\n\n\n![Creating alerts for marathon failure](../../images/sysdig/Creating-alerts-for-marathon-failure.png)\n\nWhile grouping with `mesos.framework.name` on sysdig, it lists marathon from work running on one of the masters ( marathon [<ip>:8080] ). But the ip showing in the list might change when marathon is restarted. In that case we need to create alert for new listing name also. For solving this issue, we need to create alert for each of the master nodes. \nIn order to do that:\n- Go to Alerts page and select the alert we have created from above steps. Click copy for creating a similar alert. \n- Modify the master ip from the scope manually. \n- Specify the ip of another master and create a new alert. \n- Similarly create alert for each of the master nodes.\n\n![Set the scope of nodes to watch](../../images/sysdig/Creating-alerts-for-marathon-failure2.png)\n\n\n### Creating alerts for marathon app failure\n1. Under Explore tab select Server -> Overview.\n2. Choose Group by `agent.tag.dcosName`.\n3. Click on the bell button next to your dcos name \n\n    a. A new alert popup will appear.\n\n4. Under `Set the condition` choose type as `manual`\n5. For `Alert when` option Choose `Entity is down`.\n6. For `Segmented by` option choose second radio button and select `Any of` from dropdown. Select the filter metrics `marathon.app.name` from the dropdown.\n7. Leave `Where` option unchecked.\n8. Choose the minimum monitoring value as `1 min`.\n9. Specify the Name, Description and Severity of the alert.\n10. Enable the notification channel.\n11. Enable automatic sysdig capture if necessary.\n12. Click Create button.\n\n![Creating alerts for marathon app failure](../../images/sysdig/Creating-alerts-for-marathon-app-failure.png)\n\n\n","slug":"sysdig/Creating-alert-for-marathon-and-marathon-app-failure","published":1,"updated":"2017-01-04T10:58:27.678Z","_id":"cixigfrjx000vf33phjhkfi2b","comments":1,"layout":"post","photos":[],"link":"","content":"<p>Creating alerts for marathon and marathon app failure</p>\n<h3 id=\"Creating-alerts-for-marathon-failure\"><a href=\"#Creating-alerts-for-marathon-failure\" class=\"headerlink\" title=\"Creating alerts for marathon failure\"></a>Creating alerts for marathon failure</h3><ol>\n<li>Under Explore tab select Server -&gt; Overview.</li>\n<li>Choose Group by <code>mesos.framework.name</code>.</li>\n<li>Click on the bell button next to marathon framework ( marathon [<ip>:8080] ) from the list. A new alert popup will appear.</ip></li>\n<li>Under <code>Set the condition</code> choose type as <code>manual</code></li>\n<li>For <code>Alert when</code> option Choose <code>Entity is down</code>.</li>\n<li>Leave <code>Where</code> option unchecked.</li>\n<li>Choose the minimum monitoring value as <code>1 min</code>.</li>\n<li>Specify the Name, Description and Severity of the alert.</li>\n<li>Enable the notification channel.</li>\n<li>Enable automatic sysdig capture if necessary.</li>\n<li>Click Create button.</li>\n</ol>\n<p><img src=\"../../images/sysdig/Creating-alerts-for-marathon-failure.png\" alt=\"Creating alerts for marathon failure\"></p>\n<p>While grouping with <code>mesos.framework.name</code> on sysdig, it lists marathon from work running on one of the masters ( marathon [<ip>:8080] ). But the ip showing in the list might change when marathon is restarted. In that case we need to create alert for new listing name also. For solving this issue, we need to create alert for each of the master nodes.<br>In order to do that:</ip></p>\n<ul>\n<li>Go to Alerts page and select the alert we have created from above steps. Click copy for creating a similar alert. </li>\n<li>Modify the master ip from the scope manually. </li>\n<li>Specify the ip of another master and create a new alert. </li>\n<li>Similarly create alert for each of the master nodes.</li>\n</ul>\n<p><img src=\"../../images/sysdig/Creating-alerts-for-marathon-failure2.png\" alt=\"Set the scope of nodes to watch\"></p>\n<h3 id=\"Creating-alerts-for-marathon-app-failure\"><a href=\"#Creating-alerts-for-marathon-app-failure\" class=\"headerlink\" title=\"Creating alerts for marathon app failure\"></a>Creating alerts for marathon app failure</h3><ol>\n<li>Under Explore tab select Server -&gt; Overview.</li>\n<li>Choose Group by <code>agent.tag.dcosName</code>.</li>\n<li><p>Click on the bell button next to your dcos name </p>\n<p> a. A new alert popup will appear.</p>\n</li>\n<li><p>Under <code>Set the condition</code> choose type as <code>manual</code></p>\n</li>\n<li>For <code>Alert when</code> option Choose <code>Entity is down</code>.</li>\n<li>For <code>Segmented by</code> option choose second radio button and select <code>Any of</code> from dropdown. Select the filter metrics <code>marathon.app.name</code> from the dropdown.</li>\n<li>Leave <code>Where</code> option unchecked.</li>\n<li>Choose the minimum monitoring value as <code>1 min</code>.</li>\n<li>Specify the Name, Description and Severity of the alert.</li>\n<li>Enable the notification channel.</li>\n<li>Enable automatic sysdig capture if necessary.</li>\n<li>Click Create button.</li>\n</ol>\n<p><img src=\"../../images/sysdig/Creating-alerts-for-marathon-app-failure.png\" alt=\"Creating alerts for marathon app failure\"></p>\n","excerpt":"","more":"<p>Creating alerts for marathon and marathon app failure</p>\n<h3 id=\"Creating-alerts-for-marathon-failure\"><a href=\"#Creating-alerts-for-marathon-failure\" class=\"headerlink\" title=\"Creating alerts for marathon failure\"></a>Creating alerts for marathon failure</h3><ol>\n<li>Under Explore tab select Server -&gt; Overview.</li>\n<li>Choose Group by <code>mesos.framework.name</code>.</li>\n<li>Click on the bell button next to marathon framework ( marathon [<ip>:8080] ) from the list. A new alert popup will appear.</li>\n<li>Under <code>Set the condition</code> choose type as <code>manual</code></li>\n<li>For <code>Alert when</code> option Choose <code>Entity is down</code>.</li>\n<li>Leave <code>Where</code> option unchecked.</li>\n<li>Choose the minimum monitoring value as <code>1 min</code>.</li>\n<li>Specify the Name, Description and Severity of the alert.</li>\n<li>Enable the notification channel.</li>\n<li>Enable automatic sysdig capture if necessary.</li>\n<li>Click Create button.</li>\n</ol>\n<p><img src=\"../../images/sysdig/Creating-alerts-for-marathon-failure.png\" alt=\"Creating alerts for marathon failure\"></p>\n<p>While grouping with <code>mesos.framework.name</code> on sysdig, it lists marathon from work running on one of the masters ( marathon [<ip>:8080] ). But the ip showing in the list might change when marathon is restarted. In that case we need to create alert for new listing name also. For solving this issue, we need to create alert for each of the master nodes.<br>In order to do that:</p>\n<ul>\n<li>Go to Alerts page and select the alert we have created from above steps. Click copy for creating a similar alert. </li>\n<li>Modify the master ip from the scope manually. </li>\n<li>Specify the ip of another master and create a new alert. </li>\n<li>Similarly create alert for each of the master nodes.</li>\n</ul>\n<p><img src=\"../../images/sysdig/Creating-alerts-for-marathon-failure2.png\" alt=\"Set the scope of nodes to watch\"></p>\n<h3 id=\"Creating-alerts-for-marathon-app-failure\"><a href=\"#Creating-alerts-for-marathon-app-failure\" class=\"headerlink\" title=\"Creating alerts for marathon app failure\"></a>Creating alerts for marathon app failure</h3><ol>\n<li>Under Explore tab select Server -&gt; Overview.</li>\n<li>Choose Group by <code>agent.tag.dcosName</code>.</li>\n<li><p>Click on the bell button next to your dcos name </p>\n<p> a. A new alert popup will appear.</p>\n</li>\n<li><p>Under <code>Set the condition</code> choose type as <code>manual</code></p>\n</li>\n<li>For <code>Alert when</code> option Choose <code>Entity is down</code>.</li>\n<li>For <code>Segmented by</code> option choose second radio button and select <code>Any of</code> from dropdown. Select the filter metrics <code>marathon.app.name</code> from the dropdown.</li>\n<li>Leave <code>Where</code> option unchecked.</li>\n<li>Choose the minimum monitoring value as <code>1 min</code>.</li>\n<li>Specify the Name, Description and Severity of the alert.</li>\n<li>Enable the notification channel.</li>\n<li>Enable automatic sysdig capture if necessary.</li>\n<li>Click Create button.</li>\n</ol>\n<p><img src=\"../../images/sysdig/Creating-alerts-for-marathon-app-failure.png\" alt=\"Creating alerts for marathon app failure\"></p>\n"},{"title":"Creating alert for marathon-lb timeouts","date":"2016-11-09T14:30:00.000Z","_content":"\nCreating alert for marathon-lb timeouts\n\n\n\n\nUnder Explore tab select Server -> Overview.\nChoose Group by `marathon.app.name`.\nClick on the bell button next to `marathon-lb`\nA new alert popup will appear.\nUnder `Set the condition` choose type as `manual`\nFor `Alert when` option Choose `net.request.time.out`. Assign threshold value.\nFor `Segmented by` option choose second radio button and select `Any of` from dropdown. Select the filter metrics `proc.name` from the dropdown.\nCheck `Where` option and `proc.name` is `haproxy` .\nChoose the minimum monitoring value as `1 min`.\nSpecify the Name, Description and Severity of the alert.\nEnable the notification channel.\nEnable automatic sysdig capture if necessary.\nClick Create button.\n\n\n![sysdig snapshot](../../images/marathon-lb-timeouts.png)\n\n\n\n","source":"_posts/sysdig/Creating-alert-for-marathon-lb-timeouts.md","raw":"---\ntitle: Creating alert for marathon-lb timeouts\ndate: 2016-11-09 20:00:00\ntags:\ncategories: sysdig\n---\n\nCreating alert for marathon-lb timeouts\n\n\n\n\nUnder Explore tab select Server -> Overview.\nChoose Group by `marathon.app.name`.\nClick on the bell button next to `marathon-lb`\nA new alert popup will appear.\nUnder `Set the condition` choose type as `manual`\nFor `Alert when` option Choose `net.request.time.out`. Assign threshold value.\nFor `Segmented by` option choose second radio button and select `Any of` from dropdown. Select the filter metrics `proc.name` from the dropdown.\nCheck `Where` option and `proc.name` is `haproxy` .\nChoose the minimum monitoring value as `1 min`.\nSpecify the Name, Description and Severity of the alert.\nEnable the notification channel.\nEnable automatic sysdig capture if necessary.\nClick Create button.\n\n\n![sysdig snapshot](../../images/marathon-lb-timeouts.png)\n\n\n\n","slug":"sysdig/Creating-alert-for-marathon-lb-timeouts","published":1,"updated":"2017-01-04T10:58:27.750Z","_id":"cixigfrjz000yf33plxqkpnke","comments":1,"layout":"post","photos":[],"link":"","content":"<p>Creating alert for marathon-lb timeouts</p>\n<p>Under Explore tab select Server -&gt; Overview.<br>Choose Group by <code>marathon.app.name</code>.<br>Click on the bell button next to <code>marathon-lb</code><br>A new alert popup will appear.<br>Under <code>Set the condition</code> choose type as <code>manual</code><br>For <code>Alert when</code> option Choose <code>net.request.time.out</code>. Assign threshold value.<br>For <code>Segmented by</code> option choose second radio button and select <code>Any of</code> from dropdown. Select the filter metrics <code>proc.name</code> from the dropdown.<br>Check <code>Where</code> option and <code>proc.name</code> is <code>haproxy</code> .<br>Choose the minimum monitoring value as <code>1 min</code>.<br>Specify the Name, Description and Severity of the alert.<br>Enable the notification channel.<br>Enable automatic sysdig capture if necessary.<br>Click Create button.</p>\n<p><img src=\"../../images/marathon-lb-timeouts.png\" alt=\"sysdig snapshot\"></p>\n","excerpt":"","more":"<p>Creating alert for marathon-lb timeouts</p>\n<p>Under Explore tab select Server -&gt; Overview.<br>Choose Group by <code>marathon.app.name</code>.<br>Click on the bell button next to <code>marathon-lb</code><br>A new alert popup will appear.<br>Under <code>Set the condition</code> choose type as <code>manual</code><br>For <code>Alert when</code> option Choose <code>net.request.time.out</code>. Assign threshold value.<br>For <code>Segmented by</code> option choose second radio button and select <code>Any of</code> from dropdown. Select the filter metrics <code>proc.name</code> from the dropdown.<br>Check <code>Where</code> option and <code>proc.name</code> is <code>haproxy</code> .<br>Choose the minimum monitoring value as <code>1 min</code>.<br>Specify the Name, Description and Severity of the alert.<br>Enable the notification channel.<br>Enable automatic sysdig capture if necessary.<br>Click Create button.</p>\n<p><img src=\"../../images/marathon-lb-timeouts.png\" alt=\"sysdig snapshot\"></p>\n"},{"title":"Disk utilization monitoring using Sysdig","date":"2016-11-12T10:22:00.000Z","_content":"\nDisk utilization monitoring using Sysdig\n\n\n### Creating a Dashboard tab\n\n1. Under Explore tab select Server -> Overview.\n2. Choose Group by host (host.mac).\n3. On Table columns configuration (gear icon) Select the following fields\n - `fs.used.percent` - FS Usage %\n - `fs.root.used.percent` - FS Root Usage %\n - `fs.largest.used.percent`  - FS Largest Usage %\n - `fs.bytes.total` - FS Size\n - `fs.bytes.free` - FS Free Space\n - `fs.bytes.used` - Disk Used Bytes\n4. Change the color coding by clicking on the gear icon of each of the columns. (default is yellow after 50% and red after 80%)\n5. Pin the tab to the dashboard.\n\n![creating a dashboard tab](../../images/sysdig/Disk-utilization-monitoring-using-Sysdig-dashboard-tab.png)\n\n\n### Creating an alert for 60% disk utilization\n\nThe following steps will help you to create an alert when the root directory (/) exceeds 60% of its usage:\n\n1. Under alert tab click add alert button\n2. Select the scope as `agent.tag.dcosName` or `region`. `agent.tag.dcosName` Is the tag we have added for the dcos cluster. `region` specify the aws region name. Assign the value for scope from the dropdown accordingly which one you selected as the scope.\n3. Under `Set the condition` choose type as `manual`\n4. For `Alert when` option Choose `fs.used.percent` as the metric > 60% as the threshold value.\n5. For `Segment by` choose second option, select `Any of` and `fs.mountDir` metric.\n![creating an alert for disk utilization](../../images/sysdig/Creating-alert-for-disk-utilization.png)\n6. Check the `Where` option and select `fs.mountDir` from the dropdown. Assign the value `/`\n![creating an alert for disk](../../images/sysdig/Creating-alert-for-disk-utilization2.png)\n7. Choose the minimum monitor value as `1 min`.\n8. Specify the Name, Description and Severity of the alert.\n9. Enable the notification channel.\n10. Enable automatic sysdig capture if necessary.\n11. Click Create button.\n\n","source":"_posts/sysdig/Disk-utilization-monitoring-using-Sysdig.md","raw":"---\ntitle: Disk utilization monitoring using Sysdig\ndate: 2016-11-12 15:52:00\ntags:\ncategories: sysdig\n---\n\nDisk utilization monitoring using Sysdig\n\n\n### Creating a Dashboard tab\n\n1. Under Explore tab select Server -> Overview.\n2. Choose Group by host (host.mac).\n3. On Table columns configuration (gear icon) Select the following fields\n - `fs.used.percent` - FS Usage %\n - `fs.root.used.percent` - FS Root Usage %\n - `fs.largest.used.percent`  - FS Largest Usage %\n - `fs.bytes.total` - FS Size\n - `fs.bytes.free` - FS Free Space\n - `fs.bytes.used` - Disk Used Bytes\n4. Change the color coding by clicking on the gear icon of each of the columns. (default is yellow after 50% and red after 80%)\n5. Pin the tab to the dashboard.\n\n![creating a dashboard tab](../../images/sysdig/Disk-utilization-monitoring-using-Sysdig-dashboard-tab.png)\n\n\n### Creating an alert for 60% disk utilization\n\nThe following steps will help you to create an alert when the root directory (/) exceeds 60% of its usage:\n\n1. Under alert tab click add alert button\n2. Select the scope as `agent.tag.dcosName` or `region`. `agent.tag.dcosName` Is the tag we have added for the dcos cluster. `region` specify the aws region name. Assign the value for scope from the dropdown accordingly which one you selected as the scope.\n3. Under `Set the condition` choose type as `manual`\n4. For `Alert when` option Choose `fs.used.percent` as the metric > 60% as the threshold value.\n5. For `Segment by` choose second option, select `Any of` and `fs.mountDir` metric.\n![creating an alert for disk utilization](../../images/sysdig/Creating-alert-for-disk-utilization.png)\n6. Check the `Where` option and select `fs.mountDir` from the dropdown. Assign the value `/`\n![creating an alert for disk](../../images/sysdig/Creating-alert-for-disk-utilization2.png)\n7. Choose the minimum monitor value as `1 min`.\n8. Specify the Name, Description and Severity of the alert.\n9. Enable the notification channel.\n10. Enable automatic sysdig capture if necessary.\n11. Click Create button.\n\n","slug":"sysdig/Disk-utilization-monitoring-using-Sysdig","published":1,"updated":"2017-01-04T10:58:27.730Z","_id":"cixigfrjz0010f33pxxac5sm6","comments":1,"layout":"post","photos":[],"link":"","content":"<p>Disk utilization monitoring using Sysdig</p>\n<h3 id=\"Creating-a-Dashboard-tab\"><a href=\"#Creating-a-Dashboard-tab\" class=\"headerlink\" title=\"Creating a Dashboard tab\"></a>Creating a Dashboard tab</h3><ol>\n<li>Under Explore tab select Server -&gt; Overview.</li>\n<li>Choose Group by host (host.mac).</li>\n<li>On Table columns configuration (gear icon) Select the following fields<ul>\n<li><code>fs.used.percent</code> - FS Usage %</li>\n<li><code>fs.root.used.percent</code> - FS Root Usage %</li>\n<li><code>fs.largest.used.percent</code>  - FS Largest Usage %</li>\n<li><code>fs.bytes.total</code> - FS Size</li>\n<li><code>fs.bytes.free</code> - FS Free Space</li>\n<li><code>fs.bytes.used</code> - Disk Used Bytes</li>\n</ul>\n</li>\n<li>Change the color coding by clicking on the gear icon of each of the columns. (default is yellow after 50% and red after 80%)</li>\n<li>Pin the tab to the dashboard.</li>\n</ol>\n<p><img src=\"../../images/sysdig/Disk-utilization-monitoring-using-Sysdig-dashboard-tab.png\" alt=\"creating a dashboard tab\"></p>\n<h3 id=\"Creating-an-alert-for-60-disk-utilization\"><a href=\"#Creating-an-alert-for-60-disk-utilization\" class=\"headerlink\" title=\"Creating an alert for 60% disk utilization\"></a>Creating an alert for 60% disk utilization</h3><p>The following steps will help you to create an alert when the root directory (/) exceeds 60% of its usage:</p>\n<ol>\n<li>Under alert tab click add alert button</li>\n<li>Select the scope as <code>agent.tag.dcosName</code> or <code>region</code>. <code>agent.tag.dcosName</code> Is the tag we have added for the dcos cluster. <code>region</code> specify the aws region name. Assign the value for scope from the dropdown accordingly which one you selected as the scope.</li>\n<li>Under <code>Set the condition</code> choose type as <code>manual</code></li>\n<li>For <code>Alert when</code> option Choose <code>fs.used.percent</code> as the metric &gt; 60% as the threshold value.</li>\n<li>For <code>Segment by</code> choose second option, select <code>Any of</code> and <code>fs.mountDir</code> metric.<br><img src=\"../../images/sysdig/Creating-alert-for-disk-utilization.png\" alt=\"creating an alert for disk utilization\"></li>\n<li>Check the <code>Where</code> option and select <code>fs.mountDir</code> from the dropdown. Assign the value <code>/</code><br><img src=\"../../images/sysdig/Creating-alert-for-disk-utilization2.png\" alt=\"creating an alert for disk\"></li>\n<li>Choose the minimum monitor value as <code>1 min</code>.</li>\n<li>Specify the Name, Description and Severity of the alert.</li>\n<li>Enable the notification channel.</li>\n<li>Enable automatic sysdig capture if necessary.</li>\n<li>Click Create button.</li>\n</ol>\n","excerpt":"","more":"<p>Disk utilization monitoring using Sysdig</p>\n<h3 id=\"Creating-a-Dashboard-tab\"><a href=\"#Creating-a-Dashboard-tab\" class=\"headerlink\" title=\"Creating a Dashboard tab\"></a>Creating a Dashboard tab</h3><ol>\n<li>Under Explore tab select Server -&gt; Overview.</li>\n<li>Choose Group by host (host.mac).</li>\n<li>On Table columns configuration (gear icon) Select the following fields<ul>\n<li><code>fs.used.percent</code> - FS Usage %</li>\n<li><code>fs.root.used.percent</code> - FS Root Usage %</li>\n<li><code>fs.largest.used.percent</code>  - FS Largest Usage %</li>\n<li><code>fs.bytes.total</code> - FS Size</li>\n<li><code>fs.bytes.free</code> - FS Free Space</li>\n<li><code>fs.bytes.used</code> - Disk Used Bytes</li>\n</ul>\n</li>\n<li>Change the color coding by clicking on the gear icon of each of the columns. (default is yellow after 50% and red after 80%)</li>\n<li>Pin the tab to the dashboard.</li>\n</ol>\n<p><img src=\"../../images/sysdig/Disk-utilization-monitoring-using-Sysdig-dashboard-tab.png\" alt=\"creating a dashboard tab\"></p>\n<h3 id=\"Creating-an-alert-for-60-disk-utilization\"><a href=\"#Creating-an-alert-for-60-disk-utilization\" class=\"headerlink\" title=\"Creating an alert for 60% disk utilization\"></a>Creating an alert for 60% disk utilization</h3><p>The following steps will help you to create an alert when the root directory (/) exceeds 60% of its usage:</p>\n<ol>\n<li>Under alert tab click add alert button</li>\n<li>Select the scope as <code>agent.tag.dcosName</code> or <code>region</code>. <code>agent.tag.dcosName</code> Is the tag we have added for the dcos cluster. <code>region</code> specify the aws region name. Assign the value for scope from the dropdown accordingly which one you selected as the scope.</li>\n<li>Under <code>Set the condition</code> choose type as <code>manual</code></li>\n<li>For <code>Alert when</code> option Choose <code>fs.used.percent</code> as the metric &gt; 60% as the threshold value.</li>\n<li>For <code>Segment by</code> choose second option, select <code>Any of</code> and <code>fs.mountDir</code> metric.<br><img src=\"../../images/sysdig/Creating-alert-for-disk-utilization.png\" alt=\"creating an alert for disk utilization\"></li>\n<li>Check the <code>Where</code> option and select <code>fs.mountDir</code> from the dropdown. Assign the value <code>/</code><br><img src=\"../../images/sysdig/Creating-alert-for-disk-utilization2.png\" alt=\"creating an alert for disk\"></li>\n<li>Choose the minimum monitor value as <code>1 min</code>.</li>\n<li>Specify the Name, Description and Severity of the alert.</li>\n<li>Enable the notification channel.</li>\n<li>Enable automatic sysdig capture if necessary.</li>\n<li>Click Create button.</li>\n</ol>\n"},{"title":"Memory utilization monitoring using Sysdig","date":"2016-11-15T08:18:00.000Z","_content":"\nMemory utilization monitoring using Sysdig\n\n\n\n### Creating an alert for 95% CPU utilization\n\nThe following steps will help you to create an alert when a node exceeds 90% of its memory utilization.\n\n\n1. Under alert tab click add alert button\n2. Select the scope as `agent.tag.dcosName` or `region`. `agent.tag.dcosName` Is the tag we have added for the dcos cluster. `region` specify the aws region name. Assign the value for scope from the drop down accordingly which one you selected as the scope.\n3. Under `Set the condition` choose type as `manual`\n4. For `Alert when` option Choose `memory.used.percent` as the metric > 95% as the threshold value.\n5. For `Segment by` choose second option, select `Any of` and `host.hostName` metric.\n6. Leave the `Where` option unchecked.\n7. Choose the minimum monitor value as `5 min`.\n8. Specify the Name, Description and Severity of the alert.\n9. Enable the notification channel.\n10. Enable automatic sysdig capture if necessary.\n11. Click Create button.\n![creating an alert for CPU utilization](../../images/sysdig/Memory-utilization-monitoring-using-Sysdig.png)","source":"_posts/sysdig/Memory-utilization-monitoring-using-Sysdig.md","raw":"---\ntitle: Memory utilization monitoring using Sysdig\ndate: 2016-11-15 13:48:00\ntags:\ncategories: sysdig\n---\n\nMemory utilization monitoring using Sysdig\n\n\n\n### Creating an alert for 95% CPU utilization\n\nThe following steps will help you to create an alert when a node exceeds 90% of its memory utilization.\n\n\n1. Under alert tab click add alert button\n2. Select the scope as `agent.tag.dcosName` or `region`. `agent.tag.dcosName` Is the tag we have added for the dcos cluster. `region` specify the aws region name. Assign the value for scope from the drop down accordingly which one you selected as the scope.\n3. Under `Set the condition` choose type as `manual`\n4. For `Alert when` option Choose `memory.used.percent` as the metric > 95% as the threshold value.\n5. For `Segment by` choose second option, select `Any of` and `host.hostName` metric.\n6. Leave the `Where` option unchecked.\n7. Choose the minimum monitor value as `5 min`.\n8. Specify the Name, Description and Severity of the alert.\n9. Enable the notification channel.\n10. Enable automatic sysdig capture if necessary.\n11. Click Create button.\n![creating an alert for CPU utilization](../../images/sysdig/Memory-utilization-monitoring-using-Sysdig.png)","slug":"sysdig/Memory-utilization-monitoring-using-Sysdig","published":1,"updated":"2017-01-04T10:58:27.762Z","_id":"cixigfrk00012f33pl3p690a3","comments":1,"layout":"post","photos":[],"link":"","content":"<p>Memory utilization monitoring using Sysdig</p>\n<h3 id=\"Creating-an-alert-for-95-CPU-utilization\"><a href=\"#Creating-an-alert-for-95-CPU-utilization\" class=\"headerlink\" title=\"Creating an alert for 95% CPU utilization\"></a>Creating an alert for 95% CPU utilization</h3><p>The following steps will help you to create an alert when a node exceeds 90% of its memory utilization.</p>\n<ol>\n<li>Under alert tab click add alert button</li>\n<li>Select the scope as <code>agent.tag.dcosName</code> or <code>region</code>. <code>agent.tag.dcosName</code> Is the tag we have added for the dcos cluster. <code>region</code> specify the aws region name. Assign the value for scope from the drop down accordingly which one you selected as the scope.</li>\n<li>Under <code>Set the condition</code> choose type as <code>manual</code></li>\n<li>For <code>Alert when</code> option Choose <code>memory.used.percent</code> as the metric &gt; 95% as the threshold value.</li>\n<li>For <code>Segment by</code> choose second option, select <code>Any of</code> and <code>host.hostName</code> metric.</li>\n<li>Leave the <code>Where</code> option unchecked.</li>\n<li>Choose the minimum monitor value as <code>5 min</code>.</li>\n<li>Specify the Name, Description and Severity of the alert.</li>\n<li>Enable the notification channel.</li>\n<li>Enable automatic sysdig capture if necessary.</li>\n<li>Click Create button.<br><img src=\"../../images/sysdig/Memory-utilization-monitoring-using-Sysdig.png\" alt=\"creating an alert for CPU utilization\"></li>\n</ol>\n","excerpt":"","more":"<p>Memory utilization monitoring using Sysdig</p>\n<h3 id=\"Creating-an-alert-for-95-CPU-utilization\"><a href=\"#Creating-an-alert-for-95-CPU-utilization\" class=\"headerlink\" title=\"Creating an alert for 95% CPU utilization\"></a>Creating an alert for 95% CPU utilization</h3><p>The following steps will help you to create an alert when a node exceeds 90% of its memory utilization.</p>\n<ol>\n<li>Under alert tab click add alert button</li>\n<li>Select the scope as <code>agent.tag.dcosName</code> or <code>region</code>. <code>agent.tag.dcosName</code> Is the tag we have added for the dcos cluster. <code>region</code> specify the aws region name. Assign the value for scope from the drop down accordingly which one you selected as the scope.</li>\n<li>Under <code>Set the condition</code> choose type as <code>manual</code></li>\n<li>For <code>Alert when</code> option Choose <code>memory.used.percent</code> as the metric &gt; 95% as the threshold value.</li>\n<li>For <code>Segment by</code> choose second option, select <code>Any of</code> and <code>host.hostName</code> metric.</li>\n<li>Leave the <code>Where</code> option unchecked.</li>\n<li>Choose the minimum monitor value as <code>5 min</code>.</li>\n<li>Specify the Name, Description and Severity of the alert.</li>\n<li>Enable the notification channel.</li>\n<li>Enable automatic sysdig capture if necessary.</li>\n<li>Click Create button.<br><img src=\"../../images/sysdig/Memory-utilization-monitoring-using-Sysdig.png\" alt=\"creating an alert for CPU utilization\"></li>\n</ol>\n"},{"title":"Monitoring CPU utilization using Sysdig","date":"2016-11-15T09:18:00.000Z","_content":"\nMonitoring CPU utilization using Sysdig\n\n\n\n### Creating an alert for 90% CPU utilization\n\nThe following steps will help you to create an alert when a node exceeds 90% of its cpu utilization:\n \n1. Under alert tab click add alert button.\n2. Select the scope as `agent.tag.dcosName` or `region`. `agent.tag.dcosName` Is the tag we have added for the dcos cluster. `region` specify the aws region name. Assign the value for scope from the drop down accordingly which one you selected as the scope.\n3. Under `Set the condition` choose type as `manual`\n4. For `Alert when` option Choose `cpu.used.percent` as the metric > 90% as the threshold value.\n5. For `Segment by` choose second option, select `Any of` and `host.hostName` metric.\n6. Leave the `Where` option unchecked.\n7. Choose the minimum monitor value as `5 min`.\n8. Specify the Name, Description and Severity of the alert.\n9. Enable the notification channel.\n10. Enable automatic sysdig capture if necessary.\n11. Click Create button.\n\n![creating an alert for 90% CPU utilization](../../images/sysdig/Creating-an-alert-for-90-CPU-utilization.png)","source":"_posts/sysdig/Monitoring-CPU-utilization-using-Sysdig.md","raw":"---\ntitle: Monitoring CPU utilization using Sysdig\ndate: 2016-11-15 14:48:00\ntags:\ncategories: sysdig\n---\n\nMonitoring CPU utilization using Sysdig\n\n\n\n### Creating an alert for 90% CPU utilization\n\nThe following steps will help you to create an alert when a node exceeds 90% of its cpu utilization:\n \n1. Under alert tab click add alert button.\n2. Select the scope as `agent.tag.dcosName` or `region`. `agent.tag.dcosName` Is the tag we have added for the dcos cluster. `region` specify the aws region name. Assign the value for scope from the drop down accordingly which one you selected as the scope.\n3. Under `Set the condition` choose type as `manual`\n4. For `Alert when` option Choose `cpu.used.percent` as the metric > 90% as the threshold value.\n5. For `Segment by` choose second option, select `Any of` and `host.hostName` metric.\n6. Leave the `Where` option unchecked.\n7. Choose the minimum monitor value as `5 min`.\n8. Specify the Name, Description and Severity of the alert.\n9. Enable the notification channel.\n10. Enable automatic sysdig capture if necessary.\n11. Click Create button.\n\n![creating an alert for 90% CPU utilization](../../images/sysdig/Creating-an-alert-for-90-CPU-utilization.png)","slug":"sysdig/Monitoring-CPU-utilization-using-Sysdig","published":1,"updated":"2017-01-04T10:58:27.698Z","_id":"cixigfrk10014f33p7nt6216s","comments":1,"layout":"post","photos":[],"link":"","content":"<p>Monitoring CPU utilization using Sysdig</p>\n<h3 id=\"Creating-an-alert-for-90-CPU-utilization\"><a href=\"#Creating-an-alert-for-90-CPU-utilization\" class=\"headerlink\" title=\"Creating an alert for 90% CPU utilization\"></a>Creating an alert for 90% CPU utilization</h3><p>The following steps will help you to create an alert when a node exceeds 90% of its cpu utilization:</p>\n<ol>\n<li>Under alert tab click add alert button.</li>\n<li>Select the scope as <code>agent.tag.dcosName</code> or <code>region</code>. <code>agent.tag.dcosName</code> Is the tag we have added for the dcos cluster. <code>region</code> specify the aws region name. Assign the value for scope from the drop down accordingly which one you selected as the scope.</li>\n<li>Under <code>Set the condition</code> choose type as <code>manual</code></li>\n<li>For <code>Alert when</code> option Choose <code>cpu.used.percent</code> as the metric &gt; 90% as the threshold value.</li>\n<li>For <code>Segment by</code> choose second option, select <code>Any of</code> and <code>host.hostName</code> metric.</li>\n<li>Leave the <code>Where</code> option unchecked.</li>\n<li>Choose the minimum monitor value as <code>5 min</code>.</li>\n<li>Specify the Name, Description and Severity of the alert.</li>\n<li>Enable the notification channel.</li>\n<li>Enable automatic sysdig capture if necessary.</li>\n<li>Click Create button.</li>\n</ol>\n<p><img src=\"../../images/sysdig/Creating-an-alert-for-90-CPU-utilization.png\" alt=\"creating an alert for 90% CPU utilization\"></p>\n","excerpt":"","more":"<p>Monitoring CPU utilization using Sysdig</p>\n<h3 id=\"Creating-an-alert-for-90-CPU-utilization\"><a href=\"#Creating-an-alert-for-90-CPU-utilization\" class=\"headerlink\" title=\"Creating an alert for 90% CPU utilization\"></a>Creating an alert for 90% CPU utilization</h3><p>The following steps will help you to create an alert when a node exceeds 90% of its cpu utilization:</p>\n<ol>\n<li>Under alert tab click add alert button.</li>\n<li>Select the scope as <code>agent.tag.dcosName</code> or <code>region</code>. <code>agent.tag.dcosName</code> Is the tag we have added for the dcos cluster. <code>region</code> specify the aws region name. Assign the value for scope from the drop down accordingly which one you selected as the scope.</li>\n<li>Under <code>Set the condition</code> choose type as <code>manual</code></li>\n<li>For <code>Alert when</code> option Choose <code>cpu.used.percent</code> as the metric &gt; 90% as the threshold value.</li>\n<li>For <code>Segment by</code> choose second option, select <code>Any of</code> and <code>host.hostName</code> metric.</li>\n<li>Leave the <code>Where</code> option unchecked.</li>\n<li>Choose the minimum monitor value as <code>5 min</code>.</li>\n<li>Specify the Name, Description and Severity of the alert.</li>\n<li>Enable the notification channel.</li>\n<li>Enable automatic sysdig capture if necessary.</li>\n<li>Click Create button.</li>\n</ol>\n<p><img src=\"../../images/sysdig/Creating-an-alert-for-90-CPU-utilization.png\" alt=\"creating an alert for 90% CPU utilization\"></p>\n"},{"layout":"iac-manager","title":"Creating a Managment Environment in AWS with terraform.","date":"2016-07-19T05:50:30.000Z","banner":"/images/iac-manager.jpg","Projects":"Iac-manager","git":"https://github.com/microservices-today/IaC-manager","_content":"### IaC: Manager Node (Jump Server)\nThis terraform script will setup an infra for management in AWS:\n - CentOS (Manager Node)\n - VPC\n - Public subnet\n - Internet gateway\n\n#### Pre-requisites\n- An IAM account with administrator privileges.\n- Install [terraform](https://www.terraform.io/intro/getting-started/install.html) on your machine.\n- Public Key Access with Agent support/ Agent Forwarding:\n\n  ```bash\n  ssh-add <key_pair_name>.pem\n  ssh -A centos@<manager_public_ip>\n  ```\n\n#### Steps for installation\n- Clone this repo .\n- `cp terraform.dummy terraform.tfvars`\n- Modify params in `terraform.tfvars`\n- Modify params in `variable.tf` to change subnet or add AMI accordingly to your aws region\n- Export AWS credentials as bash variables (e.g. `ap-northeast-1` for Tokyo and `ap-southeast-1` for Singapore region):\n```bash\nexport AWS_ACCESS_KEY_ID=\"anaccesskey\"\nexport AWS_SECRET_ACCESS_KEY=\"asecretkey\"\nexport AWS_DEFAULT_REGION=\"ap-northeast-1\"\n```\n- Run `terraform plan` to see the plan to execute.\n- Run `terraform apply` to run the scripts.\n- You may have `prod/dev/stage` configurations in\n`terraform.tfvars.{prod/dev/stage}` files (already ignored by `.gitignore`).\n\n#### Generate Docs\nGenerate terraform documentation by running `bash generate-docs.sh`\n\n#### Notes\n- SSH into the manager node and check whether `terraform.out` in `home/centos` contains:\na record of the VPC, Subnet, Security Group and Nat gateway ID.\n- More details on [terraform-docs](https://github.com/segmentio/terraform-docs).\n","source":"_posts/projects/IaC-Manager.md","raw":"---\nlayout: iac-manager\ntitle:  Creating a Managment Environment in AWS with terraform.\ndate: 2016-07-19 11:20:30\ntags: manager\nbanner: /images/iac-manager.jpg\ncategories: Projects\nProjects: Iac-manager\ngit: https://github.com/microservices-today/IaC-manager\n---\n### IaC: Manager Node (Jump Server)\nThis terraform script will setup an infra for management in AWS:\n - CentOS (Manager Node)\n - VPC\n - Public subnet\n - Internet gateway\n\n#### Pre-requisites\n- An IAM account with administrator privileges.\n- Install [terraform](https://www.terraform.io/intro/getting-started/install.html) on your machine.\n- Public Key Access with Agent support/ Agent Forwarding:\n\n  ```bash\n  ssh-add <key_pair_name>.pem\n  ssh -A centos@<manager_public_ip>\n  ```\n\n#### Steps for installation\n- Clone this repo .\n- `cp terraform.dummy terraform.tfvars`\n- Modify params in `terraform.tfvars`\n- Modify params in `variable.tf` to change subnet or add AMI accordingly to your aws region\n- Export AWS credentials as bash variables (e.g. `ap-northeast-1` for Tokyo and `ap-southeast-1` for Singapore region):\n```bash\nexport AWS_ACCESS_KEY_ID=\"anaccesskey\"\nexport AWS_SECRET_ACCESS_KEY=\"asecretkey\"\nexport AWS_DEFAULT_REGION=\"ap-northeast-1\"\n```\n- Run `terraform plan` to see the plan to execute.\n- Run `terraform apply` to run the scripts.\n- You may have `prod/dev/stage` configurations in\n`terraform.tfvars.{prod/dev/stage}` files (already ignored by `.gitignore`).\n\n#### Generate Docs\nGenerate terraform documentation by running `bash generate-docs.sh`\n\n#### Notes\n- SSH into the manager node and check whether `terraform.out` in `home/centos` contains:\na record of the VPC, Subnet, Security Group and Nat gateway ID.\n- More details on [terraform-docs](https://github.com/segmentio/terraform-docs).\n","slug":"projects/IaC-Manager","published":1,"updated":"2017-01-04T04:33:28.000Z","comments":1,"photos":[],"link":"","_id":"cixigfrk30016f33peb02zd4o","content":"<h3 id=\"IaC-Manager-Node-Jump-Server\"><a href=\"#IaC-Manager-Node-Jump-Server\" class=\"headerlink\" title=\"IaC: Manager Node (Jump Server)\"></a>IaC: Manager Node (Jump Server)</h3><p>This terraform script will setup an infra for management in AWS:</p>\n<ul>\n<li>CentOS (Manager Node)</li>\n<li>VPC</li>\n<li>Public subnet</li>\n<li>Internet gateway</li>\n</ul>\n<h4 id=\"Pre-requisites\"><a href=\"#Pre-requisites\" class=\"headerlink\" title=\"Pre-requisites\"></a>Pre-requisites</h4><ul>\n<li>An IAM account with administrator privileges.</li>\n<li>Install <a href=\"https://www.terraform.io/intro/getting-started/install.html\" target=\"_blank\" rel=\"external\">terraform</a> on your machine.</li>\n<li><p>Public Key Access with Agent support/ Agent Forwarding:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">ssh-add &lt;key_pair_name&gt;.pem</div><div class=\"line\">ssh -A centos@&lt;manager_public_ip&gt;</div></pre></td></tr></table></figure>\n</li>\n</ul>\n<h4 id=\"Steps-for-installation\"><a href=\"#Steps-for-installation\" class=\"headerlink\" title=\"Steps for installation\"></a>Steps for installation</h4><ul>\n<li>Clone this repo .</li>\n<li><code>cp terraform.dummy terraform.tfvars</code></li>\n<li>Modify params in <code>terraform.tfvars</code></li>\n<li>Modify params in <code>variable.tf</code> to change subnet or add AMI accordingly to your aws region</li>\n<li><p>Export AWS credentials as bash variables (e.g. <code>ap-northeast-1</code> for Tokyo and <code>ap-southeast-1</code> for Singapore region):</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"built_in\">export</span> AWS_ACCESS_KEY_ID=<span class=\"string\">\"anaccesskey\"</span></div><div class=\"line\"><span class=\"built_in\">export</span> AWS_SECRET_ACCESS_KEY=<span class=\"string\">\"asecretkey\"</span></div><div class=\"line\"><span class=\"built_in\">export</span> AWS_DEFAULT_REGION=<span class=\"string\">\"ap-northeast-1\"</span></div></pre></td></tr></table></figure>\n</li>\n<li><p>Run <code>terraform plan</code> to see the plan to execute.</p>\n</li>\n<li>Run <code>terraform apply</code> to run the scripts.</li>\n<li>You may have <code>prod/dev/stage</code> configurations in<br><code>terraform.tfvars.{prod/dev/stage}</code> files (already ignored by <code>.gitignore</code>).</li>\n</ul>\n<h4 id=\"Generate-Docs\"><a href=\"#Generate-Docs\" class=\"headerlink\" title=\"Generate Docs\"></a>Generate Docs</h4><p>Generate terraform documentation by running <code>bash generate-docs.sh</code></p>\n<h4 id=\"Notes\"><a href=\"#Notes\" class=\"headerlink\" title=\"Notes\"></a>Notes</h4><ul>\n<li>SSH into the manager node and check whether <code>terraform.out</code> in <code>home/centos</code> contains:<br>a record of the VPC, Subnet, Security Group and Nat gateway ID.</li>\n<li>More details on <a href=\"https://github.com/segmentio/terraform-docs\" target=\"_blank\" rel=\"external\">terraform-docs</a>.</li>\n</ul>\n","excerpt":"","more":"<h3 id=\"IaC-Manager-Node-Jump-Server\"><a href=\"#IaC-Manager-Node-Jump-Server\" class=\"headerlink\" title=\"IaC: Manager Node (Jump Server)\"></a>IaC: Manager Node (Jump Server)</h3><p>This terraform script will setup an infra for management in AWS:</p>\n<ul>\n<li>CentOS (Manager Node)</li>\n<li>VPC</li>\n<li>Public subnet</li>\n<li>Internet gateway</li>\n</ul>\n<h4 id=\"Pre-requisites\"><a href=\"#Pre-requisites\" class=\"headerlink\" title=\"Pre-requisites\"></a>Pre-requisites</h4><ul>\n<li>An IAM account with administrator privileges.</li>\n<li>Install <a href=\"https://www.terraform.io/intro/getting-started/install.html\">terraform</a> on your machine.</li>\n<li><p>Public Key Access with Agent support/ Agent Forwarding:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">ssh-add &lt;key_pair_name&gt;.pem</div><div class=\"line\">ssh -A centos@&lt;manager_public_ip&gt;</div></pre></td></tr></table></figure>\n</li>\n</ul>\n<h4 id=\"Steps-for-installation\"><a href=\"#Steps-for-installation\" class=\"headerlink\" title=\"Steps for installation\"></a>Steps for installation</h4><ul>\n<li>Clone this repo .</li>\n<li><code>cp terraform.dummy terraform.tfvars</code></li>\n<li>Modify params in <code>terraform.tfvars</code></li>\n<li>Modify params in <code>variable.tf</code> to change subnet or add AMI accordingly to your aws region</li>\n<li><p>Export AWS credentials as bash variables (e.g. <code>ap-northeast-1</code> for Tokyo and <code>ap-southeast-1</code> for Singapore region):</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"built_in\">export</span> AWS_ACCESS_KEY_ID=<span class=\"string\">\"anaccesskey\"</span></div><div class=\"line\"><span class=\"built_in\">export</span> AWS_SECRET_ACCESS_KEY=<span class=\"string\">\"asecretkey\"</span></div><div class=\"line\"><span class=\"built_in\">export</span> AWS_DEFAULT_REGION=<span class=\"string\">\"ap-northeast-1\"</span></div></pre></td></tr></table></figure>\n</li>\n<li><p>Run <code>terraform plan</code> to see the plan to execute.</p>\n</li>\n<li>Run <code>terraform apply</code> to run the scripts.</li>\n<li>You may have <code>prod/dev/stage</code> configurations in<br><code>terraform.tfvars.{prod/dev/stage}</code> files (already ignored by <code>.gitignore</code>).</li>\n</ul>\n<h4 id=\"Generate-Docs\"><a href=\"#Generate-Docs\" class=\"headerlink\" title=\"Generate Docs\"></a>Generate Docs</h4><p>Generate terraform documentation by running <code>bash generate-docs.sh</code></p>\n<h4 id=\"Notes\"><a href=\"#Notes\" class=\"headerlink\" title=\"Notes\"></a>Notes</h4><ul>\n<li>SSH into the manager node and check whether <code>terraform.out</code> in <code>home/centos</code> contains:<br>a record of the VPC, Subnet, Security Group and Nat gateway ID.</li>\n<li>More details on <a href=\"https://github.com/segmentio/terraform-docs\">terraform-docs</a>.</li>\n</ul>\n"},{"title":"Creating a DCOS cluster in AWS using terraform.","date":"2016-07-21T09:15:56.000Z","banner":"/images/iac-wrapper.jpg","Projects":"Iac-dcos","git":"https://github.com/microservices-today/IaC-dcos","_content":"### IaC: DCOS\nThis terraform script will setup the DCOS cluster in AWS.\n - CentOS (Bootstrap Node)\n - CoreOS (Master and Agent Nodes)\n - Private subnet\n - Public subnet\n - Internet gateway\n\n#### Pre-requisites\n- An IAM account with administrator privileges.\n- (skip if you use [IaC-manager][iac-manager]) An existing infrastructure with a VPC, Subnet and instance from where this terraform can be run.\n  We need the following information prior to starting the script.\n  - public_security_group_id\n  - public_subnet_id\n  - vpc_id\n  - key_pair_name\n  We have an [Iac-manager][iac-manager] which can do this task.\n- Install terraform in the machine from [here][terraform-install].\n- Public Key Access with Agent support/ Agent Forwarding:\n\n  ```bash\n  ssh-add <key_pair_name>.pem\n  ssh -A centos@<manager_public_ip>\n  ```\n- A hosted zone in AWS Route53 for your domain name. This is required to create a record for creating a friendly dns name for the load balancer.\n  - If you do not want to create a dns name for load balancer, remove the `aws_route53_record` resource from `elb-master.tf`\n\n#### Steps to install DCOS\n- Export AWS credentials as bash variables\n```\nexport AWS_ACCESS_KEY_ID=\"anaccesskey\"\nexport AWS_SECRET_ACCESS_KEY=\"asecretkey\"\nexport AWS_DEFAULT_REGION=\"ap-northeast-1\"\n```\n- Clone this repo .\n- Copy your AWS ssh key into current dir.\n- `cp terraform.dummy terraform.tfvars`\n- If you are using [IaC-Manager][iac-manager], run ```cat ~/terraform.out >> ~/IaC-dcos/terraform.tfvars``` once.\n- Modify params in `terraform.tfvars`\n- (Optional) Modify params in `variable.tf` to change **default values** including subnet or add AMI accordingly to your aws region\n- Run `terraform plan` to see the plan to execute.\n- Run `terraform apply` to run the scripts.\n- You may have `prod/dev/stage` configurations in\n`terraform.tfvars.{prod/dev/stage}` files (already ignored by `.gitignore`).\n\n#### Notes\n- The AWS key name, AWS key path, VPC, Subnet, Security Group will be updated to `terraform.dummy`\nand AWS ssh key will be copied to the current directory if an installation is done by [IaC-Manager][iac-manager].\nTerraform v0.7.0 or above is required.\n\n[iac-manager]: <https://github.com/microservices-today/IaC-manager>\n[terraform-install]: <https://www.terraform.io/intro/getting-started/install.html>","source":"_posts/projects/IaC-dcos.md","raw":"---\ntitle: Creating a DCOS cluster in AWS using terraform.\ndate: 2016-07-21 14:45:56\ntags: dcos\nbanner: /images/iac-wrapper.jpg\ncategories: Projects\nProjects: Iac-dcos\ngit: https://github.com/microservices-today/IaC-dcos\n---\n### IaC: DCOS\nThis terraform script will setup the DCOS cluster in AWS.\n - CentOS (Bootstrap Node)\n - CoreOS (Master and Agent Nodes)\n - Private subnet\n - Public subnet\n - Internet gateway\n\n#### Pre-requisites\n- An IAM account with administrator privileges.\n- (skip if you use [IaC-manager][iac-manager]) An existing infrastructure with a VPC, Subnet and instance from where this terraform can be run.\n  We need the following information prior to starting the script.\n  - public_security_group_id\n  - public_subnet_id\n  - vpc_id\n  - key_pair_name\n  We have an [Iac-manager][iac-manager] which can do this task.\n- Install terraform in the machine from [here][terraform-install].\n- Public Key Access with Agent support/ Agent Forwarding:\n\n  ```bash\n  ssh-add <key_pair_name>.pem\n  ssh -A centos@<manager_public_ip>\n  ```\n- A hosted zone in AWS Route53 for your domain name. This is required to create a record for creating a friendly dns name for the load balancer.\n  - If you do not want to create a dns name for load balancer, remove the `aws_route53_record` resource from `elb-master.tf`\n\n#### Steps to install DCOS\n- Export AWS credentials as bash variables\n```\nexport AWS_ACCESS_KEY_ID=\"anaccesskey\"\nexport AWS_SECRET_ACCESS_KEY=\"asecretkey\"\nexport AWS_DEFAULT_REGION=\"ap-northeast-1\"\n```\n- Clone this repo .\n- Copy your AWS ssh key into current dir.\n- `cp terraform.dummy terraform.tfvars`\n- If you are using [IaC-Manager][iac-manager], run ```cat ~/terraform.out >> ~/IaC-dcos/terraform.tfvars``` once.\n- Modify params in `terraform.tfvars`\n- (Optional) Modify params in `variable.tf` to change **default values** including subnet or add AMI accordingly to your aws region\n- Run `terraform plan` to see the plan to execute.\n- Run `terraform apply` to run the scripts.\n- You may have `prod/dev/stage` configurations in\n`terraform.tfvars.{prod/dev/stage}` files (already ignored by `.gitignore`).\n\n#### Notes\n- The AWS key name, AWS key path, VPC, Subnet, Security Group will be updated to `terraform.dummy`\nand AWS ssh key will be copied to the current directory if an installation is done by [IaC-Manager][iac-manager].\nTerraform v0.7.0 or above is required.\n\n[iac-manager]: <https://github.com/microservices-today/IaC-manager>\n[terraform-install]: <https://www.terraform.io/intro/getting-started/install.html>","slug":"projects/IaC-dcos","published":1,"updated":"2017-01-04T04:33:28.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cixigfrk4001bf33pscxeqo4x","content":"<h3 id=\"IaC-DCOS\"><a href=\"#IaC-DCOS\" class=\"headerlink\" title=\"IaC: DCOS\"></a>IaC: DCOS</h3><p>This terraform script will setup the DCOS cluster in AWS.</p>\n<ul>\n<li>CentOS (Bootstrap Node)</li>\n<li>CoreOS (Master and Agent Nodes)</li>\n<li>Private subnet</li>\n<li>Public subnet</li>\n<li>Internet gateway</li>\n</ul>\n<h4 id=\"Pre-requisites\"><a href=\"#Pre-requisites\" class=\"headerlink\" title=\"Pre-requisites\"></a>Pre-requisites</h4><ul>\n<li>An IAM account with administrator privileges.</li>\n<li>(skip if you use <a href=\"https://github.com/microservices-today/IaC-manager\" target=\"_blank\" rel=\"external\">IaC-manager</a>) An existing infrastructure with a VPC, Subnet and instance from where this terraform can be run.<br>We need the following information prior to starting the script.<ul>\n<li>public_security_group_id</li>\n<li>public_subnet_id</li>\n<li>vpc_id</li>\n<li>key_pair_name<br>We have an <a href=\"https://github.com/microservices-today/IaC-manager\" target=\"_blank\" rel=\"external\">Iac-manager</a> which can do this task.</li>\n</ul>\n</li>\n<li>Install terraform in the machine from <a href=\"https://www.terraform.io/intro/getting-started/install.html\" target=\"_blank\" rel=\"external\">here</a>.</li>\n<li><p>Public Key Access with Agent support/ Agent Forwarding:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">ssh-add &lt;key_pair_name&gt;.pem</div><div class=\"line\">ssh -A centos@&lt;manager_public_ip&gt;</div></pre></td></tr></table></figure>\n</li>\n<li><p>A hosted zone in AWS Route53 for your domain name. This is required to create a record for creating a friendly dns name for the load balancer.</p>\n<ul>\n<li>If you do not want to create a dns name for load balancer, remove the <code>aws_route53_record</code> resource from <code>elb-master.tf</code></li>\n</ul>\n</li>\n</ul>\n<h4 id=\"Steps-to-install-DCOS\"><a href=\"#Steps-to-install-DCOS\" class=\"headerlink\" title=\"Steps to install DCOS\"></a>Steps to install DCOS</h4><ul>\n<li><p>Export AWS credentials as bash variables</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">export AWS_ACCESS_KEY_ID=&quot;anaccesskey&quot;</div><div class=\"line\">export AWS_SECRET_ACCESS_KEY=&quot;asecretkey&quot;</div><div class=\"line\">export AWS_DEFAULT_REGION=&quot;ap-northeast-1&quot;</div></pre></td></tr></table></figure>\n</li>\n<li><p>Clone this repo .</p>\n</li>\n<li>Copy your AWS ssh key into current dir.</li>\n<li><code>cp terraform.dummy terraform.tfvars</code></li>\n<li>If you are using <a href=\"https://github.com/microservices-today/IaC-manager\" target=\"_blank\" rel=\"external\">IaC-Manager</a>, run <code>cat ~/terraform.out &gt;&gt; ~/IaC-dcos/terraform.tfvars</code> once.</li>\n<li>Modify params in <code>terraform.tfvars</code></li>\n<li>(Optional) Modify params in <code>variable.tf</code> to change <strong>default values</strong> including subnet or add AMI accordingly to your aws region</li>\n<li>Run <code>terraform plan</code> to see the plan to execute.</li>\n<li>Run <code>terraform apply</code> to run the scripts.</li>\n<li>You may have <code>prod/dev/stage</code> configurations in<br><code>terraform.tfvars.{prod/dev/stage}</code> files (already ignored by <code>.gitignore</code>).</li>\n</ul>\n<h4 id=\"Notes\"><a href=\"#Notes\" class=\"headerlink\" title=\"Notes\"></a>Notes</h4><ul>\n<li>The AWS key name, AWS key path, VPC, Subnet, Security Group will be updated to <code>terraform.dummy</code><br>and AWS ssh key will be copied to the current directory if an installation is done by <a href=\"https://github.com/microservices-today/IaC-manager\" target=\"_blank\" rel=\"external\">IaC-Manager</a>.<br>Terraform v0.7.0 or above is required.</li>\n</ul>\n","excerpt":"","more":"<h3 id=\"IaC-DCOS\"><a href=\"#IaC-DCOS\" class=\"headerlink\" title=\"IaC: DCOS\"></a>IaC: DCOS</h3><p>This terraform script will setup the DCOS cluster in AWS.</p>\n<ul>\n<li>CentOS (Bootstrap Node)</li>\n<li>CoreOS (Master and Agent Nodes)</li>\n<li>Private subnet</li>\n<li>Public subnet</li>\n<li>Internet gateway</li>\n</ul>\n<h4 id=\"Pre-requisites\"><a href=\"#Pre-requisites\" class=\"headerlink\" title=\"Pre-requisites\"></a>Pre-requisites</h4><ul>\n<li>An IAM account with administrator privileges.</li>\n<li>(skip if you use <a href=\"https://github.com/microservices-today/IaC-manager\">IaC-manager</a>) An existing infrastructure with a VPC, Subnet and instance from where this terraform can be run.<br>We need the following information prior to starting the script.<ul>\n<li>public_security_group_id</li>\n<li>public_subnet_id</li>\n<li>vpc_id</li>\n<li>key_pair_name<br>We have an <a href=\"https://github.com/microservices-today/IaC-manager\">Iac-manager</a> which can do this task.</li>\n</ul>\n</li>\n<li>Install terraform in the machine from <a href=\"https://www.terraform.io/intro/getting-started/install.html\">here</a>.</li>\n<li><p>Public Key Access with Agent support/ Agent Forwarding:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">ssh-add &lt;key_pair_name&gt;.pem</div><div class=\"line\">ssh -A centos@&lt;manager_public_ip&gt;</div></pre></td></tr></table></figure>\n</li>\n<li><p>A hosted zone in AWS Route53 for your domain name. This is required to create a record for creating a friendly dns name for the load balancer.</p>\n<ul>\n<li>If you do not want to create a dns name for load balancer, remove the <code>aws_route53_record</code> resource from <code>elb-master.tf</code></li>\n</ul>\n</li>\n</ul>\n<h4 id=\"Steps-to-install-DCOS\"><a href=\"#Steps-to-install-DCOS\" class=\"headerlink\" title=\"Steps to install DCOS\"></a>Steps to install DCOS</h4><ul>\n<li><p>Export AWS credentials as bash variables</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">export AWS_ACCESS_KEY_ID=&quot;anaccesskey&quot;</div><div class=\"line\">export AWS_SECRET_ACCESS_KEY=&quot;asecretkey&quot;</div><div class=\"line\">export AWS_DEFAULT_REGION=&quot;ap-northeast-1&quot;</div></pre></td></tr></table></figure>\n</li>\n<li><p>Clone this repo .</p>\n</li>\n<li>Copy your AWS ssh key into current dir.</li>\n<li><code>cp terraform.dummy terraform.tfvars</code></li>\n<li>If you are using <a href=\"https://github.com/microservices-today/IaC-manager\">IaC-Manager</a>, run <code>cat ~/terraform.out &gt;&gt; ~/IaC-dcos/terraform.tfvars</code> once.</li>\n<li>Modify params in <code>terraform.tfvars</code></li>\n<li>(Optional) Modify params in <code>variable.tf</code> to change <strong>default values</strong> including subnet or add AMI accordingly to your aws region</li>\n<li>Run <code>terraform plan</code> to see the plan to execute.</li>\n<li>Run <code>terraform apply</code> to run the scripts.</li>\n<li>You may have <code>prod/dev/stage</code> configurations in<br><code>terraform.tfvars.{prod/dev/stage}</code> files (already ignored by <code>.gitignore</code>).</li>\n</ul>\n<h4 id=\"Notes\"><a href=\"#Notes\" class=\"headerlink\" title=\"Notes\"></a>Notes</h4><ul>\n<li>The AWS key name, AWS key path, VPC, Subnet, Security Group will be updated to <code>terraform.dummy</code><br>and AWS ssh key will be copied to the current directory if an installation is done by <a href=\"https://github.com/microservices-today/IaC-manager\">IaC-Manager</a>.<br>Terraform v0.7.0 or above is required.</li>\n</ul>\n"},{"title":"The Next Generation Platform","date":"2016-10-22T09:15:56.000Z","banner":"/images/iac-dcos.jpg","Projects":"Iac-platform","git":"https://github.com/microservices-today/IaC-platform","_content":"### Overview\nThe Next Gen Platform(NGP) enables Infrastructure as Code (IaC) to provision and manage a complete infrastructure that set up a DC/OS cluster and applications on top of it. The complete infrastructure is setup on AWS Cloud. \nThe Infrastructure as code is written using [Terraform][terraform]. \n\nThe different modules that are installed and managed using this IaC are:\n a. OpenVPN Server\n b. DC/OS Cluster\n c. Docker Private Registry\n d. API Gateway\n e. ELK\n f. EC2 Container Registry\n g. Marathon Snapshot\n\n### NGP Infrastructure Design\n\n![NGP Infrastructure Design](../../images/NGP_Architecture.png)\n\n### Implementing Next Gen Platform\n\n#### Pre-requisites\n- AWS IAM account with administrator privileges (Save your AWS IAM access key ID and secret access key)\n- Terraform (latest version)\n- AWS CLI\n- For the ease of Installation, we suggest using IaC-manager, to create a manager node. This IaC will create the following for you:\n  - VPC\n  - Management Subnet\n  - Internet Gateway\n  - IAM Role with required policies attached\n  - Manager Node (CentOS)\n  If not using IaC-manager, Please create the above resources (except Manager Node).\n- Accept Software Terms of AWS Marketplace for CentOS/CoreOs/OpenVPN Access Server. \n- Setup Tyk Hybrid account from https://cloud.tyk.io/signup for running Tyk API gateway \n- A hosted zone in AWS Route53 for your domain name. This is required to create a record for creating a friendly dns name for the load balancers.\n\n#### Steps\n- Export AWS credentials as bash variables\n```\nexport AWS_ACCESS_KEY_ID=\"anaccesskey\"\nexport AWS_SECRET_ACCESS_KEY=\"asecretkey\"\nexport AWS_DEFAULT_REGION=\"ap-northeast-1\"  //(e.g. ap-northeast-1 for Tokyo and ap-southeast-1 for Singapore region)\n\n```\n- Clone the repo [IaC-platform][iac-platform]\n- Change directory to IaC-platform\n- Run ./configure.sh to decide which modules to run (The different modules are explained later in this blog)\n- Copy terraform.dummy to terraform.tfvars\n- If you are using [IaC-Manager][iac-manager], run \n```\ncat ~/terraform.out >> ~/IaC-dcos/terraform.tfvars\n\n```\n\n- Modify params in `terraform.tfvars` for required modules\n- (Optional) Modify params in `variable.tf` to change **default values** including subnet or add AMI accordingly to your aws region\n- Run `terraform plan` to see the plan to execute.\n- Run `terraform apply` to run the scripts.\n- You may have `prod/dev/stage` configurations in `terraform.tfvars.{prod/dev/stage}` files (already ignored by `.gitignore`).\n\n#### Steps to Import a New Module\n\n- Create a folder with module-name in modules directory and add the following files within that folder:\n  a. module-name.tf : File to create and manage module.\n  b. module-name.dummy : Dummy values for the module.\n  c. module-name-variables.tf : Variables required for the module.\n  d. module-name-output.tf : Outputs to be displayed after execution.\n- Add module-name to module array in configure.sh.\n\n#### Monitoring DC/OS Cluster\n\n- [Sysdig][sysdig] containers will be running in all DC/OS nodes for proper monitoring of instances through sysdig cloud.\n- [Filebeat-Docker][filebeat] containers will be running in all dcos nodes for dcos and marathon log capturing. By installing Iac-Elk, you will be able to monitor the logs through AWS elasticsearch service.\n\n#### Outputs\n\nThe following outputs will be generated after running the IaC:\n\n- OpenVPN URL and credentials\n- DC/OS URL\n\n#### Notes\n- Provide the latest stable version while running the “configure.sh” bash script.\n- Always provide a uniquely identifiable pre-tag and post-tag for your deployments.\n- Adhere to AWS naming conventions when providing names for AWS resources.\n\n### OpenVPN Server\n\nOpenVPN is an open-source software application that implements virtual private network (VPN) for creating secure connections to remote     access facilities. This platform will install an OpenVPN server using AWS OpenVPN Access Server AMI. Steps to setup OpenVPN server using terraform can be found at IaC-openvpn. \nRunning the Next Generation Platform will give you the OpenVPN connect URL and Admin URL along with the credentials.\n\n#### Connecting to VPN\n\n- Install OpenVPN client on local machine.\n- Download the client config file.\n  a. Browse to https://OpenVPN_URL/ or https://OpenVPN_Public_IP\n  b. Give the openvpn admin credentials\n  c. Download the client.ovpn file by clicking Yourself(user-locked profile)\n     ![OpenVPN Connect](../../images/openVPN.png)\n  d. Run the OpenVPN client with the downloaded client config file \n     ```\n     openvpn --config client.ovpn\n     \n     ```\n   \n  e. For MaC: Follow the link [OpenVPN][openvpn]\n  \n  Once connected to the VPN, the users can access DC/OS web interface and Jenkins Web Interface. \n  Accessing Tyk dashboard does not require a VPN connection.\n  \n### DC/OS Cluster\n\nDC/OS is a distributed operating system based on Apache Mesos. It enables the management of multiple machines and simplifies the installation and management of distributed services. \nThe documentation for DC/OS can be found at DC/OS. Steps to set up a DC/OS cluster in AWS Cloud using terraform can be found at IaC-DC/OS.\nAfter running the IaC for Next Generation Platform, you can launch the DC/OS web interface by entering the DC/OS Url (Given as output for IaC).\n\n![DC/OS Web Interface](../../images/DCOS.png)\n\n### Tyk API Gateway\n\nTyk is an Open Source API Management Platform and Gateway. Our full Tyk stack consists of multiple components working together, the three most important ones are:\n\n   - Tyk Gateway: This does all the heavy lifting, and is the actual proxy doing all the work\n   - Tyk Dashboard: This is the GUI to control your gateways and view analytics, as well as an extended Dashboard REST API that enables granular integration\n   - Tyk Pump: A data processor that moves analytics data from your gateways (redis) into other data sinks, most importantly MongoDB for the dashboard to process.\n\nThe git repo for setting Tyk on DC/OS using terraform is available at [IaC-api-gateway][iac-api-gateway]. The pre-requisite would be to setup Tyk Hybrid account from https://cloud.tyk.io/signup.\n\n- Tyk dashboard is accessible at http://admin.cloud.tyk.io/ \n- Provide the credentials that were configured while running NGP\n![Tyk API Gateway Dashboard](../../images/Tyk-API-Gateway.png)\n![Tyk Registered API](../../images/Tyk-API.png)\n\n### Docker Private Registry\n\nThe registry is a stateless, server side application that stores and distributes Docker images. NGP uses docker private registry to own the image distribution pipeline. It integrates image storage and distribution tightly into in-house deployment workflow. \nThe git repo for running docker private registry on DC/OS is available at [IaC-dcos-docker-registry][iac-dcos-docker-registry].\n\nRunning NGP will create Docker Private Registry container with virtual IP: 192.168.0.1. The registry storage uses S3 bucket. \nThe S3 bucket name and region are specified while running the IaC. The storage root directory is set to “/docker-registry”.\nTo test the app, follow the below steps:\na. Pull any public docker image\n   `docker pull nginx`\nb. Tag the image with the IP of docker private registry app\n   `docker tag nginx 192.168.0.1/nginx`\nc. Push the image to docker private registry\n   `docker push 192.168.0.1/nginx`\n   The above steps will create a folder named docker-registry inside your specified S3 bucket. The docker image should be available in that folder.\n   \n### ELK \n\nElasticsearch, along with Logstash and Kibana, provides a powerful platform for indexing, searching and analyzing log data.\n##### Filebeat\nFilebeat is a lightweight, open source shipper for log file data. Filebeat tails logs and quickly sends this information to Logstash for further parsing and enrichment.\n##### Filebeat-Docker\n[Filebeat-Docker][filebeat-docker] IaC creates a filebeat docker image. This docker image is configured to monitor `mesos` and `marathon app` logs. It allows to pass the logstash uri as an environment variable to the docker.\nAWS provides a kibana interface for elasticsearch module. For accessing the elasticsearch or kibana though browser you have to update the your system IP address to the elasticsearch access policy as shown below:\n\n ![Modify Access Policy](../../images/ELK-Access-Policy.png)\n \n Kibana dashboard URL is available within AWS Elasticsearch Service as shown below:\n ![Kibana URL](../../images/ELK-Kibana-URL.png)\n \n Accessing the Kibana URL will give you a dashboard as shown below:\n ![Kibana Dashboard](../../images/Kibana-dashboard.png)\n \n### Marathon Snapshot\n\n[Marathon snapshot][iac-marathon-snapshot] IaC is used to take snapshots of marathon applications. These snapshots are stored in a S3 bucket (Bucket name is specified while running NGP). \nThis is performed by running a Lambda function which is periodically triggered by a CloudWatch metric.\nThis app takes snapshots of marathon applications every hour.\nThe IaC, also creates an AWS API gateway to trigger the Lambda function in order to restore the marathon snapshot.\n\n### EC2 Container Registry\n\nEC2 Container Registry (ECR) is a fully-managed Docker container registry by Amazon. NGP will deploy a marathon container that performs the ECR-Login in regular intervals. It then places the compressed the docker config in a location (shared location across all the agents) where the marathon can access. \nIt can be used as an alternative to the “Docker Private Registry” app discussed earlier. \nTo test the app, follow the below steps:\na. Pull any public docker image\nb. Tag the image with the ID of EC2 container registry\nc. Push the image to EC2 container registry\n\n### The Twelve Factors of Next Gen Platform\n\n- Codebase\n\nThe code repository for “The Next Generation Platform” is always tracked in Git version control system. It is a distributed system with multiple codebases. \nEach component/module in NGP is an app and each individually comply with twelve-factor.\n\n- Dependencies\n\nNGP relies on explicit dependencies which are mentioned as pre-requisites.\nIt does not rely on implicit existence of system-wide packages.\n\n- Config\n\nThe app specific configurations (such as credentials to external services, resource handles to caches) are not stored as constants in the code.\nThey are strictly separated from the code and they vary across environments(staging, production, development).\n\n- Backing Services\n\nA backing service is any service the app consumes over the network as part of its normal operation.\nNGP uses the caching system Redis for Tyk API Gateway and binary asset service, Amazon S3.\n\n- Code Release\n\nThe release processes for NGP are managed automatically using Jenkins. \n\n- Processes\n\nThe ‘Next Generation Platform’ runs applications as stateless docker containers.\n\n- Port binding\n\nThe NGP executes the applications inside docker containers. These containers exports services by binding to a port and listening to requests coming on that port. \nThe routing layer handles routing requests from a public-facing hostname to the port-bound processes.\n\n- Concurrency \n \n All the running apps in NGP can be scaled using the auto-scaling feature.\n\n- Disposability\n\nThe apps run using NGP are disposable,meaning they can be started or stopped at a moment’s notice. \nThis facilitates rapid deployment of code or config changes.\n\n- Dev/prod parity\n\nThe NGP keeps its development, staging and production environments as similar as possible. \nThe NGP is designed for continuous deployment by keeping the gap between production and development small.\n\n- Logs\n\nThe NGP does not attempt to write or manage log files. Each running process writes its event stream to ‘stdout’. This platform has its own mechanism to rotate the logs generated by the apps. \nIt uses Filebeat to collect the logs and is processed using ELK.\n\n- Admin Processes\n\nThe admin/management processes are run in an identical environment as the NGP. They run against a release, using the same codebase and config. \nThe developers use ssh or other remote command execution mechanism to run administration tasks.\n\n### DevOps Best Practices\n\n- Active participation : developers, operations staff, and support people must work closely together on a regular basis.\n- Integrated change management : change management is the act of ensuring successful and meaningful evolution of the IT infrastructure to better support the overall organization. The NGP architecture is continuously evolved to ensure high availability.\n- Continuous Integration : Continuous integration (CI) is the discipline of building and validating a project, through automated regression testing and sometimes code analysis whenever updated code is checked into the version control system. NGP uses Jenkins to ensure this.\n- Integrated Deployment Planning : Experienced development teams will do deployment planning continuously throughout construction with active stakeholder participation from development, operations, and support groups.\n- Continuous Deployment : With continuous deployment, when your integration is successful in one sandbox, your changes are automatically promoted to the next sandbox, and integration is automatically started there. NGP uses Jenkins for enabling Continuous deployment of applications.\n- Application Monitoring : This is the operational practice of monitoring running solutions and applications once they are in production. NGP uses ELK along with file-beats for log monitoring. This also implements Sysdig for monitoring using Sysdig cloud.\n\n\n[terraform]: <https://www.terraform.io/>\n[iac-platform]: <https://github.com/microservices-today/IaC-platform>\n[sysdig]: <http://www.sysdig.org/> \n[filebeat]: <https://github.com/microservices-today/filebeat-docker>\n[openvpn]: <https://openvpn.net/index.php/access-server/docs/quick-start-guide/495-connecting-to-openvpn-access-server-using-the-connect-client-on-mac.html>\n[iac-api-gateway]: <https://github.com/microservices-today/IaC-api-gateway>\n[iac-dcos-docker-registry]: <https://github.com/microservices-today/IaC-dcos-docker-registry>\n[filebeat-docker]: <https://github.com/microservices-today/filebeat-docker>\n[iac-marathon-snapshot]: <https://github.com/microservices-today/IaC-marathon-snapshots> \n\n\n","source":"_posts/projects/The-Next-Gen-Platform.md","raw":"---\ntitle: The Next Generation Platform\ndate: 2016-10-22 14:45:56\nbanner: /images/iac-dcos.jpg\ncategories: Projects\nProjects: Iac-platform\ngit: https://github.com/microservices-today/IaC-platform\n---\n### Overview\nThe Next Gen Platform(NGP) enables Infrastructure as Code (IaC) to provision and manage a complete infrastructure that set up a DC/OS cluster and applications on top of it. The complete infrastructure is setup on AWS Cloud. \nThe Infrastructure as code is written using [Terraform][terraform]. \n\nThe different modules that are installed and managed using this IaC are:\n a. OpenVPN Server\n b. DC/OS Cluster\n c. Docker Private Registry\n d. API Gateway\n e. ELK\n f. EC2 Container Registry\n g. Marathon Snapshot\n\n### NGP Infrastructure Design\n\n![NGP Infrastructure Design](../../images/NGP_Architecture.png)\n\n### Implementing Next Gen Platform\n\n#### Pre-requisites\n- AWS IAM account with administrator privileges (Save your AWS IAM access key ID and secret access key)\n- Terraform (latest version)\n- AWS CLI\n- For the ease of Installation, we suggest using IaC-manager, to create a manager node. This IaC will create the following for you:\n  - VPC\n  - Management Subnet\n  - Internet Gateway\n  - IAM Role with required policies attached\n  - Manager Node (CentOS)\n  If not using IaC-manager, Please create the above resources (except Manager Node).\n- Accept Software Terms of AWS Marketplace for CentOS/CoreOs/OpenVPN Access Server. \n- Setup Tyk Hybrid account from https://cloud.tyk.io/signup for running Tyk API gateway \n- A hosted zone in AWS Route53 for your domain name. This is required to create a record for creating a friendly dns name for the load balancers.\n\n#### Steps\n- Export AWS credentials as bash variables\n```\nexport AWS_ACCESS_KEY_ID=\"anaccesskey\"\nexport AWS_SECRET_ACCESS_KEY=\"asecretkey\"\nexport AWS_DEFAULT_REGION=\"ap-northeast-1\"  //(e.g. ap-northeast-1 for Tokyo and ap-southeast-1 for Singapore region)\n\n```\n- Clone the repo [IaC-platform][iac-platform]\n- Change directory to IaC-platform\n- Run ./configure.sh to decide which modules to run (The different modules are explained later in this blog)\n- Copy terraform.dummy to terraform.tfvars\n- If you are using [IaC-Manager][iac-manager], run \n```\ncat ~/terraform.out >> ~/IaC-dcos/terraform.tfvars\n\n```\n\n- Modify params in `terraform.tfvars` for required modules\n- (Optional) Modify params in `variable.tf` to change **default values** including subnet or add AMI accordingly to your aws region\n- Run `terraform plan` to see the plan to execute.\n- Run `terraform apply` to run the scripts.\n- You may have `prod/dev/stage` configurations in `terraform.tfvars.{prod/dev/stage}` files (already ignored by `.gitignore`).\n\n#### Steps to Import a New Module\n\n- Create a folder with module-name in modules directory and add the following files within that folder:\n  a. module-name.tf : File to create and manage module.\n  b. module-name.dummy : Dummy values for the module.\n  c. module-name-variables.tf : Variables required for the module.\n  d. module-name-output.tf : Outputs to be displayed after execution.\n- Add module-name to module array in configure.sh.\n\n#### Monitoring DC/OS Cluster\n\n- [Sysdig][sysdig] containers will be running in all DC/OS nodes for proper monitoring of instances through sysdig cloud.\n- [Filebeat-Docker][filebeat] containers will be running in all dcos nodes for dcos and marathon log capturing. By installing Iac-Elk, you will be able to monitor the logs through AWS elasticsearch service.\n\n#### Outputs\n\nThe following outputs will be generated after running the IaC:\n\n- OpenVPN URL and credentials\n- DC/OS URL\n\n#### Notes\n- Provide the latest stable version while running the “configure.sh” bash script.\n- Always provide a uniquely identifiable pre-tag and post-tag for your deployments.\n- Adhere to AWS naming conventions when providing names for AWS resources.\n\n### OpenVPN Server\n\nOpenVPN is an open-source software application that implements virtual private network (VPN) for creating secure connections to remote     access facilities. This platform will install an OpenVPN server using AWS OpenVPN Access Server AMI. Steps to setup OpenVPN server using terraform can be found at IaC-openvpn. \nRunning the Next Generation Platform will give you the OpenVPN connect URL and Admin URL along with the credentials.\n\n#### Connecting to VPN\n\n- Install OpenVPN client on local machine.\n- Download the client config file.\n  a. Browse to https://OpenVPN_URL/ or https://OpenVPN_Public_IP\n  b. Give the openvpn admin credentials\n  c. Download the client.ovpn file by clicking Yourself(user-locked profile)\n     ![OpenVPN Connect](../../images/openVPN.png)\n  d. Run the OpenVPN client with the downloaded client config file \n     ```\n     openvpn --config client.ovpn\n     \n     ```\n   \n  e. For MaC: Follow the link [OpenVPN][openvpn]\n  \n  Once connected to the VPN, the users can access DC/OS web interface and Jenkins Web Interface. \n  Accessing Tyk dashboard does not require a VPN connection.\n  \n### DC/OS Cluster\n\nDC/OS is a distributed operating system based on Apache Mesos. It enables the management of multiple machines and simplifies the installation and management of distributed services. \nThe documentation for DC/OS can be found at DC/OS. Steps to set up a DC/OS cluster in AWS Cloud using terraform can be found at IaC-DC/OS.\nAfter running the IaC for Next Generation Platform, you can launch the DC/OS web interface by entering the DC/OS Url (Given as output for IaC).\n\n![DC/OS Web Interface](../../images/DCOS.png)\n\n### Tyk API Gateway\n\nTyk is an Open Source API Management Platform and Gateway. Our full Tyk stack consists of multiple components working together, the three most important ones are:\n\n   - Tyk Gateway: This does all the heavy lifting, and is the actual proxy doing all the work\n   - Tyk Dashboard: This is the GUI to control your gateways and view analytics, as well as an extended Dashboard REST API that enables granular integration\n   - Tyk Pump: A data processor that moves analytics data from your gateways (redis) into other data sinks, most importantly MongoDB for the dashboard to process.\n\nThe git repo for setting Tyk on DC/OS using terraform is available at [IaC-api-gateway][iac-api-gateway]. The pre-requisite would be to setup Tyk Hybrid account from https://cloud.tyk.io/signup.\n\n- Tyk dashboard is accessible at http://admin.cloud.tyk.io/ \n- Provide the credentials that were configured while running NGP\n![Tyk API Gateway Dashboard](../../images/Tyk-API-Gateway.png)\n![Tyk Registered API](../../images/Tyk-API.png)\n\n### Docker Private Registry\n\nThe registry is a stateless, server side application that stores and distributes Docker images. NGP uses docker private registry to own the image distribution pipeline. It integrates image storage and distribution tightly into in-house deployment workflow. \nThe git repo for running docker private registry on DC/OS is available at [IaC-dcos-docker-registry][iac-dcos-docker-registry].\n\nRunning NGP will create Docker Private Registry container with virtual IP: 192.168.0.1. The registry storage uses S3 bucket. \nThe S3 bucket name and region are specified while running the IaC. The storage root directory is set to “/docker-registry”.\nTo test the app, follow the below steps:\na. Pull any public docker image\n   `docker pull nginx`\nb. Tag the image with the IP of docker private registry app\n   `docker tag nginx 192.168.0.1/nginx`\nc. Push the image to docker private registry\n   `docker push 192.168.0.1/nginx`\n   The above steps will create a folder named docker-registry inside your specified S3 bucket. The docker image should be available in that folder.\n   \n### ELK \n\nElasticsearch, along with Logstash and Kibana, provides a powerful platform for indexing, searching and analyzing log data.\n##### Filebeat\nFilebeat is a lightweight, open source shipper for log file data. Filebeat tails logs and quickly sends this information to Logstash for further parsing and enrichment.\n##### Filebeat-Docker\n[Filebeat-Docker][filebeat-docker] IaC creates a filebeat docker image. This docker image is configured to monitor `mesos` and `marathon app` logs. It allows to pass the logstash uri as an environment variable to the docker.\nAWS provides a kibana interface for elasticsearch module. For accessing the elasticsearch or kibana though browser you have to update the your system IP address to the elasticsearch access policy as shown below:\n\n ![Modify Access Policy](../../images/ELK-Access-Policy.png)\n \n Kibana dashboard URL is available within AWS Elasticsearch Service as shown below:\n ![Kibana URL](../../images/ELK-Kibana-URL.png)\n \n Accessing the Kibana URL will give you a dashboard as shown below:\n ![Kibana Dashboard](../../images/Kibana-dashboard.png)\n \n### Marathon Snapshot\n\n[Marathon snapshot][iac-marathon-snapshot] IaC is used to take snapshots of marathon applications. These snapshots are stored in a S3 bucket (Bucket name is specified while running NGP). \nThis is performed by running a Lambda function which is periodically triggered by a CloudWatch metric.\nThis app takes snapshots of marathon applications every hour.\nThe IaC, also creates an AWS API gateway to trigger the Lambda function in order to restore the marathon snapshot.\n\n### EC2 Container Registry\n\nEC2 Container Registry (ECR) is a fully-managed Docker container registry by Amazon. NGP will deploy a marathon container that performs the ECR-Login in regular intervals. It then places the compressed the docker config in a location (shared location across all the agents) where the marathon can access. \nIt can be used as an alternative to the “Docker Private Registry” app discussed earlier. \nTo test the app, follow the below steps:\na. Pull any public docker image\nb. Tag the image with the ID of EC2 container registry\nc. Push the image to EC2 container registry\n\n### The Twelve Factors of Next Gen Platform\n\n- Codebase\n\nThe code repository for “The Next Generation Platform” is always tracked in Git version control system. It is a distributed system with multiple codebases. \nEach component/module in NGP is an app and each individually comply with twelve-factor.\n\n- Dependencies\n\nNGP relies on explicit dependencies which are mentioned as pre-requisites.\nIt does not rely on implicit existence of system-wide packages.\n\n- Config\n\nThe app specific configurations (such as credentials to external services, resource handles to caches) are not stored as constants in the code.\nThey are strictly separated from the code and they vary across environments(staging, production, development).\n\n- Backing Services\n\nA backing service is any service the app consumes over the network as part of its normal operation.\nNGP uses the caching system Redis for Tyk API Gateway and binary asset service, Amazon S3.\n\n- Code Release\n\nThe release processes for NGP are managed automatically using Jenkins. \n\n- Processes\n\nThe ‘Next Generation Platform’ runs applications as stateless docker containers.\n\n- Port binding\n\nThe NGP executes the applications inside docker containers. These containers exports services by binding to a port and listening to requests coming on that port. \nThe routing layer handles routing requests from a public-facing hostname to the port-bound processes.\n\n- Concurrency \n \n All the running apps in NGP can be scaled using the auto-scaling feature.\n\n- Disposability\n\nThe apps run using NGP are disposable,meaning they can be started or stopped at a moment’s notice. \nThis facilitates rapid deployment of code or config changes.\n\n- Dev/prod parity\n\nThe NGP keeps its development, staging and production environments as similar as possible. \nThe NGP is designed for continuous deployment by keeping the gap between production and development small.\n\n- Logs\n\nThe NGP does not attempt to write or manage log files. Each running process writes its event stream to ‘stdout’. This platform has its own mechanism to rotate the logs generated by the apps. \nIt uses Filebeat to collect the logs and is processed using ELK.\n\n- Admin Processes\n\nThe admin/management processes are run in an identical environment as the NGP. They run against a release, using the same codebase and config. \nThe developers use ssh or other remote command execution mechanism to run administration tasks.\n\n### DevOps Best Practices\n\n- Active participation : developers, operations staff, and support people must work closely together on a regular basis.\n- Integrated change management : change management is the act of ensuring successful and meaningful evolution of the IT infrastructure to better support the overall organization. The NGP architecture is continuously evolved to ensure high availability.\n- Continuous Integration : Continuous integration (CI) is the discipline of building and validating a project, through automated regression testing and sometimes code analysis whenever updated code is checked into the version control system. NGP uses Jenkins to ensure this.\n- Integrated Deployment Planning : Experienced development teams will do deployment planning continuously throughout construction with active stakeholder participation from development, operations, and support groups.\n- Continuous Deployment : With continuous deployment, when your integration is successful in one sandbox, your changes are automatically promoted to the next sandbox, and integration is automatically started there. NGP uses Jenkins for enabling Continuous deployment of applications.\n- Application Monitoring : This is the operational practice of monitoring running solutions and applications once they are in production. NGP uses ELK along with file-beats for log monitoring. This also implements Sysdig for monitoring using Sysdig cloud.\n\n\n[terraform]: <https://www.terraform.io/>\n[iac-platform]: <https://github.com/microservices-today/IaC-platform>\n[sysdig]: <http://www.sysdig.org/> \n[filebeat]: <https://github.com/microservices-today/filebeat-docker>\n[openvpn]: <https://openvpn.net/index.php/access-server/docs/quick-start-guide/495-connecting-to-openvpn-access-server-using-the-connect-client-on-mac.html>\n[iac-api-gateway]: <https://github.com/microservices-today/IaC-api-gateway>\n[iac-dcos-docker-registry]: <https://github.com/microservices-today/IaC-dcos-docker-registry>\n[filebeat-docker]: <https://github.com/microservices-today/filebeat-docker>\n[iac-marathon-snapshot]: <https://github.com/microservices-today/IaC-marathon-snapshots> \n\n\n","slug":"projects/The-Next-Gen-Platform","published":1,"updated":"2017-01-04T10:58:27.786Z","_id":"cixigfrk5001ff33pxeta5cpq","comments":1,"layout":"post","photos":[],"link":"","content":"<h3 id=\"Overview\"><a href=\"#Overview\" class=\"headerlink\" title=\"Overview\"></a>Overview</h3><p>The Next Gen Platform(NGP) enables Infrastructure as Code (IaC) to provision and manage a complete infrastructure that set up a DC/OS cluster and applications on top of it. The complete infrastructure is setup on AWS Cloud.<br>The Infrastructure as code is written using <a href=\"https://www.terraform.io/\" target=\"_blank\" rel=\"external\">Terraform</a>. </p>\n<p>The different modules that are installed and managed using this IaC are:<br> a. OpenVPN Server<br> b. DC/OS Cluster<br> c. Docker Private Registry<br> d. API Gateway<br> e. ELK<br> f. EC2 Container Registry<br> g. Marathon Snapshot</p>\n<h3 id=\"NGP-Infrastructure-Design\"><a href=\"#NGP-Infrastructure-Design\" class=\"headerlink\" title=\"NGP Infrastructure Design\"></a>NGP Infrastructure Design</h3><p><img src=\"../../images/NGP_Architecture.png\" alt=\"NGP Infrastructure Design\"></p>\n<h3 id=\"Implementing-Next-Gen-Platform\"><a href=\"#Implementing-Next-Gen-Platform\" class=\"headerlink\" title=\"Implementing Next Gen Platform\"></a>Implementing Next Gen Platform</h3><h4 id=\"Pre-requisites\"><a href=\"#Pre-requisites\" class=\"headerlink\" title=\"Pre-requisites\"></a>Pre-requisites</h4><ul>\n<li>AWS IAM account with administrator privileges (Save your AWS IAM access key ID and secret access key)</li>\n<li>Terraform (latest version)</li>\n<li>AWS CLI</li>\n<li>For the ease of Installation, we suggest using IaC-manager, to create a manager node. This IaC will create the following for you:<ul>\n<li>VPC</li>\n<li>Management Subnet</li>\n<li>Internet Gateway</li>\n<li>IAM Role with required policies attached</li>\n<li>Manager Node (CentOS)<br>If not using IaC-manager, Please create the above resources (except Manager Node).</li>\n</ul>\n</li>\n<li>Accept Software Terms of AWS Marketplace for CentOS/CoreOs/OpenVPN Access Server. </li>\n<li>Setup Tyk Hybrid account from <a href=\"https://cloud.tyk.io/signup\" target=\"_blank\" rel=\"external\">https://cloud.tyk.io/signup</a> for running Tyk API gateway </li>\n<li>A hosted zone in AWS Route53 for your domain name. This is required to create a record for creating a friendly dns name for the load balancers.</li>\n</ul>\n<h4 id=\"Steps\"><a href=\"#Steps\" class=\"headerlink\" title=\"Steps\"></a>Steps</h4><ul>\n<li><p>Export AWS credentials as bash variables</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">export AWS_ACCESS_KEY_ID=&quot;anaccesskey&quot;</div><div class=\"line\">export AWS_SECRET_ACCESS_KEY=&quot;asecretkey&quot;</div><div class=\"line\">export AWS_DEFAULT_REGION=&quot;ap-northeast-1&quot;  //(e.g. ap-northeast-1 for Tokyo and ap-southeast-1 for Singapore region)</div></pre></td></tr></table></figure>\n</li>\n<li><p>Clone the repo <a href=\"https://github.com/microservices-today/IaC-platform\" target=\"_blank\" rel=\"external\">IaC-platform</a></p>\n</li>\n<li>Change directory to IaC-platform</li>\n<li>Run ./configure.sh to decide which modules to run (The different modules are explained later in this blog)</li>\n<li>Copy terraform.dummy to terraform.tfvars</li>\n<li><p>If you are using [IaC-Manager][iac-manager], run </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">cat ~/terraform.out &gt;&gt; ~/IaC-dcos/terraform.tfvars</div></pre></td></tr></table></figure>\n</li>\n<li><p>Modify params in <code>terraform.tfvars</code> for required modules</p>\n</li>\n<li>(Optional) Modify params in <code>variable.tf</code> to change <strong>default values</strong> including subnet or add AMI accordingly to your aws region</li>\n<li>Run <code>terraform plan</code> to see the plan to execute.</li>\n<li>Run <code>terraform apply</code> to run the scripts.</li>\n<li>You may have <code>prod/dev/stage</code> configurations in <code>terraform.tfvars.{prod/dev/stage}</code> files (already ignored by <code>.gitignore</code>).</li>\n</ul>\n<h4 id=\"Steps-to-Import-a-New-Module\"><a href=\"#Steps-to-Import-a-New-Module\" class=\"headerlink\" title=\"Steps to Import a New Module\"></a>Steps to Import a New Module</h4><ul>\n<li>Create a folder with module-name in modules directory and add the following files within that folder:<br>a. module-name.tf : File to create and manage module.<br>b. module-name.dummy : Dummy values for the module.<br>c. module-name-variables.tf : Variables required for the module.<br>d. module-name-output.tf : Outputs to be displayed after execution.</li>\n<li>Add module-name to module array in configure.sh.</li>\n</ul>\n<h4 id=\"Monitoring-DC-OS-Cluster\"><a href=\"#Monitoring-DC-OS-Cluster\" class=\"headerlink\" title=\"Monitoring DC/OS Cluster\"></a>Monitoring DC/OS Cluster</h4><ul>\n<li><a href=\"http://www.sysdig.org/\" target=\"_blank\" rel=\"external\">Sysdig</a> containers will be running in all DC/OS nodes for proper monitoring of instances through sysdig cloud.</li>\n<li><a href=\"https://github.com/microservices-today/filebeat-docker\" target=\"_blank\" rel=\"external\">Filebeat-Docker</a> containers will be running in all dcos nodes for dcos and marathon log capturing. By installing Iac-Elk, you will be able to monitor the logs through AWS elasticsearch service.</li>\n</ul>\n<h4 id=\"Outputs\"><a href=\"#Outputs\" class=\"headerlink\" title=\"Outputs\"></a>Outputs</h4><p>The following outputs will be generated after running the IaC:</p>\n<ul>\n<li>OpenVPN URL and credentials</li>\n<li>DC/OS URL</li>\n</ul>\n<h4 id=\"Notes\"><a href=\"#Notes\" class=\"headerlink\" title=\"Notes\"></a>Notes</h4><ul>\n<li>Provide the latest stable version while running the “configure.sh” bash script.</li>\n<li>Always provide a uniquely identifiable pre-tag and post-tag for your deployments.</li>\n<li>Adhere to AWS naming conventions when providing names for AWS resources.</li>\n</ul>\n<h3 id=\"OpenVPN-Server\"><a href=\"#OpenVPN-Server\" class=\"headerlink\" title=\"OpenVPN Server\"></a>OpenVPN Server</h3><p>OpenVPN is an open-source software application that implements virtual private network (VPN) for creating secure connections to remote     access facilities. This platform will install an OpenVPN server using AWS OpenVPN Access Server AMI. Steps to setup OpenVPN server using terraform can be found at IaC-openvpn.<br>Running the Next Generation Platform will give you the OpenVPN connect URL and Admin URL along with the credentials.</p>\n<h4 id=\"Connecting-to-VPN\"><a href=\"#Connecting-to-VPN\" class=\"headerlink\" title=\"Connecting to VPN\"></a>Connecting to VPN</h4><ul>\n<li>Install OpenVPN client on local machine.</li>\n<li>Download the client config file.<br>a. Browse to <a href=\"https://OpenVPN_URL/\" target=\"_blank\" rel=\"external\">https://OpenVPN_URL/</a> or <a href=\"https://OpenVPN_Public_IP\" target=\"_blank\" rel=\"external\">https://OpenVPN_Public_IP</a><br>b. Give the openvpn admin credentials<br>c. Download the client.ovpn file by clicking Yourself(user-locked profile)<br>   <img src=\"../../images/openVPN.png\" alt=\"OpenVPN Connect\"><br>d. Run the OpenVPN client with the downloaded client config file    <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">openvpn --config client.ovpn</div></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>  e. For MaC: Follow the link <a href=\"https://openvpn.net/index.php/access-server/docs/quick-start-guide/495-connecting-to-openvpn-access-server-using-the-connect-client-on-mac.html\" target=\"_blank\" rel=\"external\">OpenVPN</a></p>\n<p>  Once connected to the VPN, the users can access DC/OS web interface and Jenkins Web Interface.<br>  Accessing Tyk dashboard does not require a VPN connection.</p>\n<h3 id=\"DC-OS-Cluster\"><a href=\"#DC-OS-Cluster\" class=\"headerlink\" title=\"DC/OS Cluster\"></a>DC/OS Cluster</h3><p>DC/OS is a distributed operating system based on Apache Mesos. It enables the management of multiple machines and simplifies the installation and management of distributed services.<br>The documentation for DC/OS can be found at DC/OS. Steps to set up a DC/OS cluster in AWS Cloud using terraform can be found at IaC-DC/OS.<br>After running the IaC for Next Generation Platform, you can launch the DC/OS web interface by entering the DC/OS Url (Given as output for IaC).</p>\n<p><img src=\"../../images/DCOS.png\" alt=\"DC/OS Web Interface\"></p>\n<h3 id=\"Tyk-API-Gateway\"><a href=\"#Tyk-API-Gateway\" class=\"headerlink\" title=\"Tyk API Gateway\"></a>Tyk API Gateway</h3><p>Tyk is an Open Source API Management Platform and Gateway. Our full Tyk stack consists of multiple components working together, the three most important ones are:</p>\n<ul>\n<li>Tyk Gateway: This does all the heavy lifting, and is the actual proxy doing all the work</li>\n<li>Tyk Dashboard: This is the GUI to control your gateways and view analytics, as well as an extended Dashboard REST API that enables granular integration</li>\n<li>Tyk Pump: A data processor that moves analytics data from your gateways (redis) into other data sinks, most importantly MongoDB for the dashboard to process.</li>\n</ul>\n<p>The git repo for setting Tyk on DC/OS using terraform is available at <a href=\"https://github.com/microservices-today/IaC-api-gateway\" target=\"_blank\" rel=\"external\">IaC-api-gateway</a>. The pre-requisite would be to setup Tyk Hybrid account from <a href=\"https://cloud.tyk.io/signup\" target=\"_blank\" rel=\"external\">https://cloud.tyk.io/signup</a>.</p>\n<ul>\n<li>Tyk dashboard is accessible at <a href=\"http://admin.cloud.tyk.io/\" target=\"_blank\" rel=\"external\">http://admin.cloud.tyk.io/</a> </li>\n<li>Provide the credentials that were configured while running NGP<br><img src=\"../../images/Tyk-API-Gateway.png\" alt=\"Tyk API Gateway Dashboard\"><br><img src=\"../../images/Tyk-API.png\" alt=\"Tyk Registered API\"></li>\n</ul>\n<h3 id=\"Docker-Private-Registry\"><a href=\"#Docker-Private-Registry\" class=\"headerlink\" title=\"Docker Private Registry\"></a>Docker Private Registry</h3><p>The registry is a stateless, server side application that stores and distributes Docker images. NGP uses docker private registry to own the image distribution pipeline. It integrates image storage and distribution tightly into in-house deployment workflow.<br>The git repo for running docker private registry on DC/OS is available at <a href=\"https://github.com/microservices-today/IaC-dcos-docker-registry\" target=\"_blank\" rel=\"external\">IaC-dcos-docker-registry</a>.</p>\n<p>Running NGP will create Docker Private Registry container with virtual IP: 192.168.0.1. The registry storage uses S3 bucket.<br>The S3 bucket name and region are specified while running the IaC. The storage root directory is set to “/docker-registry”.<br>To test the app, follow the below steps:<br>a. Pull any public docker image<br>   <code>docker pull nginx</code><br>b. Tag the image with the IP of docker private registry app<br>   <code>docker tag nginx 192.168.0.1/nginx</code><br>c. Push the image to docker private registry<br>   <code>docker push 192.168.0.1/nginx</code><br>   The above steps will create a folder named docker-registry inside your specified S3 bucket. The docker image should be available in that folder.</p>\n<h3 id=\"ELK\"><a href=\"#ELK\" class=\"headerlink\" title=\"ELK\"></a>ELK</h3><p>Elasticsearch, along with Logstash and Kibana, provides a powerful platform for indexing, searching and analyzing log data.</p>\n<h5 id=\"Filebeat\"><a href=\"#Filebeat\" class=\"headerlink\" title=\"Filebeat\"></a>Filebeat</h5><p>Filebeat is a lightweight, open source shipper for log file data. Filebeat tails logs and quickly sends this information to Logstash for further parsing and enrichment.</p>\n<h5 id=\"Filebeat-Docker\"><a href=\"#Filebeat-Docker\" class=\"headerlink\" title=\"Filebeat-Docker\"></a>Filebeat-Docker</h5><p><a href=\"https://github.com/microservices-today/filebeat-docker\" target=\"_blank\" rel=\"external\">Filebeat-Docker</a> IaC creates a filebeat docker image. This docker image is configured to monitor <code>mesos</code> and <code>marathon app</code> logs. It allows to pass the logstash uri as an environment variable to the docker.<br>AWS provides a kibana interface for elasticsearch module. For accessing the elasticsearch or kibana though browser you have to update the your system IP address to the elasticsearch access policy as shown below:</p>\n<p> <img src=\"../../images/ELK-Access-Policy.png\" alt=\"Modify Access Policy\"></p>\n<p> Kibana dashboard URL is available within AWS Elasticsearch Service as shown below:<br> <img src=\"../../images/ELK-Kibana-URL.png\" alt=\"Kibana URL\"></p>\n<p> Accessing the Kibana URL will give you a dashboard as shown below:<br> <img src=\"../../images/Kibana-dashboard.png\" alt=\"Kibana Dashboard\"></p>\n<h3 id=\"Marathon-Snapshot\"><a href=\"#Marathon-Snapshot\" class=\"headerlink\" title=\"Marathon Snapshot\"></a>Marathon Snapshot</h3><p><a href=\"https://github.com/microservices-today/IaC-marathon-snapshots\" target=\"_blank\" rel=\"external\">Marathon snapshot</a> IaC is used to take snapshots of marathon applications. These snapshots are stored in a S3 bucket (Bucket name is specified while running NGP).<br>This is performed by running a Lambda function which is periodically triggered by a CloudWatch metric.<br>This app takes snapshots of marathon applications every hour.<br>The IaC, also creates an AWS API gateway to trigger the Lambda function in order to restore the marathon snapshot.</p>\n<h3 id=\"EC2-Container-Registry\"><a href=\"#EC2-Container-Registry\" class=\"headerlink\" title=\"EC2 Container Registry\"></a>EC2 Container Registry</h3><p>EC2 Container Registry (ECR) is a fully-managed Docker container registry by Amazon. NGP will deploy a marathon container that performs the ECR-Login in regular intervals. It then places the compressed the docker config in a location (shared location across all the agents) where the marathon can access.<br>It can be used as an alternative to the “Docker Private Registry” app discussed earlier.<br>To test the app, follow the below steps:<br>a. Pull any public docker image<br>b. Tag the image with the ID of EC2 container registry<br>c. Push the image to EC2 container registry</p>\n<h3 id=\"The-Twelve-Factors-of-Next-Gen-Platform\"><a href=\"#The-Twelve-Factors-of-Next-Gen-Platform\" class=\"headerlink\" title=\"The Twelve Factors of Next Gen Platform\"></a>The Twelve Factors of Next Gen Platform</h3><ul>\n<li>Codebase</li>\n</ul>\n<p>The code repository for “The Next Generation Platform” is always tracked in Git version control system. It is a distributed system with multiple codebases.<br>Each component/module in NGP is an app and each individually comply with twelve-factor.</p>\n<ul>\n<li>Dependencies</li>\n</ul>\n<p>NGP relies on explicit dependencies which are mentioned as pre-requisites.<br>It does not rely on implicit existence of system-wide packages.</p>\n<ul>\n<li>Config</li>\n</ul>\n<p>The app specific configurations (such as credentials to external services, resource handles to caches) are not stored as constants in the code.<br>They are strictly separated from the code and they vary across environments(staging, production, development).</p>\n<ul>\n<li>Backing Services</li>\n</ul>\n<p>A backing service is any service the app consumes over the network as part of its normal operation.<br>NGP uses the caching system Redis for Tyk API Gateway and binary asset service, Amazon S3.</p>\n<ul>\n<li>Code Release</li>\n</ul>\n<p>The release processes for NGP are managed automatically using Jenkins. </p>\n<ul>\n<li>Processes</li>\n</ul>\n<p>The ‘Next Generation Platform’ runs applications as stateless docker containers.</p>\n<ul>\n<li>Port binding</li>\n</ul>\n<p>The NGP executes the applications inside docker containers. These containers exports services by binding to a port and listening to requests coming on that port.<br>The routing layer handles routing requests from a public-facing hostname to the port-bound processes.</p>\n<ul>\n<li><p>Concurrency </p>\n<p>All the running apps in NGP can be scaled using the auto-scaling feature.</p>\n</li>\n<li><p>Disposability</p>\n</li>\n</ul>\n<p>The apps run using NGP are disposable,meaning they can be started or stopped at a moment’s notice.<br>This facilitates rapid deployment of code or config changes.</p>\n<ul>\n<li>Dev/prod parity</li>\n</ul>\n<p>The NGP keeps its development, staging and production environments as similar as possible.<br>The NGP is designed for continuous deployment by keeping the gap between production and development small.</p>\n<ul>\n<li>Logs</li>\n</ul>\n<p>The NGP does not attempt to write or manage log files. Each running process writes its event stream to ‘stdout’. This platform has its own mechanism to rotate the logs generated by the apps.<br>It uses Filebeat to collect the logs and is processed using ELK.</p>\n<ul>\n<li>Admin Processes</li>\n</ul>\n<p>The admin/management processes are run in an identical environment as the NGP. They run against a release, using the same codebase and config.<br>The developers use ssh or other remote command execution mechanism to run administration tasks.</p>\n<h3 id=\"DevOps-Best-Practices\"><a href=\"#DevOps-Best-Practices\" class=\"headerlink\" title=\"DevOps Best Practices\"></a>DevOps Best Practices</h3><ul>\n<li>Active participation : developers, operations staff, and support people must work closely together on a regular basis.</li>\n<li>Integrated change management : change management is the act of ensuring successful and meaningful evolution of the IT infrastructure to better support the overall organization. The NGP architecture is continuously evolved to ensure high availability.</li>\n<li>Continuous Integration : Continuous integration (CI) is the discipline of building and validating a project, through automated regression testing and sometimes code analysis whenever updated code is checked into the version control system. NGP uses Jenkins to ensure this.</li>\n<li>Integrated Deployment Planning : Experienced development teams will do deployment planning continuously throughout construction with active stakeholder participation from development, operations, and support groups.</li>\n<li>Continuous Deployment : With continuous deployment, when your integration is successful in one sandbox, your changes are automatically promoted to the next sandbox, and integration is automatically started there. NGP uses Jenkins for enabling Continuous deployment of applications.</li>\n<li>Application Monitoring : This is the operational practice of monitoring running solutions and applications once they are in production. NGP uses ELK along with file-beats for log monitoring. This also implements Sysdig for monitoring using Sysdig cloud.</li>\n</ul>\n","excerpt":"","more":"<h3 id=\"Overview\"><a href=\"#Overview\" class=\"headerlink\" title=\"Overview\"></a>Overview</h3><p>The Next Gen Platform(NGP) enables Infrastructure as Code (IaC) to provision and manage a complete infrastructure that set up a DC/OS cluster and applications on top of it. The complete infrastructure is setup on AWS Cloud.<br>The Infrastructure as code is written using <a href=\"https://www.terraform.io/\">Terraform</a>. </p>\n<p>The different modules that are installed and managed using this IaC are:<br> a. OpenVPN Server<br> b. DC/OS Cluster<br> c. Docker Private Registry<br> d. API Gateway<br> e. ELK<br> f. EC2 Container Registry<br> g. Marathon Snapshot</p>\n<h3 id=\"NGP-Infrastructure-Design\"><a href=\"#NGP-Infrastructure-Design\" class=\"headerlink\" title=\"NGP Infrastructure Design\"></a>NGP Infrastructure Design</h3><p><img src=\"../../images/NGP_Architecture.png\" alt=\"NGP Infrastructure Design\"></p>\n<h3 id=\"Implementing-Next-Gen-Platform\"><a href=\"#Implementing-Next-Gen-Platform\" class=\"headerlink\" title=\"Implementing Next Gen Platform\"></a>Implementing Next Gen Platform</h3><h4 id=\"Pre-requisites\"><a href=\"#Pre-requisites\" class=\"headerlink\" title=\"Pre-requisites\"></a>Pre-requisites</h4><ul>\n<li>AWS IAM account with administrator privileges (Save your AWS IAM access key ID and secret access key)</li>\n<li>Terraform (latest version)</li>\n<li>AWS CLI</li>\n<li>For the ease of Installation, we suggest using IaC-manager, to create a manager node. This IaC will create the following for you:<ul>\n<li>VPC</li>\n<li>Management Subnet</li>\n<li>Internet Gateway</li>\n<li>IAM Role with required policies attached</li>\n<li>Manager Node (CentOS)<br>If not using IaC-manager, Please create the above resources (except Manager Node).</li>\n</ul>\n</li>\n<li>Accept Software Terms of AWS Marketplace for CentOS/CoreOs/OpenVPN Access Server. </li>\n<li>Setup Tyk Hybrid account from <a href=\"https://cloud.tyk.io/signup\">https://cloud.tyk.io/signup</a> for running Tyk API gateway </li>\n<li>A hosted zone in AWS Route53 for your domain name. This is required to create a record for creating a friendly dns name for the load balancers.</li>\n</ul>\n<h4 id=\"Steps\"><a href=\"#Steps\" class=\"headerlink\" title=\"Steps\"></a>Steps</h4><ul>\n<li><p>Export AWS credentials as bash variables</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">export AWS_ACCESS_KEY_ID=&quot;anaccesskey&quot;</div><div class=\"line\">export AWS_SECRET_ACCESS_KEY=&quot;asecretkey&quot;</div><div class=\"line\">export AWS_DEFAULT_REGION=&quot;ap-northeast-1&quot;  //(e.g. ap-northeast-1 for Tokyo and ap-southeast-1 for Singapore region)</div></pre></td></tr></table></figure>\n</li>\n<li><p>Clone the repo <a href=\"https://github.com/microservices-today/IaC-platform\">IaC-platform</a></p>\n</li>\n<li>Change directory to IaC-platform</li>\n<li>Run ./configure.sh to decide which modules to run (The different modules are explained later in this blog)</li>\n<li>Copy terraform.dummy to terraform.tfvars</li>\n<li><p>If you are using [IaC-Manager][iac-manager], run </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">cat ~/terraform.out &gt;&gt; ~/IaC-dcos/terraform.tfvars</div></pre></td></tr></table></figure>\n</li>\n<li><p>Modify params in <code>terraform.tfvars</code> for required modules</p>\n</li>\n<li>(Optional) Modify params in <code>variable.tf</code> to change <strong>default values</strong> including subnet or add AMI accordingly to your aws region</li>\n<li>Run <code>terraform plan</code> to see the plan to execute.</li>\n<li>Run <code>terraform apply</code> to run the scripts.</li>\n<li>You may have <code>prod/dev/stage</code> configurations in <code>terraform.tfvars.{prod/dev/stage}</code> files (already ignored by <code>.gitignore</code>).</li>\n</ul>\n<h4 id=\"Steps-to-Import-a-New-Module\"><a href=\"#Steps-to-Import-a-New-Module\" class=\"headerlink\" title=\"Steps to Import a New Module\"></a>Steps to Import a New Module</h4><ul>\n<li>Create a folder with module-name in modules directory and add the following files within that folder:<br>a. module-name.tf : File to create and manage module.<br>b. module-name.dummy : Dummy values for the module.<br>c. module-name-variables.tf : Variables required for the module.<br>d. module-name-output.tf : Outputs to be displayed after execution.</li>\n<li>Add module-name to module array in configure.sh.</li>\n</ul>\n<h4 id=\"Monitoring-DC-OS-Cluster\"><a href=\"#Monitoring-DC-OS-Cluster\" class=\"headerlink\" title=\"Monitoring DC/OS Cluster\"></a>Monitoring DC/OS Cluster</h4><ul>\n<li><a href=\"http://www.sysdig.org/\">Sysdig</a> containers will be running in all DC/OS nodes for proper monitoring of instances through sysdig cloud.</li>\n<li><a href=\"https://github.com/microservices-today/filebeat-docker\">Filebeat-Docker</a> containers will be running in all dcos nodes for dcos and marathon log capturing. By installing Iac-Elk, you will be able to monitor the logs through AWS elasticsearch service.</li>\n</ul>\n<h4 id=\"Outputs\"><a href=\"#Outputs\" class=\"headerlink\" title=\"Outputs\"></a>Outputs</h4><p>The following outputs will be generated after running the IaC:</p>\n<ul>\n<li>OpenVPN URL and credentials</li>\n<li>DC/OS URL</li>\n</ul>\n<h4 id=\"Notes\"><a href=\"#Notes\" class=\"headerlink\" title=\"Notes\"></a>Notes</h4><ul>\n<li>Provide the latest stable version while running the “configure.sh” bash script.</li>\n<li>Always provide a uniquely identifiable pre-tag and post-tag for your deployments.</li>\n<li>Adhere to AWS naming conventions when providing names for AWS resources.</li>\n</ul>\n<h3 id=\"OpenVPN-Server\"><a href=\"#OpenVPN-Server\" class=\"headerlink\" title=\"OpenVPN Server\"></a>OpenVPN Server</h3><p>OpenVPN is an open-source software application that implements virtual private network (VPN) for creating secure connections to remote     access facilities. This platform will install an OpenVPN server using AWS OpenVPN Access Server AMI. Steps to setup OpenVPN server using terraform can be found at IaC-openvpn.<br>Running the Next Generation Platform will give you the OpenVPN connect URL and Admin URL along with the credentials.</p>\n<h4 id=\"Connecting-to-VPN\"><a href=\"#Connecting-to-VPN\" class=\"headerlink\" title=\"Connecting to VPN\"></a>Connecting to VPN</h4><ul>\n<li>Install OpenVPN client on local machine.</li>\n<li>Download the client config file.<br>a. Browse to <a href=\"https://OpenVPN_URL/\">https://OpenVPN_URL/</a> or <a href=\"https://OpenVPN_Public_IP\">https://OpenVPN_Public_IP</a><br>b. Give the openvpn admin credentials<br>c. Download the client.ovpn file by clicking Yourself(user-locked profile)<br>   <img src=\"../../images/openVPN.png\" alt=\"OpenVPN Connect\"><br>d. Run the OpenVPN client with the downloaded client config file    <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">openvpn --config client.ovpn</div></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>  e. For MaC: Follow the link <a href=\"https://openvpn.net/index.php/access-server/docs/quick-start-guide/495-connecting-to-openvpn-access-server-using-the-connect-client-on-mac.html\">OpenVPN</a></p>\n<p>  Once connected to the VPN, the users can access DC/OS web interface and Jenkins Web Interface.<br>  Accessing Tyk dashboard does not require a VPN connection.</p>\n<h3 id=\"DC-OS-Cluster\"><a href=\"#DC-OS-Cluster\" class=\"headerlink\" title=\"DC/OS Cluster\"></a>DC/OS Cluster</h3><p>DC/OS is a distributed operating system based on Apache Mesos. It enables the management of multiple machines and simplifies the installation and management of distributed services.<br>The documentation for DC/OS can be found at DC/OS. Steps to set up a DC/OS cluster in AWS Cloud using terraform can be found at IaC-DC/OS.<br>After running the IaC for Next Generation Platform, you can launch the DC/OS web interface by entering the DC/OS Url (Given as output for IaC).</p>\n<p><img src=\"../../images/DCOS.png\" alt=\"DC/OS Web Interface\"></p>\n<h3 id=\"Tyk-API-Gateway\"><a href=\"#Tyk-API-Gateway\" class=\"headerlink\" title=\"Tyk API Gateway\"></a>Tyk API Gateway</h3><p>Tyk is an Open Source API Management Platform and Gateway. Our full Tyk stack consists of multiple components working together, the three most important ones are:</p>\n<ul>\n<li>Tyk Gateway: This does all the heavy lifting, and is the actual proxy doing all the work</li>\n<li>Tyk Dashboard: This is the GUI to control your gateways and view analytics, as well as an extended Dashboard REST API that enables granular integration</li>\n<li>Tyk Pump: A data processor that moves analytics data from your gateways (redis) into other data sinks, most importantly MongoDB for the dashboard to process.</li>\n</ul>\n<p>The git repo for setting Tyk on DC/OS using terraform is available at <a href=\"https://github.com/microservices-today/IaC-api-gateway\">IaC-api-gateway</a>. The pre-requisite would be to setup Tyk Hybrid account from <a href=\"https://cloud.tyk.io/signup\">https://cloud.tyk.io/signup</a>.</p>\n<ul>\n<li>Tyk dashboard is accessible at <a href=\"http://admin.cloud.tyk.io/\">http://admin.cloud.tyk.io/</a> </li>\n<li>Provide the credentials that were configured while running NGP<br><img src=\"../../images/Tyk-API-Gateway.png\" alt=\"Tyk API Gateway Dashboard\"><br><img src=\"../../images/Tyk-API.png\" alt=\"Tyk Registered API\"></li>\n</ul>\n<h3 id=\"Docker-Private-Registry\"><a href=\"#Docker-Private-Registry\" class=\"headerlink\" title=\"Docker Private Registry\"></a>Docker Private Registry</h3><p>The registry is a stateless, server side application that stores and distributes Docker images. NGP uses docker private registry to own the image distribution pipeline. It integrates image storage and distribution tightly into in-house deployment workflow.<br>The git repo for running docker private registry on DC/OS is available at <a href=\"https://github.com/microservices-today/IaC-dcos-docker-registry\">IaC-dcos-docker-registry</a>.</p>\n<p>Running NGP will create Docker Private Registry container with virtual IP: 192.168.0.1. The registry storage uses S3 bucket.<br>The S3 bucket name and region are specified while running the IaC. The storage root directory is set to “/docker-registry”.<br>To test the app, follow the below steps:<br>a. Pull any public docker image<br>   <code>docker pull nginx</code><br>b. Tag the image with the IP of docker private registry app<br>   <code>docker tag nginx 192.168.0.1/nginx</code><br>c. Push the image to docker private registry<br>   <code>docker push 192.168.0.1/nginx</code><br>   The above steps will create a folder named docker-registry inside your specified S3 bucket. The docker image should be available in that folder.</p>\n<h3 id=\"ELK\"><a href=\"#ELK\" class=\"headerlink\" title=\"ELK\"></a>ELK</h3><p>Elasticsearch, along with Logstash and Kibana, provides a powerful platform for indexing, searching and analyzing log data.</p>\n<h5 id=\"Filebeat\"><a href=\"#Filebeat\" class=\"headerlink\" title=\"Filebeat\"></a>Filebeat</h5><p>Filebeat is a lightweight, open source shipper for log file data. Filebeat tails logs and quickly sends this information to Logstash for further parsing and enrichment.</p>\n<h5 id=\"Filebeat-Docker\"><a href=\"#Filebeat-Docker\" class=\"headerlink\" title=\"Filebeat-Docker\"></a>Filebeat-Docker</h5><p><a href=\"https://github.com/microservices-today/filebeat-docker\">Filebeat-Docker</a> IaC creates a filebeat docker image. This docker image is configured to monitor <code>mesos</code> and <code>marathon app</code> logs. It allows to pass the logstash uri as an environment variable to the docker.<br>AWS provides a kibana interface for elasticsearch module. For accessing the elasticsearch or kibana though browser you have to update the your system IP address to the elasticsearch access policy as shown below:</p>\n<p> <img src=\"../../images/ELK-Access-Policy.png\" alt=\"Modify Access Policy\"></p>\n<p> Kibana dashboard URL is available within AWS Elasticsearch Service as shown below:<br> <img src=\"../../images/ELK-Kibana-URL.png\" alt=\"Kibana URL\"></p>\n<p> Accessing the Kibana URL will give you a dashboard as shown below:<br> <img src=\"../../images/Kibana-dashboard.png\" alt=\"Kibana Dashboard\"></p>\n<h3 id=\"Marathon-Snapshot\"><a href=\"#Marathon-Snapshot\" class=\"headerlink\" title=\"Marathon Snapshot\"></a>Marathon Snapshot</h3><p><a href=\"https://github.com/microservices-today/IaC-marathon-snapshots\">Marathon snapshot</a> IaC is used to take snapshots of marathon applications. These snapshots are stored in a S3 bucket (Bucket name is specified while running NGP).<br>This is performed by running a Lambda function which is periodically triggered by a CloudWatch metric.<br>This app takes snapshots of marathon applications every hour.<br>The IaC, also creates an AWS API gateway to trigger the Lambda function in order to restore the marathon snapshot.</p>\n<h3 id=\"EC2-Container-Registry\"><a href=\"#EC2-Container-Registry\" class=\"headerlink\" title=\"EC2 Container Registry\"></a>EC2 Container Registry</h3><p>EC2 Container Registry (ECR) is a fully-managed Docker container registry by Amazon. NGP will deploy a marathon container that performs the ECR-Login in regular intervals. It then places the compressed the docker config in a location (shared location across all the agents) where the marathon can access.<br>It can be used as an alternative to the “Docker Private Registry” app discussed earlier.<br>To test the app, follow the below steps:<br>a. Pull any public docker image<br>b. Tag the image with the ID of EC2 container registry<br>c. Push the image to EC2 container registry</p>\n<h3 id=\"The-Twelve-Factors-of-Next-Gen-Platform\"><a href=\"#The-Twelve-Factors-of-Next-Gen-Platform\" class=\"headerlink\" title=\"The Twelve Factors of Next Gen Platform\"></a>The Twelve Factors of Next Gen Platform</h3><ul>\n<li>Codebase</li>\n</ul>\n<p>The code repository for “The Next Generation Platform” is always tracked in Git version control system. It is a distributed system with multiple codebases.<br>Each component/module in NGP is an app and each individually comply with twelve-factor.</p>\n<ul>\n<li>Dependencies</li>\n</ul>\n<p>NGP relies on explicit dependencies which are mentioned as pre-requisites.<br>It does not rely on implicit existence of system-wide packages.</p>\n<ul>\n<li>Config</li>\n</ul>\n<p>The app specific configurations (such as credentials to external services, resource handles to caches) are not stored as constants in the code.<br>They are strictly separated from the code and they vary across environments(staging, production, development).</p>\n<ul>\n<li>Backing Services</li>\n</ul>\n<p>A backing service is any service the app consumes over the network as part of its normal operation.<br>NGP uses the caching system Redis for Tyk API Gateway and binary asset service, Amazon S3.</p>\n<ul>\n<li>Code Release</li>\n</ul>\n<p>The release processes for NGP are managed automatically using Jenkins. </p>\n<ul>\n<li>Processes</li>\n</ul>\n<p>The ‘Next Generation Platform’ runs applications as stateless docker containers.</p>\n<ul>\n<li>Port binding</li>\n</ul>\n<p>The NGP executes the applications inside docker containers. These containers exports services by binding to a port and listening to requests coming on that port.<br>The routing layer handles routing requests from a public-facing hostname to the port-bound processes.</p>\n<ul>\n<li><p>Concurrency </p>\n<p>All the running apps in NGP can be scaled using the auto-scaling feature.</p>\n</li>\n<li><p>Disposability</p>\n</li>\n</ul>\n<p>The apps run using NGP are disposable,meaning they can be started or stopped at a moment’s notice.<br>This facilitates rapid deployment of code or config changes.</p>\n<ul>\n<li>Dev/prod parity</li>\n</ul>\n<p>The NGP keeps its development, staging and production environments as similar as possible.<br>The NGP is designed for continuous deployment by keeping the gap between production and development small.</p>\n<ul>\n<li>Logs</li>\n</ul>\n<p>The NGP does not attempt to write or manage log files. Each running process writes its event stream to ‘stdout’. This platform has its own mechanism to rotate the logs generated by the apps.<br>It uses Filebeat to collect the logs and is processed using ELK.</p>\n<ul>\n<li>Admin Processes</li>\n</ul>\n<p>The admin/management processes are run in an identical environment as the NGP. They run against a release, using the same codebase and config.<br>The developers use ssh or other remote command execution mechanism to run administration tasks.</p>\n<h3 id=\"DevOps-Best-Practices\"><a href=\"#DevOps-Best-Practices\" class=\"headerlink\" title=\"DevOps Best Practices\"></a>DevOps Best Practices</h3><ul>\n<li>Active participation : developers, operations staff, and support people must work closely together on a regular basis.</li>\n<li>Integrated change management : change management is the act of ensuring successful and meaningful evolution of the IT infrastructure to better support the overall organization. The NGP architecture is continuously evolved to ensure high availability.</li>\n<li>Continuous Integration : Continuous integration (CI) is the discipline of building and validating a project, through automated regression testing and sometimes code analysis whenever updated code is checked into the version control system. NGP uses Jenkins to ensure this.</li>\n<li>Integrated Deployment Planning : Experienced development teams will do deployment planning continuously throughout construction with active stakeholder participation from development, operations, and support groups.</li>\n<li>Continuous Deployment : With continuous deployment, when your integration is successful in one sandbox, your changes are automatically promoted to the next sandbox, and integration is automatically started there. NGP uses Jenkins for enabling Continuous deployment of applications.</li>\n<li>Application Monitoring : This is the operational practice of monitoring running solutions and applications once they are in production. NGP uses ELK along with file-beats for log monitoring. This also implements Sysdig for monitoring using Sysdig cloud.</li>\n</ul>\n"},{"title":"Steps to verify elastic stack creation","date":"2017-01-03T10:10:48.000Z","_content":"### Steps to verify elastic stack creation\n\n##### 1. Open kibana interface\n\n1. Open the kibana ALB DNSName in a browser tab\n - you can find the ALB DNSName form stack output list\n - also you can find the ALB DNSName form Load Balancers list in AWS console.\n\n![image](../../images/elastic-stack/verify-kibana.png)\n\n2. The link will open up kibana interface.\n\n![image](../../images/elastic-stack/kibana.png)\n\n##### 2. Create a Management instance in public subnet\n1. Bring up a CentOs instance in our public subnet inorder to access ELK instances.\n2. SSH in to Management instance.\n```\n    ssh-add <pem>\n    ssh -A centos@<ip>\n```\n##### 3.Inastall filebeat 5.1.1\n\n```\n curl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-5.1.1-x86_64.rpm\n sudo rpm -vi filebeat-5.1.1-x86_64.rpm\n```\n4. Update file beat logstash configuration\n- Switch to root user\n```\nsudo su\n```\n- Open filebeat.yml\n```\nvi /etc/filebeat/filebeat.yml\n```\n- Comment default elastcsearch configuration\n- Uncomment logstash configuration and update host with logstash elb DNSName\n```\noutput.logstash:\n  # The Logstash hosts\n  hosts: [\"<logstash-elb-DNSname>:80\"]\n```\n- restart filebeat service\n```\nsystemctl restart filebeat\n```\n5. Verfiy results in kibana\n","source":"_posts/elastic-stack/Steps-to-verify-elastic-stack-creation.md","raw":"---\ntitle: Steps to verify elastic stack creation\ndate: 2017-01-03 15:40:48\ntags: elstic-stack\ncategories: elstic-stack\n---\n### Steps to verify elastic stack creation\n\n##### 1. Open kibana interface\n\n1. Open the kibana ALB DNSName in a browser tab\n - you can find the ALB DNSName form stack output list\n - also you can find the ALB DNSName form Load Balancers list in AWS console.\n\n![image](../../images/elastic-stack/verify-kibana.png)\n\n2. The link will open up kibana interface.\n\n![image](../../images/elastic-stack/kibana.png)\n\n##### 2. Create a Management instance in public subnet\n1. Bring up a CentOs instance in our public subnet inorder to access ELK instances.\n2. SSH in to Management instance.\n```\n    ssh-add <pem>\n    ssh -A centos@<ip>\n```\n##### 3.Inastall filebeat 5.1.1\n\n```\n curl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-5.1.1-x86_64.rpm\n sudo rpm -vi filebeat-5.1.1-x86_64.rpm\n```\n4. Update file beat logstash configuration\n- Switch to root user\n```\nsudo su\n```\n- Open filebeat.yml\n```\nvi /etc/filebeat/filebeat.yml\n```\n- Comment default elastcsearch configuration\n- Uncomment logstash configuration and update host with logstash elb DNSName\n```\noutput.logstash:\n  # The Logstash hosts\n  hosts: [\"<logstash-elb-DNSname>:80\"]\n```\n- restart filebeat service\n```\nsystemctl restart filebeat\n```\n5. Verfiy results in kibana\n","slug":"elastic-stack/Steps-to-verify-elastic-stack-creation","published":1,"updated":"2017-01-04T10:53:44.418Z","_id":"cixion04p0000wvlnbgb3r34a","comments":1,"layout":"post","photos":[],"link":"","content":"<h3 id=\"Steps-to-verify-elastic-stack-creation\"><a href=\"#Steps-to-verify-elastic-stack-creation\" class=\"headerlink\" title=\"Steps to verify elastic stack creation\"></a>Steps to verify elastic stack creation</h3><h5 id=\"1-Open-kibana-interface\"><a href=\"#1-Open-kibana-interface\" class=\"headerlink\" title=\"1. Open kibana interface\"></a>1. Open kibana interface</h5><ol>\n<li>Open the kibana ALB DNSName in a browser tab<ul>\n<li>you can find the ALB DNSName form stack output list</li>\n<li>also you can find the ALB DNSName form Load Balancers list in AWS console.</li>\n</ul>\n</li>\n</ol>\n<p><img src=\"../../images/elastic-stack/verify-kibana.png\" alt=\"image\"></p>\n<ol>\n<li>The link will open up kibana interface.</li>\n</ol>\n<p><img src=\"../../images/elastic-stack/kibana.png\" alt=\"image\"></p>\n<h5 id=\"2-Create-a-Management-instance-in-public-subnet\"><a href=\"#2-Create-a-Management-instance-in-public-subnet\" class=\"headerlink\" title=\"2. Create a Management instance in public subnet\"></a>2. Create a Management instance in public subnet</h5><ol>\n<li>Bring up a CentOs instance in our public subnet inorder to access ELK instances.</li>\n<li>SSH in to Management instance.<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">ssh-add &lt;pem&gt;</div><div class=\"line\">ssh -A centos@&lt;ip&gt;</div></pre></td></tr></table></figure>\n</li>\n</ol>\n<h5 id=\"3-Inastall-filebeat-5-1-1\"><a href=\"#3-Inastall-filebeat-5-1-1\" class=\"headerlink\" title=\"3.Inastall filebeat 5.1.1\"></a>3.Inastall filebeat 5.1.1</h5><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">curl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-5.1.1-x86_64.rpm</div><div class=\"line\">sudo rpm -vi filebeat-5.1.1-x86_64.rpm</div></pre></td></tr></table></figure>\n<ol>\n<li>Update file beat logstash configuration</li>\n</ol>\n<ul>\n<li><p>Switch to root user</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo su</div></pre></td></tr></table></figure>\n</li>\n<li><p>Open filebeat.yml</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">vi /etc/filebeat/filebeat.yml</div></pre></td></tr></table></figure>\n</li>\n<li><p>Comment default elastcsearch configuration</p>\n</li>\n<li><p>Uncomment logstash configuration and update host with logstash elb DNSName</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">output.logstash:</div><div class=\"line\">  # The Logstash hosts</div><div class=\"line\">  hosts: [&quot;&lt;logstash-elb-DNSname&gt;:80&quot;]</div></pre></td></tr></table></figure>\n</li>\n<li><p>restart filebeat service</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">systemctl restart filebeat</div></pre></td></tr></table></figure>\n</li>\n</ul>\n<ol>\n<li>Verfiy results in kibana</li>\n</ol>\n","excerpt":"","more":"<h3 id=\"Steps-to-verify-elastic-stack-creation\"><a href=\"#Steps-to-verify-elastic-stack-creation\" class=\"headerlink\" title=\"Steps to verify elastic stack creation\"></a>Steps to verify elastic stack creation</h3><h5 id=\"1-Open-kibana-interface\"><a href=\"#1-Open-kibana-interface\" class=\"headerlink\" title=\"1. Open kibana interface\"></a>1. Open kibana interface</h5><ol>\n<li>Open the kibana ALB DNSName in a browser tab<ul>\n<li>you can find the ALB DNSName form stack output list</li>\n<li>also you can find the ALB DNSName form Load Balancers list in AWS console.</li>\n</ul>\n</li>\n</ol>\n<p><img src=\"../../images/elastic-stack/verify-kibana.png\" alt=\"image\"></p>\n<ol>\n<li>The link will open up kibana interface.</li>\n</ol>\n<p><img src=\"../../images/elastic-stack/kibana.png\" alt=\"image\"></p>\n<h5 id=\"2-Create-a-Management-instance-in-public-subnet\"><a href=\"#2-Create-a-Management-instance-in-public-subnet\" class=\"headerlink\" title=\"2. Create a Management instance in public subnet\"></a>2. Create a Management instance in public subnet</h5><ol>\n<li>Bring up a CentOs instance in our public subnet inorder to access ELK instances.</li>\n<li>SSH in to Management instance.<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">ssh-add &lt;pem&gt;</div><div class=\"line\">ssh -A centos@&lt;ip&gt;</div></pre></td></tr></table></figure>\n</li>\n</ol>\n<h5 id=\"3-Inastall-filebeat-5-1-1\"><a href=\"#3-Inastall-filebeat-5-1-1\" class=\"headerlink\" title=\"3.Inastall filebeat 5.1.1\"></a>3.Inastall filebeat 5.1.1</h5><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">curl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-5.1.1-x86_64.rpm</div><div class=\"line\">sudo rpm -vi filebeat-5.1.1-x86_64.rpm</div></pre></td></tr></table></figure>\n<ol>\n<li>Update file beat logstash configuration</li>\n</ol>\n<ul>\n<li><p>Switch to root user</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo su</div></pre></td></tr></table></figure>\n</li>\n<li><p>Open filebeat.yml</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">vi /etc/filebeat/filebeat.yml</div></pre></td></tr></table></figure>\n</li>\n<li><p>Comment default elastcsearch configuration</p>\n</li>\n<li><p>Uncomment logstash configuration and update host with logstash elb DNSName</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">output.logstash:</div><div class=\"line\">  # The Logstash hosts</div><div class=\"line\">  hosts: [&quot;&lt;logstash-elb-DNSname&gt;:80&quot;]</div></pre></td></tr></table></figure>\n</li>\n<li><p>restart filebeat service</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">systemctl restart filebeat</div></pre></td></tr></table></figure>\n</li>\n</ul>\n<ol>\n<li>Verfiy results in kibana</li>\n</ol>\n"},{"title":"Elastic Stack Creation","date":"2017-01-03T12:36:06.000Z","_content":"\n### Steps to create elastic stack\n![image](../../images/elastic-stack/elastic-stack.png)\n##### 1. Download template file\n- Clone [IaC-ngp-elastic][iac-ngp-elastic] repo.\n\n##### 2. Create a stack on the AWS CloudFormation console\n1. Log in to the AWS Management Console and select CloudFormation in the Services menu.\n2. Create a new stack by using one of the following options:\n - Click **Create Stack**. This is the only option if you have a currently running stack.\n\n![image](../../images/elastic-stack/console-create-stack-button.png)\n - Click **Create New Stack** in the CloudFormation Stacks main window. This option is visible only if you have no running stacks.\n\n![image](../../images/elastic-stack/console-create-stack-button1.png)\n\n##### 3. Selecting the Stack Template\n1. Select **Upload a template to Amazon S3** under **Choose a template** section.\n2. Select **elastic.yaml** from cloned repo. Choose **Choose File** to select the template file from your local computer.\n3. Click **Next** to accept your settings and proceed.\n\n![image](../../images/elastic-stack/select-template.png)\n\n##### 4. Specifying Stack Name and Parameters\n- Specify the stack name and values for the parameters that were defined in the template.\n\n![image](../../images/elastic-stack/parameters.png)\n\n##### 5. Stack Creation Successful\n- If the stack creation is successful you will see a **CREATE_COMPLETE** message in status section.\n\n![image](../../images/elastic-stack/creation-completed.png)\n[iac-ngp-elastic]: <https://github.com/microservices-today/IaC-ngp-elastic>","source":"_posts/elastic-stack/Steps-to-create-elastic-stack.md","raw":"---\ntitle: Elastic Stack Creation\ndate: 2017-01-03 18:06:06\ntags: elstic-stack\ncategories: elstic-stack\n---\n\n### Steps to create elastic stack\n![image](../../images/elastic-stack/elastic-stack.png)\n##### 1. Download template file\n- Clone [IaC-ngp-elastic][iac-ngp-elastic] repo.\n\n##### 2. Create a stack on the AWS CloudFormation console\n1. Log in to the AWS Management Console and select CloudFormation in the Services menu.\n2. Create a new stack by using one of the following options:\n - Click **Create Stack**. This is the only option if you have a currently running stack.\n\n![image](../../images/elastic-stack/console-create-stack-button.png)\n - Click **Create New Stack** in the CloudFormation Stacks main window. This option is visible only if you have no running stacks.\n\n![image](../../images/elastic-stack/console-create-stack-button1.png)\n\n##### 3. Selecting the Stack Template\n1. Select **Upload a template to Amazon S3** under **Choose a template** section.\n2. Select **elastic.yaml** from cloned repo. Choose **Choose File** to select the template file from your local computer.\n3. Click **Next** to accept your settings and proceed.\n\n![image](../../images/elastic-stack/select-template.png)\n\n##### 4. Specifying Stack Name and Parameters\n- Specify the stack name and values for the parameters that were defined in the template.\n\n![image](../../images/elastic-stack/parameters.png)\n\n##### 5. Stack Creation Successful\n- If the stack creation is successful you will see a **CREATE_COMPLETE** message in status section.\n\n![image](../../images/elastic-stack/creation-completed.png)\n[iac-ngp-elastic]: <https://github.com/microservices-today/IaC-ngp-elastic>","slug":"elastic-stack/Steps-to-create-elastic-stack","published":1,"updated":"2017-01-04T10:43:53.158Z","_id":"cixion04s0001wvlnprxtovei","comments":1,"layout":"post","photos":[],"link":"","content":"<h3 id=\"Steps-to-create-elastic-stack\"><a href=\"#Steps-to-create-elastic-stack\" class=\"headerlink\" title=\"Steps to create elastic stack\"></a>Steps to create elastic stack</h3><p><img src=\"../../images/elastic-stack/elastic-stack.png\" alt=\"image\"></p>\n<h5 id=\"1-Download-template-file\"><a href=\"#1-Download-template-file\" class=\"headerlink\" title=\"1. Download template file\"></a>1. Download template file</h5><ul>\n<li>Clone <a href=\"https://github.com/microservices-today/IaC-ngp-elastic\" target=\"_blank\" rel=\"external\">IaC-ngp-elastic</a> repo.</li>\n</ul>\n<h5 id=\"2-Create-a-stack-on-the-AWS-CloudFormation-console\"><a href=\"#2-Create-a-stack-on-the-AWS-CloudFormation-console\" class=\"headerlink\" title=\"2. Create a stack on the AWS CloudFormation console\"></a>2. Create a stack on the AWS CloudFormation console</h5><ol>\n<li>Log in to the AWS Management Console and select CloudFormation in the Services menu.</li>\n<li>Create a new stack by using one of the following options:<ul>\n<li>Click <strong>Create Stack</strong>. This is the only option if you have a currently running stack.</li>\n</ul>\n</li>\n</ol>\n<p><img src=\"../../images/elastic-stack/console-create-stack-button.png\" alt=\"image\"></p>\n<ul>\n<li>Click <strong>Create New Stack</strong> in the CloudFormation Stacks main window. This option is visible only if you have no running stacks.</li>\n</ul>\n<p><img src=\"../../images/elastic-stack/console-create-stack-button1.png\" alt=\"image\"></p>\n<h5 id=\"3-Selecting-the-Stack-Template\"><a href=\"#3-Selecting-the-Stack-Template\" class=\"headerlink\" title=\"3. Selecting the Stack Template\"></a>3. Selecting the Stack Template</h5><ol>\n<li>Select <strong>Upload a template to Amazon S3</strong> under <strong>Choose a template</strong> section.</li>\n<li>Select <strong>elastic.yaml</strong> from cloned repo. Choose <strong>Choose File</strong> to select the template file from your local computer.</li>\n<li>Click <strong>Next</strong> to accept your settings and proceed.</li>\n</ol>\n<p><img src=\"../../images/elastic-stack/select-template.png\" alt=\"image\"></p>\n<h5 id=\"4-Specifying-Stack-Name-and-Parameters\"><a href=\"#4-Specifying-Stack-Name-and-Parameters\" class=\"headerlink\" title=\"4. Specifying Stack Name and Parameters\"></a>4. Specifying Stack Name and Parameters</h5><ul>\n<li>Specify the stack name and values for the parameters that were defined in the template.</li>\n</ul>\n<p><img src=\"../../images/elastic-stack/parameters.png\" alt=\"image\"></p>\n<h5 id=\"5-Stack-Creation-Successful\"><a href=\"#5-Stack-Creation-Successful\" class=\"headerlink\" title=\"5. Stack Creation Successful\"></a>5. Stack Creation Successful</h5><ul>\n<li>If the stack creation is successful you will see a <strong>CREATE_COMPLETE</strong> message in status section.</li>\n</ul>\n<p><img src=\"../../images/elastic-stack/creation-completed.png\" alt=\"image\"></p>\n","excerpt":"","more":"<h3 id=\"Steps-to-create-elastic-stack\"><a href=\"#Steps-to-create-elastic-stack\" class=\"headerlink\" title=\"Steps to create elastic stack\"></a>Steps to create elastic stack</h3><p><img src=\"../../images/elastic-stack/elastic-stack.png\" alt=\"image\"></p>\n<h5 id=\"1-Download-template-file\"><a href=\"#1-Download-template-file\" class=\"headerlink\" title=\"1. Download template file\"></a>1. Download template file</h5><ul>\n<li>Clone <a href=\"https://github.com/microservices-today/IaC-ngp-elastic\">IaC-ngp-elastic</a> repo.</li>\n</ul>\n<h5 id=\"2-Create-a-stack-on-the-AWS-CloudFormation-console\"><a href=\"#2-Create-a-stack-on-the-AWS-CloudFormation-console\" class=\"headerlink\" title=\"2. Create a stack on the AWS CloudFormation console\"></a>2. Create a stack on the AWS CloudFormation console</h5><ol>\n<li>Log in to the AWS Management Console and select CloudFormation in the Services menu.</li>\n<li>Create a new stack by using one of the following options:<ul>\n<li>Click <strong>Create Stack</strong>. This is the only option if you have a currently running stack.</li>\n</ul>\n</li>\n</ol>\n<p><img src=\"../../images/elastic-stack/console-create-stack-button.png\" alt=\"image\"></p>\n<ul>\n<li>Click <strong>Create New Stack</strong> in the CloudFormation Stacks main window. This option is visible only if you have no running stacks.</li>\n</ul>\n<p><img src=\"../../images/elastic-stack/console-create-stack-button1.png\" alt=\"image\"></p>\n<h5 id=\"3-Selecting-the-Stack-Template\"><a href=\"#3-Selecting-the-Stack-Template\" class=\"headerlink\" title=\"3. Selecting the Stack Template\"></a>3. Selecting the Stack Template</h5><ol>\n<li>Select <strong>Upload a template to Amazon S3</strong> under <strong>Choose a template</strong> section.</li>\n<li>Select <strong>elastic.yaml</strong> from cloned repo. Choose <strong>Choose File</strong> to select the template file from your local computer.</li>\n<li>Click <strong>Next</strong> to accept your settings and proceed.</li>\n</ol>\n<p><img src=\"../../images/elastic-stack/select-template.png\" alt=\"image\"></p>\n<h5 id=\"4-Specifying-Stack-Name-and-Parameters\"><a href=\"#4-Specifying-Stack-Name-and-Parameters\" class=\"headerlink\" title=\"4. Specifying Stack Name and Parameters\"></a>4. Specifying Stack Name and Parameters</h5><ul>\n<li>Specify the stack name and values for the parameters that were defined in the template.</li>\n</ul>\n<p><img src=\"../../images/elastic-stack/parameters.png\" alt=\"image\"></p>\n<h5 id=\"5-Stack-Creation-Successful\"><a href=\"#5-Stack-Creation-Successful\" class=\"headerlink\" title=\"5. Stack Creation Successful\"></a>5. Stack Creation Successful</h5><ul>\n<li>If the stack creation is successful you will see a <strong>CREATE_COMPLETE</strong> message in status section.</li>\n</ul>\n<p><img src=\"../../images/elastic-stack/creation-completed.png\" alt=\"image\"></p>\n"}],"PostAsset":[],"PostCategory":[{"post_id":"cixigfrjn000bf33p6ps0t6py","category_id":"cixigfrjo000cf33pmqhtjqkm","_id":"cixigfrjo000ff33plpcgpnhg"},{"post_id":"cixigfrjp000gf33phjji6s8d","category_id":"cixigfrjo000cf33pmqhtjqkm","_id":"cixigfrjq000if33p30ugp33b"},{"post_id":"cixigfrjx000vf33phjhkfi2b","category_id":"cixigfrjy000wf33p33bon66e","_id":"cixigfrjy000xf33psvexs7v5"},{"post_id":"cixigfrjz000yf33plxqkpnke","category_id":"cixigfrjy000wf33p33bon66e","_id":"cixigfrjz000zf33p8cdsrl2q"},{"post_id":"cixigfrjz0010f33pxxac5sm6","category_id":"cixigfrjy000wf33p33bon66e","_id":"cixigfrk00011f33p5nw9sdyk"},{"post_id":"cixigfrk00012f33pl3p690a3","category_id":"cixigfrjy000wf33p33bon66e","_id":"cixigfrk10013f33psdguzn3d"},{"post_id":"cixigfrk10014f33p7nt6216s","category_id":"cixigfrjy000wf33p33bon66e","_id":"cixigfrk20015f33pxvasrzzf"},{"post_id":"cixigfrk30016f33peb02zd4o","category_id":"cixigfrk30017f33p4u18t3uj","_id":"cixigfrk3001af33pe3lir1ko"},{"post_id":"cixigfrk4001bf33pscxeqo4x","category_id":"cixigfrk30017f33p4u18t3uj","_id":"cixigfrk4001df33pdv8cp2pa"},{"post_id":"cixigfrk5001ff33pxeta5cpq","category_id":"cixigfrk30017f33p4u18t3uj","_id":"cixigfrk6001gf33prprcxi9b"},{"post_id":"cixion04p0000wvlnbgb3r34a","category_id":"cixion04u0002wvlnuhfokrt7","_id":"cixion05b0007wvln3x1o0e2w"},{"post_id":"cixion04s0001wvlnprxtovei","category_id":"cixion04u0002wvlnuhfokrt7","_id":"cixion05d0009wvln1l6d9uyl"}],"PostTag":[{"post_id":"cixigfrip0000f33pv3u4r1yj","tag_id":"cixigfris0001f33p2sqbzavg","_id":"cixigfrit0002f33pjdbdr55f"},{"post_id":"cixigfriv0003f33po264wzc3","tag_id":"cixigfriw0004f33po6uqjyw2","_id":"cixigfriw0005f33pxn0zbm8u"},{"post_id":"cixigfriw0006f33p0plx9dup","tag_id":"cixigfrix0007f33p6k4g89ft","_id":"cixigfrix0008f33pcorslktz"},{"post_id":"cixigfrjn000bf33p6ps0t6py","tag_id":"cixigfrjo000df33plvz8bi6e","_id":"cixigfrjo000ef33p49edks23"},{"post_id":"cixigfrjp000gf33phjji6s8d","tag_id":"cixigfrjq000hf33pmuftxhtf","_id":"cixigfrjq000jf33pqho34z16"},{"post_id":"cixigfrjq000kf33pf6h8yxmt","tag_id":"cixigfrjr000lf33pw3lh3rfl","_id":"cixigfrjr000mf33piorr7kqj"},{"post_id":"cixigfrjt000of33pb0qjeh70","tag_id":"cixigfrjr000lf33pw3lh3rfl","_id":"cixigfrju000pf33p3jtd8sye"},{"post_id":"cixigfrju000qf33pwfl9cv0c","tag_id":"cixigfrjr000lf33pw3lh3rfl","_id":"cixigfrjv000rf33ptpk3mqg5"},{"post_id":"cixigfrjv000sf33pusfnvix9","tag_id":"cixigfrjr000lf33pw3lh3rfl","_id":"cixigfrjw000tf33p56bm1knw"},{"post_id":"cixigfrk30016f33peb02zd4o","tag_id":"cixigfrk30018f33pz80r17go","_id":"cixigfrk30019f33p5gq0pbo7"},{"post_id":"cixigfrk4001bf33pscxeqo4x","tag_id":"cixigfrk4001cf33ptrlqdydy","_id":"cixigfrk4001ef33p2vgj8f3p"},{"post_id":"cixion04p0000wvlnbgb3r34a","tag_id":"cixion0550003wvlnvgqc25lf","_id":"cixion05a0006wvlnf76lyb2r"},{"post_id":"cixion04s0001wvlnprxtovei","tag_id":"cixion0550003wvlnvgqc25lf","_id":"cixion05c0008wvlnltpe4td9"},{"post_id":"cixigfrjs000nf33prz59ljhi","tag_id":"cixigfrjr000lf33pw3lh3rfl","_id":"cixitzupg0000g3lnbj7ig232"}],"Tag":[{"name":"DCOS Disaster Recovery","_id":"cixigfris0001f33p2sqbzavg"},{"name":"Debugging DCOS","_id":"cixigfriw0004f33po6uqjyw2"},{"name":"Nginx Marathon App example","_id":"cixigfrix0007f33p6k4g89ft"},{"name":"Troubleshoot CoreOS in DCOS","_id":"cixigfrjo000df33plvz8bi6e"},{"name":"Troubleshooting common scenarios in DCOS","_id":"cixigfrjq000hf33pmuftxhtf"},{"name":"AWS Developer tools","_id":"cixigfrjr000lf33pw3lh3rfl"},{"name":"manager","_id":"cixigfrk30018f33pz80r17go"},{"name":"dcos","_id":"cixigfrk4001cf33ptrlqdydy"},{"name":"elstic-stack","_id":"cixion0550003wvlnvgqc25lf"}]}}